{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c36baf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\onedrive\\onedrive - sri lanka institute of information technology\\research\\transcript-based-skill-validation-quiz\\transcript-based-skill-validation-quiz\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85fd633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fe08321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 175 job records\n",
      "\n",
      "Columns: ['job_id', 'title', 'company', 'location', 'posted_date', 'job_url', 'scraped_at', 'description', 'seniority_level', 'employment_type', 'job_function', 'industries', 'skills', 'role_tag', 'role_key', 'job_role_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>posted_date</th>\n",
       "      <th>job_url</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>description</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_function</th>\n",
       "      <th>industries</th>\n",
       "      <th>skills</th>\n",
       "      <th>role_tag</th>\n",
       "      <th>role_key</th>\n",
       "      <th>job_role_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai-engineer-at-ifs-4285393282</td>\n",
       "      <td>AI Engineer</td>\n",
       "      <td>IFS</td>\n",
       "      <td>Colombo, Western Province, Sri Lanka</td>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>https://lk.linkedin.com/jobs/view/ai-engineer-...</td>\n",
       "      <td>2025-11-20T07:49:22.793209</td>\n",
       "      <td>IFS is a billion-dollar revenue company with 7...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Services and IT Consulting</td>\n",
       "      <td>Python | JavaScript | TypeScript | SQL | Bash ...</td>\n",
       "      <td>AIML</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "      <td>AIML_20251120_005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ai-research-engineer-agentic-ai-intelligent-au...</td>\n",
       "      <td>AI Research Engineer - Agentic AI &amp; Intelligen...</td>\n",
       "      <td>Robotic Assistance Devices</td>\n",
       "      <td>Colombo, Western Province, Sri Lanka</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>https://lk.linkedin.com/jobs/view/ai-research-...</td>\n",
       "      <td>2025-11-20T07:49:22.793215</td>\n",
       "      <td>We are seeking a talented and driven AI Engine...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Public Safety</td>\n",
       "      <td>Python | Machine Learning | Deep Learning | Te...</td>\n",
       "      <td>AIML</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "      <td>AIML_20251120_006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ai-research-engineer-computer-vision-analytics...</td>\n",
       "      <td>AI Research Engineer Computer Vision &amp; Analytics</td>\n",
       "      <td>Robotic Assistance Devices</td>\n",
       "      <td>Colombo, Western Province, Sri Lanka</td>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>https://lk.linkedin.com/jobs/view/ai-research-...</td>\n",
       "      <td>2025-11-20T07:49:22.793219</td>\n",
       "      <td>We are seeking a talented and driven AI Engine...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>Public Safety</td>\n",
       "      <td>Python | Machine Learning | Deep Learning | Te...</td>\n",
       "      <td>AIML</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "      <td>AIML_20251120_007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ai-ml-engineer-at-rsc-solutions-4323135079</td>\n",
       "      <td>AI/ML Engineer</td>\n",
       "      <td>RSC Solutions</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/ai-ml-engin...</td>\n",
       "      <td>2025-11-20T07:49:22.793229</td>\n",
       "      <td>Long Term ContractRemoteWe are seeking a highl...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Contract</td>\n",
       "      <td>Engineering and Information Technology</td>\n",
       "      <td>IT Services and IT Consulting, Software Develo...</td>\n",
       "      <td>Python | SQL | Machine Learning | TensorFlow |...</td>\n",
       "      <td>AIML</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "      <td>AIML_20251120_011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine-learning-engineer-at-aaa-global-433656...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>AAA Global</td>\n",
       "      <td>New York City Metropolitan Area</td>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>2025-11-20T07:49:22.793242</td>\n",
       "      <td>Machine Learning Engineer – Elite Systematic T...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Research</td>\n",
       "      <td>Financial Services and Investment Management</td>\n",
       "      <td>Python | R | Machine Learning | Deep Learning ...</td>\n",
       "      <td>AIML</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "      <td>AIML_20251120_022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job_id  \\\n",
       "0                      ai-engineer-at-ifs-4285393282   \n",
       "1  ai-research-engineer-agentic-ai-intelligent-au...   \n",
       "2  ai-research-engineer-computer-vision-analytics...   \n",
       "3         ai-ml-engineer-at-rsc-solutions-4323135079   \n",
       "4  machine-learning-engineer-at-aaa-global-433656...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        AI Engineer   \n",
       "1  AI Research Engineer - Agentic AI & Intelligen...   \n",
       "2   AI Research Engineer Computer Vision & Analytics   \n",
       "3                                     AI/ML Engineer   \n",
       "4                          Machine Learning Engineer   \n",
       "\n",
       "                      company                              location  \\\n",
       "0                         IFS  Colombo, Western Province, Sri Lanka   \n",
       "1  Robotic Assistance Devices  Colombo, Western Province, Sri Lanka   \n",
       "2  Robotic Assistance Devices  Colombo, Western Province, Sri Lanka   \n",
       "3               RSC Solutions                          New York, NY   \n",
       "4                  AAA Global       New York City Metropolitan Area   \n",
       "\n",
       "  posted_date                                            job_url  \\\n",
       "0  2025-11-10  https://lk.linkedin.com/jobs/view/ai-engineer-...   \n",
       "1  2025-11-03  https://lk.linkedin.com/jobs/view/ai-research-...   \n",
       "2  2025-11-03  https://lk.linkedin.com/jobs/view/ai-research-...   \n",
       "3  2025-11-18  https://www.linkedin.com/jobs/view/ai-ml-engin...   \n",
       "4  2025-11-18  https://www.linkedin.com/jobs/view/machine-lea...   \n",
       "\n",
       "                   scraped_at  \\\n",
       "0  2025-11-20T07:49:22.793209   \n",
       "1  2025-11-20T07:49:22.793215   \n",
       "2  2025-11-20T07:49:22.793219   \n",
       "3  2025-11-20T07:49:22.793229   \n",
       "4  2025-11-20T07:49:22.793242   \n",
       "\n",
       "                                         description   seniority_level  \\\n",
       "0  IFS is a billion-dollar revenue company with 7...  Mid-Senior level   \n",
       "1  We are seeking a talented and driven AI Engine...       Entry level   \n",
       "2  We are seeking a talented and driven AI Engine...       Entry level   \n",
       "3  Long Term ContractRemoteWe are seeking a highl...       Entry level   \n",
       "4  Machine Learning Engineer – Elite Systematic T...    Not Applicable   \n",
       "\n",
       "  employment_type                            job_function  \\\n",
       "0       Full-time                  Information Technology   \n",
       "1       Full-time  Engineering and Information Technology   \n",
       "2       Full-time  Engineering and Information Technology   \n",
       "3        Contract  Engineering and Information Technology   \n",
       "4       Full-time                                Research   \n",
       "\n",
       "                                          industries  \\\n",
       "0                      IT Services and IT Consulting   \n",
       "1                                      Public Safety   \n",
       "2                                      Public Safety   \n",
       "3  IT Services and IT Consulting, Software Develo...   \n",
       "4       Financial Services and Investment Management   \n",
       "\n",
       "                                              skills role_tag        role_key  \\\n",
       "0  Python | JavaScript | TypeScript | SQL | Bash ...     AIML  ai_ml_engineer   \n",
       "1  Python | Machine Learning | Deep Learning | Te...     AIML  ai_ml_engineer   \n",
       "2  Python | Machine Learning | Deep Learning | Te...     AIML  ai_ml_engineer   \n",
       "3  Python | SQL | Machine Learning | TensorFlow |...     AIML  ai_ml_engineer   \n",
       "4  Python | R | Machine Learning | Deep Learning ...     AIML  ai_ml_engineer   \n",
       "\n",
       "         job_role_id  \n",
       "0  AIML_20251120_005  \n",
       "1  AIML_20251120_006  \n",
       "2  AIML_20251120_007  \n",
       "3  AIML_20251120_011  \n",
       "4  AIML_20251120_022  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the job data CSV\n",
    "df = pd.read_csv('../data/Job_data.csv')\n",
    "print(f\"Loaded {len(df)} job records\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a757793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role Key Counts:\n",
      "role_key\n",
      "software_engineer    40\n",
      "data_analyst         34\n",
      "ai_ml_engineer       30\n",
      "data_engineer        30\n",
      "devops_engineer      30\n",
      "web_developer        11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique role keys: 6\n"
     ]
    }
   ],
   "source": [
    "# Parse skills column - split by '|' into list\n",
    "df['skills_list'] = df['skills'].apply(lambda x: [s.strip() for s in str(x).split('|')] if pd.notna(x) and x else [])\n",
    "\n",
    "# Check role_key counts\n",
    "print(\"Role Key Counts:\")\n",
    "print(df['role_key'].value_counts())\n",
    "print(f\"\\nTotal unique role keys: {df['role_key'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6473e017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 Raw Skills:\n",
      "Python: 104\n",
      "Communication: 83\n",
      "SQL: 67\n",
      "Analytics: 64\n",
      "CI/CD: 55\n",
      "Problem-Solving: 55\n",
      "AWS: 55\n",
      "Collaboration: 45\n",
      "Innovation: 45\n",
      "DevOps: 44\n",
      "Machine Learning: 41\n",
      "Azure: 40\n",
      "Agile: 40\n",
      "Compliance: 37\n",
      "Docker: 36\n",
      "Documentation: 36\n",
      "Reporting: 36\n",
      "Git: 32\n",
      "Leadership: 29\n",
      "Java: 29\n",
      "React: 28\n",
      "Power BI: 28\n",
      "Kubernetes: 28\n",
      "ETL: 28\n",
      "Data Quality: 26\n",
      "GCP: 25\n",
      "Go: 24\n",
      "JavaScript: 23\n",
      "TypeScript: 21\n",
      "GitHub: 21\n"
     ]
    }
   ],
   "source": [
    "# Get top 30 raw skills\n",
    "from collections import Counter\n",
    "all_skills = []\n",
    "for skills in df['skills_list']:\n",
    "    all_skills.extend(skills)\n",
    "\n",
    "skill_counts = Counter(all_skills)\n",
    "print(\"Top 30 Raw Skills:\")\n",
    "for skill, count in skill_counts.most_common(30):\n",
    "    print(f\"{skill}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e930dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Exported mapping template to: ../data/job_skill_to_parent_skill.csv\n",
      "  Total skills: 200\n",
      "  Coverage: 2496 / 2662 skill occurrences (93.8%)\n",
      "\n",
      "First 10 rows of template:\n",
      "    job_skill_norm  count parent_skill\n",
      "0           python    104             \n",
      "1    communication     83             \n",
      "2              sql     67             \n",
      "3        analytics     64             \n",
      "4            ci/cd     55             \n",
      "5  problem-solving     55             \n",
      "6              aws     55             \n",
      "7    collaboration     45             \n",
      "8       innovation     45             \n",
      "9           devops     44             \n",
      "\n",
      "Please fill in the 'parent_skill' column manually!\n"
     ]
    }
   ],
   "source": [
    "# Export CSV template for manual mapping (top 200 skills)\n",
    "top_200_skills = skill_freq.most_common(200)\n",
    "\n",
    "# Create DataFrame with columns: job_skill_norm, count, parent_skill\n",
    "mapping_template = pd.DataFrame({\n",
    "    'job_skill_norm': [skill for skill, count in top_200_skills],\n",
    "    'count': [count for skill, count in top_200_skills],\n",
    "    'parent_skill': [''] * len(top_200_skills)  # Blank for manual filling\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/job_skill_to_parent_skill.csv'\n",
    "mapping_template.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✓ Exported mapping template to: {output_path}\")\n",
    "print(f\"  Total skills: {len(mapping_template)}\")\n",
    "print(f\"  Coverage: {sum(mapping_template['count'])} / {len(normalized_skills)} skill occurrences ({sum(mapping_template['count'])/len(normalized_skills)*100:.1f}%)\")\n",
    "print(f\"\\nFirst 10 rows of template:\")\n",
    "print(mapping_template.head(10))\n",
    "print(f\"\\nPlease fill in the 'parent_skill' column manually!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a299851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-filling common skill mappings...\n",
      "✓ Auto-mapped 24 skills\n",
      "  Total skills in template: 200\n",
      "  Skills with parent_skill: 24 / 200\n",
      "  Skills still unmapped: 0\n",
      "\n",
      "Updated template saved to: ../data/job_skill_to_parent_skill.csv\n",
      "\n",
      "Auto-mapped skills:\n",
      "  python → Programming Fundamentals & C Language\n",
      "  sql → Database Design & Administration\n",
      "  aws → Operating Systems & System Administration\n",
      "  azure → Operating Systems & System Administration\n",
      "  gcp → Operating Systems & System Administration\n",
      "  docker → Operating Systems & System Administration\n",
      "  kubernetes → Networking & Protocol Management\n",
      "  ci/cd → Software Development Processes\n",
      "  devops → Networking & Protocol Management\n",
      "  git → Software Development & Engineering Practices\n",
      "  github → Software Development & Engineering Practices\n",
      "  java → Object-Oriented Design & Programming\n",
      "  javascript → Web Development & Internet Technologies\n",
      "  typescript → Web Development & Internet Technologies\n",
      "  react → Full-Stack Web Application Development\n",
      "  power bi → Data Engineering & BI Analytics\n",
      "  etl → Data Engineering & BI Analytics\n",
      "  machine learning → Machine Learning & Optimization\n",
      "  deep learning → Machine Learning & Optimization\n",
      "  communication → Professionalism & Workplace Readiness\n",
      "  collaboration → Employability & Workplace Readiness\n",
      "  leadership → Employability & Workplace Readiness\n",
      "  agile → Software Development Processes\n",
      "  problem-solving → Problem Solving & Algorithm Development\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_7056\\2124002292.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Programming Fundamentals & C Language' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  mapping_df.at[idx, 'parent_skill'] = skill_parent_map[skill_norm]\n"
     ]
    }
   ],
   "source": [
    "# Auto-fill parent_skill for common job skills as starter mapping\n",
    "print(\"Auto-filling common skill mappings...\")\n",
    "\n",
    "# Define starter mappings (normalized skill -> parent_skill)\n",
    "skill_parent_map = {\n",
    "    \"python\": \"Programming Fundamentals & C Language\",\n",
    "    \"sql\": \"Database Design & Administration\",\n",
    "    \"aws\": \"Operating Systems & System Administration\",\n",
    "    \"azure\": \"Operating Systems & System Administration\",\n",
    "    \"gcp\": \"Operating Systems & System Administration\",\n",
    "    \"docker\": \"Operating Systems & System Administration\",\n",
    "    \"kubernetes\": \"Networking & Protocol Management\",\n",
    "    \"ci/cd\": \"Software Development Processes\",\n",
    "    \"devops\": \"Networking & Protocol Management\",\n",
    "    \"git\": \"Software Development & Engineering Practices\",\n",
    "    \"github\": \"Software Development & Engineering Practices\",\n",
    "    \"java\": \"Object-Oriented Design & Programming\",\n",
    "    \"javascript\": \"Web Development & Internet Technologies\",\n",
    "    \"typescript\": \"Web Development & Internet Technologies\",\n",
    "    \"react\": \"Full-Stack Web Application Development\",\n",
    "    \"power bi\": \"Data Engineering & BI Analytics\",\n",
    "    \"etl\": \"Data Engineering & BI Analytics\",\n",
    "    \"machine learning\": \"Machine Learning & Optimization\",\n",
    "    \"deep learning\": \"Machine Learning & Optimization\",\n",
    "    \"communication\": \"Professionalism & Workplace Readiness\",\n",
    "    \"collaboration\": \"Employability & Workplace Readiness\",\n",
    "    \"leadership\": \"Employability & Workplace Readiness\",\n",
    "    \"agile\": \"Software Development Processes\",\n",
    "    \"problem-solving\": \"Problem Solving & Algorithm Development\"\n",
    "}\n",
    "\n",
    "# Load the template\n",
    "template_path = '../data/job_skill_to_parent_skill.csv'\n",
    "mapping_df = pd.read_csv(template_path)\n",
    "\n",
    "# Apply auto-mapping\n",
    "auto_mapped_count = 0\n",
    "for idx, row in mapping_df.iterrows():\n",
    "    skill_norm = row['job_skill_norm']\n",
    "    if pd.isna(row['parent_skill']) or row['parent_skill'] == '':\n",
    "        if skill_norm in skill_parent_map:\n",
    "            mapping_df.at[idx, 'parent_skill'] = skill_parent_map[skill_norm]\n",
    "            auto_mapped_count += 1\n",
    "\n",
    "# Save updated template\n",
    "mapping_df.to_csv(template_path, index=False)\n",
    "\n",
    "print(f\"✓ Auto-mapped {auto_mapped_count} skills\")\n",
    "print(f\"  Total skills in template: {len(mapping_df)}\")\n",
    "print(f\"  Skills with parent_skill: {mapping_df['parent_skill'].notna().sum()} / {(mapping_df['parent_skill'] != '').sum()}\")\n",
    "print(f\"  Skills still unmapped: {(mapping_df['parent_skill'] == '').sum()}\")\n",
    "print(f\"\\nUpdated template saved to: {template_path}\")\n",
    "print(\"\\nAuto-mapped skills:\")\n",
    "for skill, parent in skill_parent_map.items():\n",
    "    if skill in mapping_df['job_skill_norm'].values:\n",
    "        print(f\"  {skill} → {parent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7007938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAPPING VALIDATION: Top 30 Job Skills → Parent Skills\n",
      "================================================================================\n",
      " Rank        Job Skill  Count                                 Parent Skill\n",
      "    1           python    104        Programming Fundamentals & C Language\n",
      "    2    communication     83        Professionalism & Workplace Readiness\n",
      "    3              sql     67             Database Design & Administration\n",
      "    4        analytics     64                                 ❌ NOT MAPPED\n",
      "    5            ci/cd     55               Software Development Processes\n",
      "    6  problem-solving     55      Problem Solving & Algorithm Development\n",
      "    7              aws     55    Operating Systems & System Administration\n",
      "    8    collaboration     45          Employability & Workplace Readiness\n",
      "    9       innovation     45                                 ❌ NOT MAPPED\n",
      "   10           devops     44             Networking & Protocol Management\n",
      "   11 machine learning     41              Machine Learning & Optimization\n",
      "   12            azure     40    Operating Systems & System Administration\n",
      "   13            agile     40               Software Development Processes\n",
      "   14       compliance     37                                 ❌ NOT MAPPED\n",
      "   15           docker     36    Operating Systems & System Administration\n",
      "   16    documentation     36                                 ❌ NOT MAPPED\n",
      "   17        reporting     36                                 ❌ NOT MAPPED\n",
      "   18              git     32 Software Development & Engineering Practices\n",
      "   19       leadership     29          Employability & Workplace Readiness\n",
      "   20             java     29         Object-Oriented Design & Programming\n",
      "   21            react     28       Full-Stack Web Application Development\n",
      "   22         power bi     28              Data Engineering & BI Analytics\n",
      "   23       kubernetes     28             Networking & Protocol Management\n",
      "   24              etl     28              Data Engineering & BI Analytics\n",
      "   25     data quality     26                                 ❌ NOT MAPPED\n",
      "   26              gcp     25    Operating Systems & System Administration\n",
      "   27               go     24                                 ❌ NOT MAPPED\n",
      "   28       javascript     23      Web Development & Internet Technologies\n",
      "   29       typescript     21      Web Development & Internet Technologies\n",
      "   30           github     21 Software Development & Engineering Practices\n",
      "\n",
      "================================================================================\n",
      "Mapping Coverage: 23/30 (76.7%) of top 30 skills are mapped\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Job Skill</th>\n",
       "      <th>Count</th>\n",
       "      <th>Parent Skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>python</td>\n",
       "      <td>104</td>\n",
       "      <td>Programming Fundamentals &amp; C Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>communication</td>\n",
       "      <td>83</td>\n",
       "      <td>Professionalism &amp; Workplace Readiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>sql</td>\n",
       "      <td>67</td>\n",
       "      <td>Database Design &amp; Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>analytics</td>\n",
       "      <td>64</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ci/cd</td>\n",
       "      <td>55</td>\n",
       "      <td>Software Development Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>problem-solving</td>\n",
       "      <td>55</td>\n",
       "      <td>Problem Solving &amp; Algorithm Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>aws</td>\n",
       "      <td>55</td>\n",
       "      <td>Operating Systems &amp; System Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>collaboration</td>\n",
       "      <td>45</td>\n",
       "      <td>Employability &amp; Workplace Readiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>innovation</td>\n",
       "      <td>45</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>devops</td>\n",
       "      <td>44</td>\n",
       "      <td>Networking &amp; Protocol Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>41</td>\n",
       "      <td>Machine Learning &amp; Optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>azure</td>\n",
       "      <td>40</td>\n",
       "      <td>Operating Systems &amp; System Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>agile</td>\n",
       "      <td>40</td>\n",
       "      <td>Software Development Processes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>compliance</td>\n",
       "      <td>37</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>docker</td>\n",
       "      <td>36</td>\n",
       "      <td>Operating Systems &amp; System Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>documentation</td>\n",
       "      <td>36</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>reporting</td>\n",
       "      <td>36</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>git</td>\n",
       "      <td>32</td>\n",
       "      <td>Software Development &amp; Engineering Practices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>leadership</td>\n",
       "      <td>29</td>\n",
       "      <td>Employability &amp; Workplace Readiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>java</td>\n",
       "      <td>29</td>\n",
       "      <td>Object-Oriented Design &amp; Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>react</td>\n",
       "      <td>28</td>\n",
       "      <td>Full-Stack Web Application Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>power bi</td>\n",
       "      <td>28</td>\n",
       "      <td>Data Engineering &amp; BI Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>kubernetes</td>\n",
       "      <td>28</td>\n",
       "      <td>Networking &amp; Protocol Management</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>etl</td>\n",
       "      <td>28</td>\n",
       "      <td>Data Engineering &amp; BI Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>data quality</td>\n",
       "      <td>26</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>gcp</td>\n",
       "      <td>25</td>\n",
       "      <td>Operating Systems &amp; System Administration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>go</td>\n",
       "      <td>24</td>\n",
       "      <td>❌ NOT MAPPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>javascript</td>\n",
       "      <td>23</td>\n",
       "      <td>Web Development &amp; Internet Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>typescript</td>\n",
       "      <td>21</td>\n",
       "      <td>Web Development &amp; Internet Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>github</td>\n",
       "      <td>21</td>\n",
       "      <td>Software Development &amp; Engineering Practices</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank         Job Skill  Count  \\\n",
       "0      1            python    104   \n",
       "1      2     communication     83   \n",
       "2      3               sql     67   \n",
       "3      4         analytics     64   \n",
       "4      5             ci/cd     55   \n",
       "5      6   problem-solving     55   \n",
       "6      7               aws     55   \n",
       "7      8     collaboration     45   \n",
       "8      9        innovation     45   \n",
       "9     10            devops     44   \n",
       "10    11  machine learning     41   \n",
       "11    12             azure     40   \n",
       "12    13             agile     40   \n",
       "13    14        compliance     37   \n",
       "14    15            docker     36   \n",
       "15    16     documentation     36   \n",
       "16    17         reporting     36   \n",
       "17    18               git     32   \n",
       "18    19        leadership     29   \n",
       "19    20              java     29   \n",
       "20    21             react     28   \n",
       "21    22          power bi     28   \n",
       "22    23        kubernetes     28   \n",
       "23    24               etl     28   \n",
       "24    25      data quality     26   \n",
       "25    26               gcp     25   \n",
       "26    27                go     24   \n",
       "27    28        javascript     23   \n",
       "28    29        typescript     21   \n",
       "29    30            github     21   \n",
       "\n",
       "                                    Parent Skill  \n",
       "0          Programming Fundamentals & C Language  \n",
       "1          Professionalism & Workplace Readiness  \n",
       "2               Database Design & Administration  \n",
       "3                                   ❌ NOT MAPPED  \n",
       "4                 Software Development Processes  \n",
       "5        Problem Solving & Algorithm Development  \n",
       "6      Operating Systems & System Administration  \n",
       "7            Employability & Workplace Readiness  \n",
       "8                                   ❌ NOT MAPPED  \n",
       "9               Networking & Protocol Management  \n",
       "10               Machine Learning & Optimization  \n",
       "11     Operating Systems & System Administration  \n",
       "12                Software Development Processes  \n",
       "13                                  ❌ NOT MAPPED  \n",
       "14     Operating Systems & System Administration  \n",
       "15                                  ❌ NOT MAPPED  \n",
       "16                                  ❌ NOT MAPPED  \n",
       "17  Software Development & Engineering Practices  \n",
       "18           Employability & Workplace Readiness  \n",
       "19          Object-Oriented Design & Programming  \n",
       "20        Full-Stack Web Application Development  \n",
       "21               Data Engineering & BI Analytics  \n",
       "22              Networking & Protocol Management  \n",
       "23               Data Engineering & BI Analytics  \n",
       "24                                  ❌ NOT MAPPED  \n",
       "25     Operating Systems & System Administration  \n",
       "26                                  ❌ NOT MAPPED  \n",
       "27       Web Development & Internet Technologies  \n",
       "28       Web Development & Internet Technologies  \n",
       "29  Software Development & Engineering Practices  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping validation table: top 30 skills with their mapped parent_skill\n",
    "print(\"\\nMAPPING VALIDATION: Top 30 Job Skills → Parent Skills\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the mapping file\n",
    "validation_mapping = pd.read_csv('../data/job_skill_to_parent_skill.csv')\n",
    "\n",
    "# Create validation dataframe for top 30 skills\n",
    "validation_data = []\n",
    "for idx, (skill, count) in enumerate(top_30_skills, 1):\n",
    "    # Find the parent_skill mapping\n",
    "    mapping_row = validation_mapping[validation_mapping['job_skill_norm'] == skill]\n",
    "    \n",
    "    if len(mapping_row) > 0:\n",
    "        parent = mapping_row.iloc[0]['parent_skill']\n",
    "        parent_display = parent if pd.notna(parent) and parent != '' else '❌ NOT MAPPED'\n",
    "    else:\n",
    "        parent_display = '⚠️ NOT IN TEMPLATE'\n",
    "    \n",
    "    validation_data.append({\n",
    "        'Rank': idx,\n",
    "        'Job Skill': skill,\n",
    "        'Count': count,\n",
    "        'Parent Skill': parent_display\n",
    "    })\n",
    "\n",
    "# Create and display validation DataFrame\n",
    "validation_df = pd.DataFrame(validation_data)\n",
    "print(validation_df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "mapped_count = sum(1 for item in validation_data if '❌' not in item['Parent Skill'] and '⚠️' not in item['Parent Skill'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Mapping Coverage: {mapped_count}/{len(top_30_skills)} ({mapped_count/len(top_30_skills)*100:.1f}%) of top 30 skills are mapped\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Show the validation table\n",
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8a30d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TOP 10 SKILLS PER ROLE\n",
      "================================================================================\n",
      "\n",
      "ai_ml_engineer (30 jobs):\n",
      "   1. python                                          26 ( 86.7%)\n",
      "   2. machine learning                                20 ( 66.7%)\n",
      "   3. pytorch                                         18 ( 60.0%)\n",
      "   4. communication                                   16 ( 53.3%)\n",
      "   5. tensorflow                                      16 ( 53.3%)\n",
      "   6. aws                                             13 ( 43.3%)\n",
      "   7. mlops                                           10 ( 33.3%)\n",
      "   8. problem-solving                                 10 ( 33.3%)\n",
      "   9. nlp                                              9 ( 30.0%)\n",
      "  10. docker                                           9 ( 30.0%)\n",
      "\n",
      "data_analyst (34 jobs):\n",
      "   1. analytics                                       26 ( 76.5%)\n",
      "   2. sql                                             25 ( 73.5%)\n",
      "   3. communication                                   20 ( 58.8%)\n",
      "   4. reporting                                       19 ( 55.9%)\n",
      "   5. python                                          18 ( 52.9%)\n",
      "   6. power bi                                        17 ( 50.0%)\n",
      "   7. tableau                                         16 ( 47.1%)\n",
      "   8. statistics                                      15 ( 44.1%)\n",
      "   9. problem-solving                                 13 ( 38.2%)\n",
      "  10. data analysis                                   11 ( 32.4%)\n",
      "\n",
      "data_engineer (30 jobs):\n",
      "   1. python                                          22 ( 73.3%)\n",
      "   2. analytics                                       22 ( 73.3%)\n",
      "   3. sql                                             21 ( 70.0%)\n",
      "   4. etl                                             17 ( 56.7%)\n",
      "   5. azure                                           13 ( 43.3%)\n",
      "   6. reporting                                       13 ( 43.3%)\n",
      "   7. communication                                   13 ( 43.3%)\n",
      "   8. data quality                                    13 ( 43.3%)\n",
      "   9. compliance                                      11 ( 36.7%)\n",
      "  10. machine learning                                11 ( 36.7%)\n",
      "\n",
      "devops_engineer (30 jobs):\n",
      "   1. devops                                          29 ( 96.7%)\n",
      "   2. ci/cd                                           25 ( 83.3%)\n",
      "   3. python                                          22 ( 73.3%)\n",
      "   4. terraform                                       18 ( 60.0%)\n",
      "   5. aws                                             17 ( 56.7%)\n",
      "   6. kubernetes                                      17 ( 56.7%)\n",
      "   7. bash                                            15 ( 50.0%)\n",
      "   8. iac                                             15 ( 50.0%)\n",
      "   9. docker                                          15 ( 50.0%)\n",
      "  10. linux                                           13 ( 43.3%)\n",
      "\n",
      "software_engineer (40 jobs):\n",
      "   1. communication                                   18 ( 45.0%)\n",
      "   2. react                                           16 ( 40.0%)\n",
      "   3. typescript                                      14 ( 35.0%)\n",
      "   4. python                                          14 ( 35.0%)\n",
      "   5. aws                                             13 ( 32.5%)\n",
      "   6. agile                                           13 ( 32.5%)\n",
      "   7. sql                                             12 ( 30.0%)\n",
      "   8. javascript                                      12 ( 30.0%)\n",
      "   9. ci/cd                                           11 ( 27.5%)\n",
      "  10. problem-solving                                 11 ( 27.5%)\n",
      "\n",
      "web_developer (11 jobs):\n",
      "   1. react                                            6 ( 54.5%)\n",
      "   2. communication                                    5 ( 45.5%)\n",
      "   3. version control                                  4 ( 36.4%)\n",
      "   4. javascript                                       4 ( 36.4%)\n",
      "   5. css                                              4 ( 36.4%)\n",
      "   6. documentation                                    3 ( 27.3%)\n",
      "   7. git                                              3 ( 27.3%)\n",
      "   8. compliance                                       3 ( 27.3%)\n",
      "   9. agile                                            3 ( 27.3%)\n",
      "  10. java                                             3 ( 27.3%)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Top 10 skills per role_key (normalized)\n",
    "print(\"\\nTOP 10 SKILLS PER ROLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for role in sorted(df['role_key'].unique()):\n",
    "    role_df = df[df['role_key'] == role]\n",
    "    \n",
    "    # Collect all normalized skills for this role\n",
    "    role_skills = []\n",
    "    for skills in role_df['skills_list']:\n",
    "        for skill in skills:\n",
    "            skill_norm = skill.strip().lower()\n",
    "            if skill_norm:\n",
    "                role_skills.append(skill_norm)\n",
    "    \n",
    "    # Count and display top 10\n",
    "    role_skill_freq = Counter(role_skills)\n",
    "    total_jobs = len(role_df)\n",
    "    \n",
    "    print(f\"\\n{role} ({total_jobs} jobs):\")\n",
    "    for idx, (skill, count) in enumerate(role_skill_freq.most_common(10), 1):\n",
    "        pct = (count / total_jobs) * 100\n",
    "        print(f\"  {idx:2d}. {skill:45s} {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588d06a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 30 IN-DEMAND JOB SKILLS\n",
      "================================================================================\n",
      " 1. python                                               104 occurrences\n",
      " 2. communication                                         83 occurrences\n",
      " 3. sql                                                   67 occurrences\n",
      " 4. analytics                                             64 occurrences\n",
      " 5. ci/cd                                                 55 occurrences\n",
      " 6. problem-solving                                       55 occurrences\n",
      " 7. aws                                                   55 occurrences\n",
      " 8. collaboration                                         45 occurrences\n",
      " 9. innovation                                            45 occurrences\n",
      "10. devops                                                44 occurrences\n",
      "11. machine learning                                      41 occurrences\n",
      "12. azure                                                 40 occurrences\n",
      "13. agile                                                 40 occurrences\n",
      "14. compliance                                            37 occurrences\n",
      "15. docker                                                36 occurrences\n",
      "16. documentation                                         36 occurrences\n",
      "17. reporting                                             36 occurrences\n",
      "18. git                                                   32 occurrences\n",
      "19. leadership                                            29 occurrences\n",
      "20. java                                                  29 occurrences\n",
      "21. react                                                 28 occurrences\n",
      "22. power bi                                              28 occurrences\n",
      "23. kubernetes                                            28 occurrences\n",
      "24. etl                                                   28 occurrences\n",
      "25. data quality                                          26 occurrences\n",
      "26. gcp                                                   25 occurrences\n",
      "27. go                                                    24 occurrences\n",
      "28. javascript                                            23 occurrences\n",
      "29. typescript                                            21 occurrences\n",
      "30. github                                                21 occurrences\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Top 30 normalized job skills with counts\n",
    "print(\"TOP 30 IN-DEMAND JOB SKILLS\")\n",
    "print(\"=\"*80)\n",
    "top_30_skills = skill_freq.most_common(30)\n",
    "for idx, (skill, count) in enumerate(top_30_skills, 1):\n",
    "    print(f\"{idx:2d}. {skill:50s} {count:5d} occurrences\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ae315",
   "metadata": {},
   "source": [
    "## Market Skill Summary\n",
    "\n",
    "Analyze the most in-demand job skills and validate mapping quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 20 skills per role_key (optional)\n",
    "print(\"\\nTop 20 Skills per Role:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for role in sorted(df['role_key'].unique()):\n",
    "    role_df = df[df['role_key'] == role]\n",
    "    \n",
    "    # Collect all normalized skills for this role\n",
    "    role_skills = []\n",
    "    for skills in role_df['skills_list']:\n",
    "        for skill in skills:\n",
    "            skill_norm = skill.strip().lower()\n",
    "            if skill_norm:\n",
    "                role_skills.append(skill_norm)\n",
    "    \n",
    "    # Count and display top 20\n",
    "    role_skill_freq = Counter(role_skills)\n",
    "    print(f\"\\n{role} (total: {len(role_skills)} skills, unique: {len(role_skill_freq)}):\")\n",
    "    for idx, (skill, count) in enumerate(role_skill_freq.most_common(20), 1):\n",
    "        print(f\"  {idx:2d}. {skill:45s} ({count:3d})\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b26ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 50 skills with counts\n",
    "print(\"Top 50 Normalized Skills:\")\n",
    "print(\"=\"*80)\n",
    "for idx, (skill, count) in enumerate(skill_freq.most_common(50), 1):\n",
    "    print(f\"{idx:2d}. {skill:50s} ({count:4d} occurrences)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd7f8153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total skill occurrences: 2662\n",
      "Unique normalized skills: 326\n",
      "\n",
      "Skill frequency distribution:\n",
      "  Skills appearing once: 86\n",
      "  Skills appearing 2-5 times: 128\n",
      "  Skills appearing 6+ times: 112\n"
     ]
    }
   ],
   "source": [
    "# Build normalized frequency table\n",
    "from collections import Counter\n",
    "\n",
    "# Normalize skills: strip spaces, lowercase, remove empty strings\n",
    "normalized_skills = []\n",
    "for skills in df['skills_list']:\n",
    "    for skill in skills:\n",
    "        skill_norm = skill.strip().lower()\n",
    "        if skill_norm:  # Remove empty strings\n",
    "            normalized_skills.append(skill_norm)\n",
    "\n",
    "# Count frequencies\n",
    "skill_freq = Counter(normalized_skills)\n",
    "print(f\"Total skill occurrences: {len(normalized_skills)}\")\n",
    "print(f\"Unique normalized skills: {len(skill_freq)}\")\n",
    "print(f\"\\nSkill frequency distribution:\")\n",
    "print(f\"  Skills appearing once: {sum(1 for count in skill_freq.values() if count == 1)}\")\n",
    "print(f\"  Skills appearing 2-5 times: {sum(1 for count in skill_freq.values() if 2 <= count <= 5)}\")\n",
    "print(f\"  Skills appearing 6+ times: {sum(1 for count in skill_freq.values() if count >= 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664fcf49",
   "metadata": {},
   "source": [
    "## Job Skill Vocabulary Analysis\n",
    "\n",
    "Build a normalized frequency table of all raw job skills and export a mapping template for manual parent skill assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78891fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 job skill mappings\n",
      "After filtering blank parent_skill: 24 mappings\n",
      "\n",
      "Unique parent skills mapped: 14\n",
      "Total parent skills (from skill_group_map): 27\n",
      "\n",
      "Parent skills: ['Academic Communication Skills', 'Advanced Database Design & Management', 'Computer Systems & Networking', 'Data Engineering & BI Analytics', 'Database Administration & Storage', 'Database Design & Administration', 'Employability & Workplace Readiness', 'Full-Stack Web Application Development', 'IT Project Management & Execution', 'Information Retrieval & Web Analytics', 'Information Security Analytics', 'Information Systems & Database Design', 'Java & Object-Oriented Application Development', 'Machine Learning & Optimization', 'Mathematics & Logical Thinking', 'Mobile Application Design & Development', 'Networking & Protocol Management', 'Object-Oriented Design & Programming', 'Operating Systems & System Administration', 'Problem Solving & Algorithm Development', 'Professionalism & Workplace Readiness', 'Programming Fundamentals & C Language', 'Software Development & Engineering Practices', 'Software Development Processes', 'Statistical Analysis & Data Interpretation', 'Statistical Modeling & Data Analysis', 'Web Development & Internet Technologies']\n"
     ]
    }
   ],
   "source": [
    "# Load job skill mapping (normalized job skills -> parent skills)\n",
    "job_mapping_df = pd.read_csv('../data/job_skill_to_parent_skill.csv')\n",
    "print(f\"Loaded {len(job_mapping_df)} job skill mappings\")\n",
    "\n",
    "# Drop rows where parent_skill is blank\n",
    "job_mapping_df = job_mapping_df[job_mapping_df['parent_skill'].notna() & (job_mapping_df['parent_skill'] != '')]\n",
    "print(f\"After filtering blank parent_skill: {len(job_mapping_df)} mappings\")\n",
    "\n",
    "# Create mapping dictionary: job_skill_norm -> parent_skill\n",
    "job_skill_to_parent = dict(zip(job_mapping_df['job_skill_norm'], job_mapping_df['parent_skill']))\n",
    "print(f\"\\nUnique parent skills mapped: {job_mapping_df['parent_skill'].nunique()}\")\n",
    "\n",
    "# Load original skill_group_map to get all 27 parent skills\n",
    "skill_map_df = pd.read_csv('../data/skill_group_map.csv')\n",
    "all_parent_skills = sorted(skill_map_df['parent_skill'].unique())\n",
    "print(f\"Total parent skills (from skill_group_map): {len(all_parent_skills)}\")\n",
    "print(f\"\\nParent skills: {all_parent_skills}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c626f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature matrix with 27 parent skill columns...\n",
      "\n",
      "X shape: (175, 27)\n",
      "y shape: (175,)\n",
      "\n",
      "Feature matrix (first 5 rows, first 10 columns):\n",
      "   Academic Communication Skills  Advanced Database Design & Management  \\\n",
      "0                              0                                      0   \n",
      "1                              0                                      0   \n",
      "2                              0                                      0   \n",
      "3                              0                                      0   \n",
      "4                              0                                      0   \n",
      "\n",
      "   Computer Systems & Networking  Data Engineering & BI Analytics  \\\n",
      "0                              0                                1   \n",
      "1                              0                                0   \n",
      "2                              0                                0   \n",
      "3                              0                                0   \n",
      "4                              0                                0   \n",
      "\n",
      "   Database Administration & Storage  Database Design & Administration  \\\n",
      "0                                  0                                 1   \n",
      "1                                  0                                 0   \n",
      "2                                  0                                 0   \n",
      "3                                  0                                 1   \n",
      "4                                  0                                 0   \n",
      "\n",
      "   Employability & Workplace Readiness  \\\n",
      "0                                    1   \n",
      "1                                    1   \n",
      "2                                    1   \n",
      "3                                    1   \n",
      "4                                    0   \n",
      "\n",
      "   Full-Stack Web Application Development  IT Project Management & Execution  \\\n",
      "0                                       1                                  0   \n",
      "1                                       0                                  0   \n",
      "2                                       0                                  0   \n",
      "3                                       0                                  0   \n",
      "4                                       0                                  0   \n",
      "\n",
      "   Information Retrieval & Web Analytics  \n",
      "0                                      0  \n",
      "1                                      0  \n",
      "2                                      0  \n",
      "3                                      0  \n",
      "4                                      0  \n"
     ]
    }
   ],
   "source": [
    "# Build feature matrix X using job skill mappings\n",
    "print(f\"Creating feature matrix with {len(all_parent_skills)} parent skill columns...\")\n",
    "\n",
    "# Initialize feature matrix\n",
    "X_dict = {parent_skill: [] for parent_skill in all_parent_skills}\n",
    "\n",
    "# For each job, map normalized skills to parent skills\n",
    "for idx, row in df.iterrows():\n",
    "    job_skills = row['skills_list']\n",
    "    \n",
    "    # Track which parent skills are active for this job\n",
    "    active_parents = set()\n",
    "    \n",
    "    # Normalize each job skill and map to parent skill\n",
    "    for job_skill in job_skills:\n",
    "        skill_norm = job_skill.strip().lower()\n",
    "        if skill_norm in job_skill_to_parent:\n",
    "            parent_skill = job_skill_to_parent[skill_norm]\n",
    "            active_parents.add(parent_skill)\n",
    "    \n",
    "    # Set binary features for each parent skill\n",
    "    for parent_skill in all_parent_skills:\n",
    "        X_dict[parent_skill].append(1 if parent_skill in active_parents else 0)\n",
    "\n",
    "# Create DataFrame\n",
    "X = pd.DataFrame(X_dict)\n",
    "y = df['role_key']\n",
    "\n",
    "print(f\"\\nX shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeature matrix (first 5 rows, first 10 columns):\")\n",
    "print(X.iloc[:5, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50028f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COVERAGE STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Non-zero feature columns: 14 / 27\n",
      "Jobs with ≥1 mapped parent skill: 167 / 175 (95.4%)\n",
      "Average mapped parent skills per job: 4.62\n",
      "\n",
      "Top 10 active parent skills by total count:\n",
      "   1. Programming Fundamentals & C Language              ( 104 jobs)\n",
      "   2. Professionalism & Workplace Readiness              (  83 jobs)\n",
      "   3. Operating Systems & System Administration          (  82 jobs)\n",
      "   4. Software Development Processes                     (  74 jobs)\n",
      "   5. Database Design & Administration                   (  67 jobs)\n",
      "   6. Employability & Workplace Readiness                (  65 jobs)\n",
      "   7. Problem Solving & Algorithm Development            (  55 jobs)\n",
      "   8. Networking & Protocol Management                   (  52 jobs)\n",
      "   9. Software Development & Engineering Practices       (  48 jobs)\n",
      "  10. Data Engineering & BI Analytics                    (  47 jobs)\n",
      "================================================================================\n",
      "\n",
      "✓ Saved feature matrix to: ../data/job_parent_skill_features.csv\n",
      "  - Shape: (175, 28)\n",
      "  - Columns: 28 (27 features + 1 target)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Academic Communication Skills</th>\n",
       "      <th>Advanced Database Design &amp; Management</th>\n",
       "      <th>Computer Systems &amp; Networking</th>\n",
       "      <th>Data Engineering &amp; BI Analytics</th>\n",
       "      <th>Database Administration &amp; Storage</th>\n",
       "      <th>Database Design &amp; Administration</th>\n",
       "      <th>Employability &amp; Workplace Readiness</th>\n",
       "      <th>Full-Stack Web Application Development</th>\n",
       "      <th>IT Project Management &amp; Execution</th>\n",
       "      <th>Information Retrieval &amp; Web Analytics</th>\n",
       "      <th>...</th>\n",
       "      <th>Operating Systems &amp; System Administration</th>\n",
       "      <th>Problem Solving &amp; Algorithm Development</th>\n",
       "      <th>Professionalism &amp; Workplace Readiness</th>\n",
       "      <th>Programming Fundamentals &amp; C Language</th>\n",
       "      <th>Software Development &amp; Engineering Practices</th>\n",
       "      <th>Software Development Processes</th>\n",
       "      <th>Statistical Analysis &amp; Data Interpretation</th>\n",
       "      <th>Statistical Modeling &amp; Data Analysis</th>\n",
       "      <th>Web Development &amp; Internet Technologies</th>\n",
       "      <th>role_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ai_ml_engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Academic Communication Skills  Advanced Database Design & Management  \\\n",
       "0                              0                                      0   \n",
       "1                              0                                      0   \n",
       "2                              0                                      0   \n",
       "3                              0                                      0   \n",
       "4                              0                                      0   \n",
       "\n",
       "   Computer Systems & Networking  Data Engineering & BI Analytics  \\\n",
       "0                              0                                1   \n",
       "1                              0                                0   \n",
       "2                              0                                0   \n",
       "3                              0                                0   \n",
       "4                              0                                0   \n",
       "\n",
       "   Database Administration & Storage  Database Design & Administration  \\\n",
       "0                                  0                                 1   \n",
       "1                                  0                                 0   \n",
       "2                                  0                                 0   \n",
       "3                                  0                                 1   \n",
       "4                                  0                                 0   \n",
       "\n",
       "   Employability & Workplace Readiness  \\\n",
       "0                                    1   \n",
       "1                                    1   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    0   \n",
       "\n",
       "   Full-Stack Web Application Development  IT Project Management & Execution  \\\n",
       "0                                       1                                  0   \n",
       "1                                       0                                  0   \n",
       "2                                       0                                  0   \n",
       "3                                       0                                  0   \n",
       "4                                       0                                  0   \n",
       "\n",
       "   Information Retrieval & Web Analytics  ...  \\\n",
       "0                                      0  ...   \n",
       "1                                      0  ...   \n",
       "2                                      0  ...   \n",
       "3                                      0  ...   \n",
       "4                                      0  ...   \n",
       "\n",
       "   Operating Systems & System Administration  \\\n",
       "0                                          1   \n",
       "1                                          1   \n",
       "2                                          1   \n",
       "3                                          1   \n",
       "4                                          0   \n",
       "\n",
       "   Problem Solving & Algorithm Development  \\\n",
       "0                                        1   \n",
       "1                                        1   \n",
       "2                                        1   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   Professionalism & Workplace Readiness  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "\n",
       "   Programming Fundamentals & C Language  \\\n",
       "0                                      1   \n",
       "1                                      1   \n",
       "2                                      1   \n",
       "3                                      1   \n",
       "4                                      1   \n",
       "\n",
       "   Software Development & Engineering Practices  \\\n",
       "0                                             1   \n",
       "1                                             1   \n",
       "2                                             1   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   Software Development Processes  Statistical Analysis & Data Interpretation  \\\n",
       "0                               1                                           0   \n",
       "1                               0                                           0   \n",
       "2                               0                                           0   \n",
       "3                               0                                           0   \n",
       "4                               0                                           0   \n",
       "\n",
       "   Statistical Modeling & Data Analysis  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "3                                     0   \n",
       "4                                     0   \n",
       "\n",
       "   Web Development & Internet Technologies        role_key  \n",
       "0                                        1  ai_ml_engineer  \n",
       "1                                        0  ai_ml_engineer  \n",
       "2                                        0  ai_ml_engineer  \n",
       "3                                        0  ai_ml_engineer  \n",
       "4                                        0  ai_ml_engineer  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coverage checks and statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COVERAGE STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Non-zero feature columns count\n",
    "non_zero_cols = (X.sum(axis=0) > 0).sum()\n",
    "print(f\"\\nNon-zero feature columns: {non_zero_cols} / {len(all_parent_skills)}\")\n",
    "\n",
    "# Jobs with at least 1 mapped parent skill\n",
    "jobs_with_skills = (X.sum(axis=1) > 0).sum()\n",
    "percent_with_skills = (jobs_with_skills / len(X)) * 100\n",
    "print(f\"Jobs with ≥1 mapped parent skill: {jobs_with_skills} / {len(X)} ({percent_with_skills:.1f}%)\")\n",
    "\n",
    "# Average mapped parent skills per job\n",
    "avg_skills_per_job = X.sum(axis=1).mean()\n",
    "print(f\"Average mapped parent skills per job: {avg_skills_per_job:.2f}\")\n",
    "\n",
    "# Top 10 active parent skills by total count\n",
    "parent_skill_counts = X.sum(axis=0).sort_values(ascending=False)\n",
    "print(f\"\\nTop 10 active parent skills by total count:\")\n",
    "for idx, (skill, count) in enumerate(parent_skill_counts.head(10).items(), 1):\n",
    "    print(f\"  {idx:2d}. {skill:50s} ({int(count):4d} jobs)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Combine X and y into final dataset\n",
    "final_df = X.copy()\n",
    "final_df['role_key'] = y.values\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/job_parent_skill_features.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n✓ Saved feature matrix to: {output_path}\")\n",
    "print(f\"  - Shape: {final_df.shape}\")\n",
    "print(f\"  - Columns: {len(final_df.columns)} ({len(all_parent_skills)} features + 1 target)\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b185f",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "\n",
    "Train and evaluate multiclass classification models to predict role_key from parent skill features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (numpy<2.4 for SHAP/numba compatibility)\n",
    "# Note: After running this cell, restart the kernel before continuing\n",
    "%pip install --force-reinstall \"numpy<2.4\" scikit-learn shap joblib scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dc5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported and models directory ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\OneDrive - Sri Lanka Institute of Information Technology\\Research\\Transcript-Based-Skill-Validation-Quiz\\Transcript-Based-Skill-Validation-Quiz\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import shap\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "print(\"✓ Libraries imported and models directory ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac94721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: (175, 28)\n",
      "\n",
      "Features shape: (175, 27)\n",
      "Target classes: ['ai_ml_engineer' 'data_analyst' 'data_engineer' 'devops_engineer'\n",
      " 'software_engineer' 'web_developer']\n",
      "Class distribution:\n",
      "role_key\n",
      "software_engineer    40\n",
      "data_analyst         34\n",
      "ai_ml_engineer       30\n",
      "data_engineer        30\n",
      "devops_engineer      30\n",
      "web_developer        11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the feature matrix\n",
    "data = pd.read_csv('../data/job_parent_skill_features.csv')\n",
    "print(f\"Loaded data: {data.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('role_key', axis=1)\n",
    "y = data['role_key']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target classes: {label_encoder.classes_}\")\n",
    "print(f\"Class distribution:\\n{pd.Series(y).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7824e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation functions\n",
    "def top_k_accuracy(y_true, y_proba, k=3):\n",
    "    \"\"\"Calculate top-k accuracy\"\"\"\n",
    "    top_k_preds = np.argsort(y_proba, axis=1)[:, -k:]\n",
    "    correct = sum([y_true[i] in top_k_preds[i] for i in range(len(y_true))])\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Evaluate a model and return metrics\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_proba = model.predict_proba(X_val)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    top3 = top_k_accuracy(y_val, y_proba, k=3)\n",
    "    \n",
    "    return acc, f1, top3\n",
    "\n",
    "print(\"✓ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c47c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models defined:\n",
      "  - LogisticRegression\n",
      "  - RandomForest\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(max_iter=5000, solver='lbfgs', class_weight='balanced', random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=400, \n",
    "        random_state=42, \n",
    "        class_weight='balanced_subsample'\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Models defined:\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47928efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training: LogisticRegression\n",
      "============================================================\n",
      "  Fold 1: Acc=0.5143, F1=0.4717, Top-3=0.8286\n",
      "  Fold 2: Acc=0.5714, F1=0.5239, Top-3=0.9143\n",
      "  Fold 3: Acc=0.6571, F1=0.6252, Top-3=0.9714\n",
      "  Fold 4: Acc=0.4857, F1=0.4524, Top-3=0.8857\n",
      "  Fold 5: Acc=0.5143, F1=0.4890, Top-3=0.8571\n",
      "\n",
      "  MEAN RESULTS:\n",
      "    Accuracy:  0.5486 ± 0.0610\n",
      "    Macro F1:  0.5124 ± 0.0611\n",
      "    Top-3 Acc: 0.8914 ± 0.0492\n",
      "\n",
      "============================================================\n",
      "Training: RandomForest\n",
      "============================================================\n",
      "  Fold 1: Acc=0.5143, F1=0.4285, Top-3=0.9143\n",
      "  Fold 2: Acc=0.6857, F1=0.6026, Top-3=1.0000\n",
      "  Fold 3: Acc=0.7429, F1=0.6440, Top-3=0.8857\n",
      "  Fold 4: Acc=0.6857, F1=0.5817, Top-3=0.9429\n",
      "  Fold 5: Acc=0.5143, F1=0.4205, Top-3=0.9143\n",
      "\n",
      "  MEAN RESULTS:\n",
      "    Accuracy:  0.6286 ± 0.0956\n",
      "    Macro F1:  0.5355 ± 0.0928\n",
      "    Top-3 Acc: 0.9314 ± 0.0388\n",
      "\n",
      "============================================================\n",
      "Cross-validation complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform 5-fold stratified cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training: {model_name}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    fold_results = {'accuracy': [], 'macro_f1': [], 'top3_acc': []}\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "        \n",
    "        acc, f1, top3 = evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        fold_results['accuracy'].append(acc)\n",
    "        fold_results['macro_f1'].append(f1)\n",
    "        fold_results['top3_acc'].append(top3)\n",
    "        \n",
    "        print(f\"  Fold {fold}: Acc={acc:.4f}, F1={f1:.4f}, Top-3={top3:.4f}\")\n",
    "    \n",
    "    # Calculate means\n",
    "    mean_acc = np.mean(fold_results['accuracy'])\n",
    "    mean_f1 = np.mean(fold_results['macro_f1'])\n",
    "    mean_top3 = np.mean(fold_results['top3_acc'])\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'mean_accuracy': mean_acc,\n",
    "        'mean_macro_f1': mean_f1,\n",
    "        'mean_top3_acc': mean_top3,\n",
    "        'fold_results': fold_results\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  MEAN RESULTS:\")\n",
    "    print(f\"    Accuracy:  {mean_acc:.4f} ± {np.std(fold_results['accuracy']):.4f}\")\n",
    "    print(f\"    Macro F1:  {mean_f1:.4f} ± {np.std(fold_results['macro_f1']):.4f}\")\n",
    "    print(f\"    Top-3 Acc: {mean_top3:.4f} ± {np.std(fold_results['top3_acc']):.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Cross-validation complete!\")\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfc25429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BEST MODEL: RandomForest\n",
      "============================================================\n",
      "  Mean Accuracy:  0.6286\n",
      "  Mean Macro F1:  0.5355\n",
      "  Mean Top-3 Acc: 0.9314\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Select best model based on Macro F1, break ties with Top-3 accuracy\n",
    "best_model_name = None\n",
    "best_f1 = -1\n",
    "best_top3 = -1\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    if metrics['mean_macro_f1'] > best_f1:\n",
    "        best_f1 = metrics['mean_macro_f1']\n",
    "        best_top3 = metrics['mean_top3_acc']\n",
    "        best_model_name = model_name\n",
    "    elif metrics['mean_macro_f1'] == best_f1 and metrics['mean_top3_acc'] > best_top3:\n",
    "        best_top3 = metrics['mean_top3_acc']\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print('='*60)\n",
    "print(f\"  Mean Accuracy:  {results[best_model_name]['mean_accuracy']:.4f}\")\n",
    "print(f\"  Mean Macro F1:  {results[best_model_name]['mean_macro_f1']:.4f}\")\n",
    "print(f\"  Mean Top-3 Acc: {results[best_model_name]['mean_top3_acc']:.4f}\")\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab834dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest on full dataset...\n",
      "✓ Saved model to: ../models/role_model.pkl\n",
      "✓ Saved 27 feature columns to: ../models/feature_columns.json\n",
      "✓ Saved role labels mapping to: ../models/role_labels.json\n",
      "  Role mapping: {0: 'ai_ml_engineer', 1: 'data_analyst', 2: 'data_engineer', 3: 'devops_engineer', 4: 'software_engineer', 5: 'web_developer'}\n"
     ]
    }
   ],
   "source": [
    "# Train best model on full dataset\n",
    "print(f\"\\nTraining {best_model_name} on full dataset...\")\n",
    "best_model = models[best_model_name]\n",
    "best_model.fit(X, y_encoded)\n",
    "\n",
    "# Save model\n",
    "model_path = '../models/role_model.pkl'\n",
    "joblib.dump(best_model, model_path)\n",
    "print(f\"✓ Saved model to: {model_path}\")\n",
    "\n",
    "# Save feature columns\n",
    "feature_columns = X.columns.tolist()\n",
    "with open('../models/feature_columns.json', 'w') as f:\n",
    "    json.dump(feature_columns, f, indent=2)\n",
    "print(f\"✓ Saved {len(feature_columns)} feature columns to: ../models/feature_columns.json\")\n",
    "\n",
    "# Save role labels mapping\n",
    "role_labels = {int(i): label for i, label in enumerate(label_encoder.classes_)}\n",
    "with open('../models/role_labels.json', 'w') as f:\n",
    "    json.dump(role_labels, f, indent=2)\n",
    "print(f\"✓ Saved role labels mapping to: ../models/role_labels.json\")\n",
    "print(f\"  Role mapping: {role_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dc00199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved role prototypes to: ../models/role_prototypes.csv\n",
      "  Shape: (6, 27)\n",
      "\n",
      "Role Prototypes (sample):\n",
      "                   Academic Communication Skills  \\\n",
      "role_key                                           \n",
      "ai_ml_engineer                               0.0   \n",
      "data_analyst                                 0.0   \n",
      "data_engineer                                0.0   \n",
      "devops_engineer                              0.0   \n",
      "software_engineer                            0.0   \n",
      "\n",
      "                   Advanced Database Design & Management  \\\n",
      "role_key                                                   \n",
      "ai_ml_engineer                                       0.0   \n",
      "data_analyst                                         0.0   \n",
      "data_engineer                                        0.0   \n",
      "devops_engineer                                      0.0   \n",
      "software_engineer                                    0.0   \n",
      "\n",
      "                   Computer Systems & Networking  \\\n",
      "role_key                                           \n",
      "ai_ml_engineer                               0.0   \n",
      "data_analyst                                 0.0   \n",
      "data_engineer                                0.0   \n",
      "devops_engineer                              0.0   \n",
      "software_engineer                            0.0   \n",
      "\n",
      "                   Data Engineering & BI Analytics  \\\n",
      "role_key                                             \n",
      "ai_ml_engineer                            0.066667   \n",
      "data_analyst                              0.647059   \n",
      "data_engineer                             0.600000   \n",
      "devops_engineer                           0.033333   \n",
      "software_engineer                         0.100000   \n",
      "\n",
      "                   Database Administration & Storage  \\\n",
      "role_key                                               \n",
      "ai_ml_engineer                                   0.0   \n",
      "data_analyst                                     0.0   \n",
      "data_engineer                                    0.0   \n",
      "devops_engineer                                  0.0   \n",
      "software_engineer                                0.0   \n",
      "\n",
      "                   Database Design & Administration  \\\n",
      "role_key                                              \n",
      "ai_ml_engineer                             0.233333   \n",
      "data_analyst                               0.735294   \n",
      "data_engineer                              0.700000   \n",
      "devops_engineer                            0.000000   \n",
      "software_engineer                          0.300000   \n",
      "\n",
      "                   Employability & Workplace Readiness  \\\n",
      "role_key                                                 \n",
      "ai_ml_engineer                                0.333333   \n",
      "data_analyst                                  0.382353   \n",
      "data_engineer                                 0.433333   \n",
      "devops_engineer                               0.333333   \n",
      "software_engineer                             0.375000   \n",
      "\n",
      "                   Full-Stack Web Application Development  \\\n",
      "role_key                                                    \n",
      "ai_ml_engineer                                   0.133333   \n",
      "data_analyst                                     0.029412   \n",
      "data_engineer                                    0.000000   \n",
      "devops_engineer                                  0.033333   \n",
      "software_engineer                                0.400000   \n",
      "\n",
      "                   IT Project Management & Execution  \\\n",
      "role_key                                               \n",
      "ai_ml_engineer                                   0.0   \n",
      "data_analyst                                     0.0   \n",
      "data_engineer                                    0.0   \n",
      "devops_engineer                                  0.0   \n",
      "software_engineer                                0.0   \n",
      "\n",
      "                   Information Retrieval & Web Analytics  ...  \\\n",
      "role_key                                                  ...   \n",
      "ai_ml_engineer                                       0.0  ...   \n",
      "data_analyst                                         0.0  ...   \n",
      "data_engineer                                        0.0  ...   \n",
      "devops_engineer                                      0.0  ...   \n",
      "software_engineer                                    0.0  ...   \n",
      "\n",
      "                   Object-Oriented Design & Programming  \\\n",
      "role_key                                                  \n",
      "ai_ml_engineer                                 0.133333   \n",
      "data_analyst                                   0.000000   \n",
      "data_engineer                                  0.200000   \n",
      "devops_engineer                                0.200000   \n",
      "software_engineer                              0.250000   \n",
      "\n",
      "                   Operating Systems & System Administration  \\\n",
      "role_key                                                       \n",
      "ai_ml_engineer                                      0.566667   \n",
      "data_analyst                                        0.117647   \n",
      "data_engineer                                       0.566667   \n",
      "devops_engineer                                     0.800000   \n",
      "software_engineer                                   0.425000   \n",
      "\n",
      "                   Problem Solving & Algorithm Development  \\\n",
      "role_key                                                     \n",
      "ai_ml_engineer                                    0.333333   \n",
      "data_analyst                                      0.382353   \n",
      "data_engineer                                     0.266667   \n",
      "devops_engineer                                   0.366667   \n",
      "software_engineer                                 0.275000   \n",
      "\n",
      "                   Professionalism & Workplace Readiness  \\\n",
      "role_key                                                   \n",
      "ai_ml_engineer                                  0.533333   \n",
      "data_analyst                                    0.588235   \n",
      "data_engineer                                   0.433333   \n",
      "devops_engineer                                 0.366667   \n",
      "software_engineer                               0.450000   \n",
      "\n",
      "                   Programming Fundamentals & C Language  \\\n",
      "role_key                                                   \n",
      "ai_ml_engineer                                  0.866667   \n",
      "data_analyst                                    0.529412   \n",
      "data_engineer                                   0.733333   \n",
      "devops_engineer                                 0.733333   \n",
      "software_engineer                               0.350000   \n",
      "\n",
      "                   Software Development & Engineering Practices  \\\n",
      "role_key                                                          \n",
      "ai_ml_engineer                                         0.266667   \n",
      "data_analyst                                           0.000000   \n",
      "data_engineer                                          0.366667   \n",
      "devops_engineer                                        0.466667   \n",
      "software_engineer                                      0.275000   \n",
      "\n",
      "                   Software Development Processes  \\\n",
      "role_key                                            \n",
      "ai_ml_engineer                           0.266667   \n",
      "data_analyst                             0.088235   \n",
      "data_engineer                            0.400000   \n",
      "devops_engineer                          1.000000   \n",
      "software_engineer                        0.425000   \n",
      "\n",
      "                   Statistical Analysis & Data Interpretation  \\\n",
      "role_key                                                        \n",
      "ai_ml_engineer                                            0.0   \n",
      "data_analyst                                              0.0   \n",
      "data_engineer                                             0.0   \n",
      "devops_engineer                                           0.0   \n",
      "software_engineer                                         0.0   \n",
      "\n",
      "                   Statistical Modeling & Data Analysis  \\\n",
      "role_key                                                  \n",
      "ai_ml_engineer                                      0.0   \n",
      "data_analyst                                        0.0   \n",
      "data_engineer                                       0.0   \n",
      "devops_engineer                                     0.0   \n",
      "software_engineer                                   0.0   \n",
      "\n",
      "                   Web Development & Internet Technologies  \n",
      "role_key                                                    \n",
      "ai_ml_engineer                                    0.133333  \n",
      "data_analyst                                      0.000000  \n",
      "data_engineer                                     0.066667  \n",
      "devops_engineer                                   0.066667  \n",
      "software_engineer                                 0.475000  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Compute role prototypes for skill gap analysis\n",
    "# Group by role_key and compute mean of each feature\n",
    "role_prototypes = data.groupby('role_key')[feature_columns].mean()\n",
    "\n",
    "# Save role prototypes\n",
    "prototypes_path = '../models/role_prototypes.csv'\n",
    "role_prototypes.to_csv(prototypes_path)\n",
    "print(f\"\\n✓ Saved role prototypes to: {prototypes_path}\")\n",
    "print(f\"  Shape: {role_prototypes.shape}\")\n",
    "print(f\"\\nRole Prototypes (sample):\")\n",
    "print(role_prototypes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff72f8d2",
   "metadata": {},
   "source": [
    "## SHAP Analysis for Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e59a519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating SHAP explainer for RandomForest...\n",
      "✓ SHAP values computed\n",
      "  SHAP values shape: (175, 27, 6)\n"
     ]
    }
   ],
   "source": [
    "# Create SHAP explainer based on model type\n",
    "print(f\"\\nCreating SHAP explainer for {best_model_name}...\")\n",
    "\n",
    "if best_model_name == 'LogisticRegression':\n",
    "    # For LogisticRegression pipeline, need to transform data first\n",
    "    X_transformed = best_model.named_steps['scaler'].transform(X)\n",
    "    explainer = shap.LinearExplainer(best_model.named_steps['clf'], X_transformed)\n",
    "    shap_values = explainer.shap_values(X_transformed)\n",
    "else:  # RandomForest\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "\n",
    "print(f\"✓ SHAP values computed\")\n",
    "print(f\"  SHAP values shape: {np.array(shap_values).shape if isinstance(shap_values, list) else shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c9ebc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing global SHAP importance...\n",
      "✓ Saved global SHAP importance to: ../models/shap_global_importance.csv\n",
      "\n",
      "Top 5 features per role (by mean absolute SHAP):\n",
      "\n",
      "  ai_ml_engineer:\n",
      "    Machine Learning & Optimization: 0.0941\n",
      "    Programming Fundamentals & C Language: 0.0619\n",
      "    Data Engineering & BI Analytics: 0.0458\n",
      "    Operating Systems & System Administration: 0.0379\n",
      "    Software Development Processes: 0.0323\n",
      "\n",
      "  data_analyst:\n",
      "    Data Engineering & BI Analytics: 0.0781\n",
      "    Database Design & Administration: 0.0598\n",
      "    Operating Systems & System Administration: 0.0542\n",
      "    Networking & Protocol Management: 0.0466\n",
      "    Software Development Processes: 0.0420\n",
      "\n",
      "  data_engineer:\n",
      "    Data Engineering & BI Analytics: 0.0587\n",
      "    Database Design & Administration: 0.0493\n",
      "    Full-Stack Web Application Development: 0.0279\n",
      "    Programming Fundamentals & C Language: 0.0263\n",
      "    Professionalism & Workplace Readiness: 0.0254\n",
      "\n",
      "  devops_engineer:\n",
      "    Networking & Protocol Management: 0.1247\n",
      "    Software Development Processes: 0.0697\n",
      "    Database Design & Administration: 0.0640\n",
      "    Machine Learning & Optimization: 0.0368\n",
      "    Data Engineering & BI Analytics: 0.0324\n",
      "\n",
      "  software_engineer:\n",
      "    Networking & Protocol Management: 0.0520\n",
      "    Web Development & Internet Technologies: 0.0427\n",
      "    Full-Stack Web Application Development: 0.0397\n",
      "    Machine Learning & Optimization: 0.0379\n",
      "    Programming Fundamentals & C Language: 0.0363\n",
      "\n",
      "  web_developer:\n",
      "    Programming Fundamentals & C Language: 0.0449\n",
      "    Full-Stack Web Application Development: 0.0328\n",
      "    Web Development & Internet Technologies: 0.0281\n",
      "    Data Engineering & BI Analytics: 0.0244\n",
      "    Machine Learning & Optimization: 0.0237\n"
     ]
    }
   ],
   "source": [
    "# Compute global importance: mean(abs(shap_values)) per feature and class\n",
    "print(\"\\nComputing global SHAP importance...\")\n",
    "\n",
    "# Handle different SHAP value formats\n",
    "# TreeExplainer returns 3D array: (samples, features, classes)\n",
    "# LinearExplainer returns list of 2D arrays: [(samples, features) for each class]\n",
    "if isinstance(shap_values, list):\n",
    "    # List format from LinearExplainer\n",
    "    num_classes = len(shap_values)\n",
    "    global_importance_data = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        class_shap = shap_values[class_idx]\n",
    "        mean_abs_shap = np.abs(class_shap).mean(axis=0)\n",
    "        \n",
    "        for feat_idx, feat_name in enumerate(feature_columns):\n",
    "            global_importance_data.append({\n",
    "                'role_key': label_encoder.classes_[class_idx],\n",
    "                'feature': feat_name,\n",
    "                'mean_abs_shap': float(mean_abs_shap[feat_idx])\n",
    "            })\n",
    "elif len(shap_values.shape) == 3:\n",
    "    # 3D array format from TreeExplainer: (samples, features, classes)\n",
    "    num_classes = shap_values.shape[2]\n",
    "    global_importance_data = []\n",
    "    \n",
    "    for class_idx in range(num_classes):\n",
    "        # Extract SHAP values for this class across all samples and features\n",
    "        class_shap = shap_values[:, :, class_idx]\n",
    "        mean_abs_shap = np.abs(class_shap).mean(axis=0)\n",
    "        \n",
    "        for feat_idx, feat_name in enumerate(feature_columns):\n",
    "            global_importance_data.append({\n",
    "                'role_key': label_encoder.classes_[class_idx],\n",
    "                'feature': feat_name,\n",
    "                'mean_abs_shap': float(mean_abs_shap[feat_idx])\n",
    "            })\n",
    "else:\n",
    "    # 2D array for binary classification\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    global_importance_data = []\n",
    "    \n",
    "    for feat_idx, feat_name in enumerate(feature_columns):\n",
    "        global_importance_data.append({\n",
    "            'role_key': 'all',\n",
    "            'feature': feat_name,\n",
    "            'mean_abs_shap': float(mean_abs_shap[feat_idx])\n",
    "        })\n",
    "\n",
    "# Save global importance\n",
    "global_importance_df = pd.DataFrame(global_importance_data)\n",
    "global_importance_path = '../models/shap_global_importance.csv'\n",
    "global_importance_df.to_csv(global_importance_path, index=False)\n",
    "print(f\"✓ Saved global SHAP importance to: {global_importance_path}\")\n",
    "\n",
    "# Show top features per class\n",
    "print(\"\\nTop 5 features per role (by mean absolute SHAP):\")\n",
    "for role in label_encoder.classes_:\n",
    "    role_data = global_importance_df[global_importance_df['role_key'] == role].nlargest(5, 'mean_abs_shap')\n",
    "    print(f\"\\n  {role}:\")\n",
    "    for _, row in role_data.iterrows():\n",
    "        print(f\"    {row['feature']}: {row['mean_abs_shap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87bd1847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing local SHAP explanation for sample instance...\n",
      "✓ Saved local SHAP example to: ../models/shap_local_example.csv\n",
      "  Sample role: ai_ml_engineer\n",
      "\n",
      "Top contributors (positive):\n",
      "                                         feature  feature_value  shap_value\n",
      "7         Full-Stack Web Application Development              1    0.119289\n",
      "26       Web Development & Internet Technologies              1    0.096859\n",
      "22  Software Development & Engineering Practices              1    0.057697\n",
      "21         Programming Fundamentals & C Language              1    0.049684\n",
      "18     Operating Systems & System Administration              1    0.042840\n",
      "\n",
      "Top contributors (negative):\n",
      "                            feature  feature_value  shap_value\n",
      "13  Machine Learning & Optimization              0   -0.020448\n",
      "23   Software Development Processes              1   -0.015563\n"
     ]
    }
   ],
   "source": [
    "# Compute local explanation for one example\n",
    "print(\"\\nComputing local SHAP explanation for sample instance...\")\n",
    "\n",
    "# Pick first instance\n",
    "sample_idx = 0\n",
    "sample_X = X.iloc[sample_idx:sample_idx+1]\n",
    "sample_role = y.iloc[sample_idx]\n",
    "true_class_idx = y_encoded[sample_idx]\n",
    "\n",
    "# Get SHAP values for this sample\n",
    "if best_model_name == 'LogisticRegression':\n",
    "    sample_X_transformed = best_model.named_steps['scaler'].transform(sample_X)\n",
    "    if isinstance(shap_values, list):\n",
    "        # List format: get SHAP values for the true class\n",
    "        sample_shap = shap_values[true_class_idx][sample_idx]\n",
    "    else:\n",
    "        sample_shap = shap_values[sample_idx]\n",
    "else:  # RandomForest\n",
    "    if isinstance(shap_values, list):\n",
    "        # List format: get SHAP values for the true class\n",
    "        sample_shap = shap_values[true_class_idx][sample_idx]\n",
    "    elif len(shap_values.shape) == 3:\n",
    "        # 3D array format: extract for this sample and true class\n",
    "        sample_shap = shap_values[sample_idx, :, true_class_idx]\n",
    "    else:\n",
    "        # 2D format\n",
    "        sample_shap = shap_values[sample_idx]\n",
    "\n",
    "# Create DataFrame with features and SHAP values\n",
    "local_explanation = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'feature_value': sample_X.values[0],\n",
    "    'shap_value': sample_shap\n",
    "})\n",
    "\n",
    "# Sort by absolute SHAP value\n",
    "local_explanation['abs_shap'] = np.abs(local_explanation['shap_value'])\n",
    "local_explanation = local_explanation.sort_values('abs_shap', ascending=False)\n",
    "\n",
    "# Get top 10 positive and negative\n",
    "top_positive = local_explanation[local_explanation['shap_value'] > 0].head(10)\n",
    "top_negative = local_explanation[local_explanation['shap_value'] < 0].head(10)\n",
    "\n",
    "local_example = pd.concat([top_positive, top_negative])\n",
    "local_example['sample_role'] = sample_role\n",
    "\n",
    "# Save local example\n",
    "local_path = '../models/shap_local_example.csv'\n",
    "local_example.to_csv(local_path, index=False)\n",
    "print(f\"✓ Saved local SHAP example to: {local_path}\")\n",
    "print(f\"  Sample role: {sample_role}\")\n",
    "print(f\"\\nTop contributors (positive):\")\n",
    "print(top_positive[['feature', 'feature_value', 'shap_value']].head())\n",
    "print(f\"\\nTop contributors (negative):\")\n",
    "print(top_negative[['feature', 'feature_value', 'shap_value']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c96ebbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPLETE SUMMARY\n",
      "============================================================\n",
      "\n",
      "✓ Models Trained: 2\n",
      "\n",
      "  LogisticRegression:\n",
      "    Accuracy:  0.5486\n",
      "    Macro F1:  0.5124\n",
      "    Top-3 Acc: 0.8914\n",
      "\n",
      "  RandomForest:\n",
      "    Accuracy:  0.6286\n",
      "    Macro F1:  0.5355\n",
      "    Top-3 Acc: 0.9314\n",
      "\n",
      "✓ Selected Best Model: RandomForest\n",
      "\n",
      "✓ Artifacts Saved:\n",
      "    - ../models/role_model.pkl\n",
      "    - ../models/feature_columns.json\n",
      "    - ../models/role_labels.json\n",
      "    - ../models/role_prototypes.csv\n",
      "    - ../models/shap_global_importance.csv\n",
      "    - ../models/shap_local_example.csv\n",
      "\n",
      "============================================================\n",
      "Training and evaluation complete! 🎉\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPLETE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✓ Models Trained: {len(models)}\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"\\n  {name}:\")\n",
    "    print(f\"    Accuracy:  {metrics['mean_accuracy']:.4f}\")\n",
    "    print(f\"    Macro F1:  {metrics['mean_macro_f1']:.4f}\")\n",
    "    print(f\"    Top-3 Acc: {metrics['mean_top3_acc']:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ Selected Best Model: {best_model_name}\")\n",
    "print(f\"\\n✓ Artifacts Saved:\")\n",
    "print(f\"    - ../models/role_model.pkl\")\n",
    "print(f\"    - ../models/feature_columns.json\")\n",
    "print(f\"    - ../models/role_labels.json\")\n",
    "print(f\"    - ../models/role_prototypes.csv\")\n",
    "print(f\"    - ../models/shap_global_importance.csv\")\n",
    "print(f\"    - ../models/shap_local_example.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training and evaluation complete! 🎉\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
