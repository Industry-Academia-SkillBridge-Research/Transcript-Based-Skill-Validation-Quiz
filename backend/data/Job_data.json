[
  {
    "job_id": "lead-ai-ml-engineer-%2B-agent-orchestration-1m-lkr-p-m-at-codax-4324581179",
    "title": "Lead AI/ML Engineer + Agent Orchestration (1M LKR - P/m)",
    "company": "codax",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-26",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-ai-ml-engineer-%2B-agent-orchestration-1m-lkr-p-m-at-codax-4324581179?position=3&pageNum=0&refId=KC73ACcTRMwfdSvTpIXUqA%3D%3D&trackingId=%2Fmu5eLwMkttpwACDpSA0lQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.423993",
    "description": "Role: Lead AI/ML Engineer + Agent OrchestrationLocation: Colombo Type: Full-time | Founding Team Level | Mix of Salary + EquityReports to: Co-Founder & CTOAbout Orchestration by Codax Orchestration is redefining how marketing teams operate. We’re building a reasoning-driven agentic orchestration platform, where specialized AI agents collaborate to analyze data, make decisions, and execute marketing workflows autonomously.You’ll be the technical backbone turning this vision into a deployable product, working directly with our CTO (ex-Adobe) on architecture, orchestration frameworks, and model integration.What You’ll Build Core multi-agent orchestration layer (crewAI / LangGraph / AutoGen-style) for reasoning, coordination, and execution.Integration APIs connecting agents to marketing and analytics tools.Data pipelines enabling behavioral signal understanding and feedback loops.Lightweight frontend interface for orchestration visualization.Support MVP launch and scalability toward production.Key Skills5 + years in software engineering (Python + FastAPI + LangChain / LlamaIndex).Hands-on with agent frameworks, orchestration, or multi-agent reasoning systems.Understanding of Reinforcement Learning, RAG, or decision optimization.GCP, Docker, Pub/Sub, CI/CD pipelines.Bonus: marketing automation or personalisation system experience.Tech StackPython | FastAPI | LangChain | Postgres | Redis | GCP | Vertex AI | Next.js | Docker | KubernetesCompensationBase Salary: LKR 1,000,000 per month (≈ LKR 12 M annually)Equity: Equity options with a 1 Year CliffAdditional: Performance-based increments after funding roundWhy Join?Work directly with a CTO and founder team that have built large-scale personalisation and AI systems.Build the world’s first reasoning-based orchestration platform for marketing.Competitive pay + early equity in a global venture on track for rapid funding.Freedom to experiment, ship, and scale real agentic systems used by enterprise clients.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Marketing Services"
    },
    "skills": [
      "Python",
      "FastAPI",
      "LangChain",
      "LlamaIndex",
      "PostgreSQL",
      "Redis",
      "Google Cloud Platform",
      "Vertex AI",
      "Next.js",
      "Docker",
      "Kubernetes",
      "Pub/Sub",
      "CI/CD",
      "Reinforcement Learning",
      "RAG"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_001"
  },
  {
    "job_id": "machine-learning-engineer-python-ifs-loops-at-ifs-4337104017",
    "title": "Machine Learning Engineer (Python)- IFS Loops",
    "company": "IFS",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-20",
    "job_url": "https://lk.linkedin.com/jobs/view/machine-learning-engineer-python-ifs-loops-at-ifs-4337104017?position=5&pageNum=0&refId=9L3UPsxU14O6NdWtrF5%2BWQ%3D%3D&trackingId=v7ZV3jYO6MdN46xnoyQRrA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424007",
    "description": "IFS is a billion-dollar revenue company with 7000+ employees on all continents. Our leading AI technology is the backbone of our award-winning enterprise software solutions, enabling our customers to be their best when it really matters–at the Moment of Service™. Our commitment to internal AI adoption has allowed us to stay at the forefront of technological advancements, ensuring our colleagues can unlock their creativity and productivity, and our solutions are always cutting-edge.At IFS, we’re flexible, we’re innovative, and we’re focused not only on how we can engage with our customers but on how we can make a real change and have a worldwide impact. We help solve some of society’s greatest challenges, fostering a better future through our agility, collaboration, and trust.We celebrate diversity and understand our responsibility to reflect the diverse world we work in. We are committed to promoting an inclusive workforce that fully represents the many different cultures, backgrounds, and viewpoints of our customers, our partners, and our communities. As a truly international company serving people from around the globe, we realize that our success is tantamount to the respect we have for those different points of view.By joining our team, you will have the opportunity to be part of a global, diverse environment; you will be joining a winning team with a commitment to sustainability; and a company where we get things done so that you can make a positive impact on the world.We’re looking for innovative and original thinkers to work in an environment where you can #MakeYourMoment so that we can help others make theirs. With the power of our AI-driven solutions, we empower our team to change the status quo and make a real difference.If you want to change the status quo, we’ll help you make your moment. Join Team Purple. Join IFS.Job DescriptionWe are looking for a motivated Machine Learning Engineer (Python) to join our fast-moving team. This is a hands-on role ideal for someone with a solid foundation in machine learning, strong Python skills, and a desire to grow in a dynamic and often ambiguous environment. You’ll work closely with product managers, data scientists, and engineers to rapidly prototype, test, and deploy ML-driven features and pipelines.What You’ll DoCollaborate in an agile team to develop and deploy ML models and data pipelines.Translate loosely defined business or customer requirements into practical ML solutions.Be creative and proactive in shaping solutions that solve real-world problems.Build, test, and optimize scalable Python-based systems for training and inference.Work with structured and unstructured data (e.g., tabular, text, image).Participate in sprint planning, daily stand-ups, and reviews.Own and maintain parts of the codebase and contribute to improving engineering best practices.QualificationsWhat We’re Looking For2–4 years of experience in software engineering or ML engineering roles.Strong Python programming skills with experience in ML frameworks like scikit-learn, TensorFlow, or PyTorch.Proficiency with data handling libraries (e.g., pandas, NumPy) and tools like Jupyter.Ability to take customer or business requirements and creatively turn them into technical solutions.Exposure to common ML workflows: data cleaning, feature engineering, model evaluation.Comfortable working in a fast-paced, agile environment with changing priorities and some ambiguity.Good communication and collaboration skills; you’re proactive and not afraid to ask questions.Familiarity with version control (e.g., Git) and containerization (e.g., Docker).Experience with cloud platforms (AWS, GCP, or Azure) and basic understanding of MLOps practices.Exposure to CI/CD workflows and tools like MLflow or model serving frameworks.Ability to build lightweight APIs (e.g., FastAPI, Flask) to expose models is a plus.Additional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Human Resources",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Flask",
      "FastAPI",
      "scikit-learn",
      "TensorFlow",
      "PyTorch",
      "Pandas",
      "NumPy",
      "Jupyter",
      "MLflow",
      "AWS",
      "Azure",
      "Google Cloud Platform",
      "Docker",
      "CI/CD",
      "Git",
      "MLOps"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_003"
  },
  {
    "job_id": "ai-engineer-at-heymilo-ai-4323227897",
    "title": "AI Engineer",
    "company": "HeyMilo AI",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/ai-engineer-at-heymilo-ai-4323227897?position=4&pageNum=0&refId=FOOV7J%2FXXMarHkqnsHJXxg%3D%3D&trackingId=jReULQohHT88WNCpEDFT0A%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424010",
    "description": "Location: Remote Sri LankaType: Full-TimeAt HeyMilo, we're redefining how companies recruit using Agentic AI to automate interviews, evaluate candidates, and scale intelligent hiring experiences.We're looking for an AI Engineer who's passionate about building next-generation AI systems that create real-world impact. If you love experimenting with LLMs, deploying AI pipelines, and pushing the boundaries of whats possible youll fit right in.What You'll DoWrite clean, scalable, and maintainable Python code that powers HeyMilo's AI-driven platform.Design, implement, and maintain FastAPI-based APIs to deliver intelligent, enterprise-grade AI services.Prototype and iterate rapidly, transforming new ideas into production-ready features.Experiment with LLMs and apply robust prompt engineering to minimize hallucinations and improve performance.Build and optimize Retrieval-Augmented Generation (RAG), contextual search, and AI workflow pipelines.Fine-tune, deploy, and optimize deep learning models for NLP and computer vision applications.Research emerging AI tools, frameworks, and research adopting them to enhance HeyMilo as a product.Develop observability and AI content auditing systems to ensure reliability, transparency, and continuous improvement.Who You AreStrong in Python, with hands-on experience in FastAPI.Deep understanding of LLMs, prompt engineering, and AI infrastructure.Proven experience with Agentic AI frameworks, data pipelines, and asynchronous systems.A fast learner curious, adaptable, and always exploring the frontier of AI innovation.Solid computer science fundamentals and a problem-solving mindset that thrives in a fast-paced, startup environment.Why Join HeyMiloWork on cutting-edge AI technologies shaping the future of recruiting.Collaborate with world-class engineers from Instagram, Salesforce, Uber, and Meta.High ownership, high impact build, ship, and see your work in action fast.Competitive compensation, strong performance-based rewards, and a culture that values curiosity, speed, and excellence.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "FastAPI",
      "LLM",
      "RAG",
      "NLP",
      "Deep Learning",
      "Data Pipelines",
      "AI Infrastructure"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_005"
  },
  {
    "job_id": "full-stack-ai-application-engineer-at-prismetic-4347234085",
    "title": "Full-Stack AI Application Engineer",
    "company": "PRISMETIC",
    "location": "Sri Lanka",
    "posted_date": "2025-11-22",
    "job_url": "https://lk.linkedin.com/jobs/view/full-stack-ai-application-engineer-at-prismetic-4347234085?position=12&pageNum=0&refId=FOOV7J%2FXXMarHkqnsHJXxg%3D%3D&trackingId=x7eA1mwlgn%2F8%2Fh06M2BwIw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424011",
    "description": "Join Our AI Innovation Team as a Full-Stack AI Application EngineerABOUT PRISMETICWe are a fast-moving, AI-native startup on a mission to redefine how businesses interact with and extract value from frontier AI technologies. In the rapidly evolving AI landscape, we move quickly, prioritize elegant engineering, and empower our team members to take ownership of significant features from concept to production. If you thrive in an environment where your code directly translates into intelligent, user-facing applications, we want to talk to you.The Role: Full-Stack AI Application EngineerWe are seeking a highly skilled and versatile Full-Stack AI Application Engineer to design, build, and deploy our core AI-powered products. This is a critical, hands-on role requiring expertise across the entire application stack, from foundational cloud infrastructure and robust backend services to scalable, delightful user interfaces.You will be the architect and builder of applications that leverage the cutting edge of commercial and proprietary AI models.What You'll DoEnd-to-End Ownership: Take full ownership of product features, from initial technical design and architecture to development, deployment, and monitoring in a production environment.AI Application Development: Architect and build high-performance, scalable applications that deeply integrate with Large Language Models (LLMs) and other AI services (e.g., embeddings, vision).Cloud Agnostic Implementation: Deploy and manage services using leading cloud platforms, ensuring reliability and cost-efficiency.Full-Stack Engineering:Backend: Design and implement robust, secure, and scalable APIs and services, primarily using Python.Frontend: Develop modern, responsive, and intuitive user interfaces using a contemporary framework (e.g., React, Vue, or similar) to showcase AI capabilities.Tooling and Infrastructure: Select, integrate, and optimize the appropriate tools for data handling, model serving, vector databases, and application security.Collaboration: Work closely with Product Managers and AI/ML Scientists to translate research and models into polished, production-ready features.What You'll Bring (Required Skills)Exceptional Python Proficiency: Deep, demonstrable expertise in building production-grade services and APIs using Python (e.g., FastAPI, Django, Flask).Full-Stack Experience: Proven experience as a Full-Stack Engineer, capable of tackling both frontend development (JavaScript/TypeScript and a modern framework) and backend architecture.Cloud Services Mastery: Demonstrated practical experience deploying and managing applications on at least two of the following major cloud platforms: AWS, GCP, or Azure. (Experience with serverless computing is a major plus.)AI/LLM Integration: Direct, hands-on experience integrating with leading AI/SaaS platforms like OpenAI (ChatGPT), Google Gemini, Anthropic, etc., to build complex, multi-step applications.System Design: Strong understanding of microservices architecture, asynchronous programming, database technologies (SQL/NoSQL), and software design patterns.Fluent English Communication: Excellent verbal and written English skills are required to collaborate effectively with product, engineering, and leadership teams.Bonus PointsFamiliarity with vector databases (e.g., Pinecone, Chroma, pgvector).Experience with workflow orchestration tools (e.g., Airflow, Prefect, KubeFlow)Why Join Us?Impact: Build the core technology that defines our company's success and shape the future of AI applications.Growth: Work alongside experienced founders and engineers in an environment committed to continuous learning and professional development.Ownership: We offer competitive compensation, including significant equity opportunities, ensuring you share directly in our success.Our Streamlined Hiring ProcessWe value your time and expertise. Our process is designed to be efficient, hands-on, and focused on real-world engineering skills.Application and Portfolio Review: Submit your resume and cover letter. We are looking for engineers who are enthusiastic about our mission and whose backgrounds align with the full-stack AI skills required.The Engineering Challenge (Coding Round): This isn't a theoretical exam. You will solve a practical problem relevant to our work by building a small, working Proof-of-Concept (POC). This step allows you to showcase your proficiency in Python, cloud integration, and full-stack development.Final Round with the Founders: A focused, high-level conversation with our leadership team. We'll discuss your technical approach to the challenge, your aspirations, and how you can contribute to our vision and culture at PRISMETIC.We aim to move quickly for the right candidate!Ready to build the next generation of AI apps? Apply today!Send your resume, cover letter and a link to your portfolio/GitHub to careers@prismetic.com #AI #FullStack #Python #AWS #GCP #Azure #GenerativeAI #Startup #Hiring #LLM #SoftwareEngineer",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "FastAPI",
      "Django",
      "Flask",
      "JavaScript",
      "TypeScript",
      "React",
      "SQL",
      "NoSQL",
      "AWS",
      "Google Cloud Platform",
      "Azure",
      "Serverless",
      "OpenAI",
      "Google Gemini",
      "Anthropic",
      "Microservices",
      "Asynchronous Programming",
      "Airflow",
      "Prefect",
      "KubeFlow",
      "Pinecone",
      "Chroma",
      "pgvector"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_008"
  },
  {
    "job_id": "senior-ai-augmented-software-engineer-at-dijital-team-4320712827",
    "title": "Senior AI-Augmented Software Engineer",
    "company": "Dijital Team",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-26",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-ai-augmented-software-engineer-at-dijital-team-4320712827?position=25&pageNum=0&refId=FOOV7J%2FXXMarHkqnsHJXxg%3D%3D&trackingId=hkPigub97Qj9dldPK8t8Ew%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424013",
    "description": "Our Tech Culture: Prefer developers who use AI tools like Cursor, GitHub Copilot, or similar to boost productivity and maintain code quality. Agile, async-friendly communication style. Focused on clean software architecture, automation, and fast iteration. Value transparency, quality, and continuous improvementResponsibilities:Ensure clean, maintainable, and well-tested code. Participate in sprint planning, code reviews, and stand-ups. Collaborate with designers to deliver UI that matches the intended UX. Identify performance issues and propose optimisations. Write and maintain automated tests to ensure long-term codebase quality. Experience/Role Requirements:4+ Years of strong experience building front-end applications with ReactJS and backend development with NodeJS for REST APIs Writing clean, scalable code in TypeScript (frontend and backend). Experience with GitHub for version control and collaboration. Bonus Points For:Knowledge of Azure, AWS, and Cloudflare services. Familiarity with Docker and basic containerization workflows. Experience with Agile delivery, using Jira and Confluence. Familiarity with modern CI/CD pipelines (e.g., GitHub Actions). Understanding of security best practices for web applications and APIs. Experience writing unit and integration tests (e.g., Jest, React Testing Library). Soft Skills: Strong communication (verbal and written) and interpersonal skills. You have excellent communication skills and can clearly articulate your ideas, designs, and suggestions. You are a strong team player who can collaborate effectively with different stakeholders. You’re a team player, who loves technology, sharing and communicating new ideas. Analytical thinker and problem solver. You pay strong attention to detail and have a keen eye for aesthetics You have a burning desire to constantly improve your skills, and you’re keen to pick up and learn new technologies. An analytical, yet creative, approach to problem solvingWe may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Transportation, Logistics, Supply Chain and Storage"
    },
    "skills": [
      "TypeScript",
      "React",
      "Node.js",
      "REST API",
      "GitHub",
      "Azure",
      "AWS",
      "Cloudflare",
      "Docker",
      "Containerization",
      "CI/CD",
      "GitHub Actions",
      "Jest",
      "Security",
      "APIs"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_009"
  },
  {
    "job_id": "machine-learning-engineer-l5-ads-at-netflix-4295854495",
    "title": "Machine Learning Engineer (L5) - Ads",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-11-12",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-l5-ads-at-netflix-4295854495?position=7&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=ZxZT1H2Wpw0vAq5OGvgT%2Bg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424015",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.In April 2022, we announced that we are creating a new lower-priced, ad-supported tier for our customers. We are now working toward our goal of providing more choice for consumers and a premium, better-than-linear TV brand experience for advertisers. That said, we are looking for the founding members of this new business area for Netflix!The mission of the GenAI Creative team in Ads DSE is to figure out how to leverage Generative AI to create a new class image and video ads at scale that are customized to the Netflix experience. The team is not only challenged with the task of creating high quality image and video ads with new technology, but also will need to figure out how to scale these workflows and build artists friendly tools around them.ResponsibilitiesWork with technical artists to figure out how to design and build a scalable system for creating generated image ads with style transfer.Finetune and customize open source image generation and editing models, and build systems to automate those workflows.Design algorithms and models to automate training data collection and curation.Setup and maintain model inference APIs and training pipelines.Build internal Generative AI apps for artists and creatives to use.Work with technical artists to design artist facing tools for image editing.Port ComfyUI workflows to APIs and webUIs.Stay up to date with the latest image generation and editing models and identify new opportunities.RequirementsExperience writing and deploying production Python code.Past computer vision experience.Nice To Have But Not RequiredExperience with open source image generation (ComfyUI, LoRA training)Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Python",
      "ComfyUI",
      "LoRA",
      "APIs",
      "Model Inference",
      "Computer Vision"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_019"
  },
  {
    "job_id": "machine-learning-engineer-at-emonics-llc-4324337386",
    "title": "Machine Learning Engineer",
    "company": "Emonics LLC",
    "location": "New York, United States",
    "posted_date": "2025-11-25",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-at-emonics-llc-4324337386?position=10&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=K1YwPJL4qT3Z%2FG5dgPxgnw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424017",
    "description": "Position Overview Emonics LLC is seeking an enthusiastic and motivated Entry-Level Machine Learning Engineer to join our growing data science team in Dallas, TX. The ideal candidate will have a foundational understanding of machine learning concepts, data analysis, and software development practices, with a strong desire to learn and grow within a dynamic and collaborative environment. Key Responsibilities Assist in developing, training, and deploying machine learning models and algorithms. Collaborate with data scientists and software engineers to collect, clean, and preprocess large datasets. Support the design and implementation of scalable data pipelines and ML workflows. Conduct model performance testing and optimize algorithms for accuracy and efficiency. Participate in code reviews, documentation, and version control practices. Stay up to date with emerging trends and tools in AI, ML, and data engineering. Required Qualifications Bachelor’s degree in Computer Science, Data Science, Statistics, Mathematics, or a related field. Basic knowledge of machine learning concepts (supervised, unsupervised learning, etc.). Proficiency in Python and familiarity with ML libraries such as scikit-learn, TensorFlow, or PyTorch. Understanding of data manipulation and analysis using Pandas, NumPy, or SQL. Strong analytical, problem-solving, and communication skills. Eagerness to learn new technologies and contribute to a team environment. Preferred Qualifications Exposure to cloud platforms (AWS, Azure, or GCP). Experience with version control systems (Git/GitHub). Knowledge of data visualization tools (Matplotlib, Seaborn, or Power BI). Internship or project experience in data science or machine learning. What We Offer Competitive entry-level salary and comprehensive benefits package. Professional development and mentorship opportunities. Collaborative and innovative work environment. Opportunities to work on real-world AI and ML projects that make an impact. How to Apply Interested candidates can apply by submitting their resume and a brief cover letter highlighting relevant coursework, projects, or experience to:",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Business Development, Consulting, and Information Technology",
      "Industries": "Staffing and Recruiting, Software Development, and Civil Engineering"
    },
    "skills": [
      "Python",
      "scikit-learn",
      "TensorFlow",
      "PyTorch",
      "Pandas",
      "NumPy",
      "SQL",
      "AWS",
      "Azure",
      "Google Cloud Platform",
      "Git",
      "GitHub",
      "Matplotlib",
      "Seaborn",
      "Power BI",
      "Data Pipelines",
      "ML Workflows"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_020"
  },
  {
    "job_id": "machine-learning-engineer-l4-production-science-at-netflix-4340536132",
    "title": "Machine Learning Engineer (L4) - Production Science",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-11-13",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-l4-production-science-at-netflix-4340536132?position=12&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=362MRJtd%2FPRa2QUOlrOsIQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424019",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.The Production Science team is part of the Data and Insights organization at Netflix. The team builds machine learning and analytics solutions to augment financial and operational decisions in the Netflix studio, supporting workflows like content planning, budgeting, scheduling, and financial forecasting. We are looking for an ML Engineer to help us develop, optimize and deploy models that directly integrate with internal workflows.ResponsibilitiesDesign, maintain, automate, and optimize ML training pipelines and realtime model serving infrastructure. Improve ML observability, model evaluations, model monitoring, and debugging tools to ensure reliability of deployed models. Collaborate closely with ML scientists and engineering teams to integrate deployed models into studio applications.Develop new ML solutions to extract information from studio artifacts like scripts, budgets, cost reports, and schedules.Stay up to date with ML infrastructure advancements, identifying new technologies and best practices to enhance efficiency. About YouYou have a strong foundation in machine learning, including supervised and unsupervised learning, and model evaluation.You have a track record of deploying performant and scalable data-intensive applications.You have a strong understanding of feature engineering, data pipelines, and model lifecycle management.You hold an advanced degree (MS or PhD) in Computer Science, Electrical Engineering, or a related technical field with a focus on machine learning, artificial intelligence or computer vision.You are proficient in Python and have experience with ML frameworks such as PyTorch, or Jax.You excel at complex problem solving with innovative solutions, developing novel algorithms, and adapting existing methods from literature to new challenges. You are an excellent communicator, capable of explaining complex technical details to both technical and non-technical audiences.You are highly collaborative and thrive in dynamic environments, contributing positively to the team and company culture.Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Python",
      "PyTorch",
      "Jax",
      "Machine Learning",
      "Feature Engineering",
      "Data Pipelines",
      "Model Serving",
      "Model Monitoring",
      "Computer Vision"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_021"
  },
  {
    "job_id": "machine-learning-engineer-l5-content-understanding-at-netflix-4241285593",
    "title": "Machine Learning Engineer (L5) - Content Understanding",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-11-24",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-l5-content-understanding-at-netflix-4241285593?position=14&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=uTA2noLkkMS4zf6Q9vwCIQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424021",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.The goal of our Content Understanding team is to enable operational and creative excellence in the distribution and promotion of our content on our service. We collaborate closely with our partners in the Product Discovery & Promotion organization, and our work directly contributes to launching high-quality content on our service and helps our members discover content they will love. We conduct analyses, build analytical tools, and develop models to help our partners execute on these primary objectives.We are looking for a talented machine learning engineer to join our Merchandising & Content Understanding pod, which focuses on deepening our content metadata across all formats and improving the discovery experience on our service. You will design and develop models and infrastructure for algorithms that will power the next generation of capabilities for our business. You will partner with our world-class team of creative production practitioners and various cross-functional teams to shape strategy and deliver impact via machine learning and artificial intelligence solutions. Interested? Read more about the job description and qualifications below!What You Will DoCollaborate closely with stakeholders in Product Discovery & Promotion to learn deeply about content metadata and merchandising and identify potentially impactful problems to solve via scalable machine learning and artificial intelligence solutionsDevelop innovative systems and models that empower decision-making for stakeholders and product features that can deliver member joy by leveraging a wide variety of metadata and production media generated by and collected from our productions throughout their end-to-end lifecycleCollaborate with team members and cross-functional partners to operationalize your models so that they can be integrated seamlessly into operational workflowsServe as a key thought partner for stakeholders, cross-functional partners, and our diverse set of team members regarding machine learning algorithms and system architecturesYour Background And CharacteristicsPh.D. or MS degree in a quantitative or computational field 4+ years of full-time work experience in one or more relevant machine-learning rolesPractical experience in supervised, unsupervised, and deep machine learning methodsPractical experience applying machine learning and Gen AI solutions to video, audio, and/or textual data sourcesPractical experience operationalizing or productionizing machine learning and/or artificial intelligence solutionsComfortable and effective in ambiguous problem spaces; ability to own and drive projects with minimal oversight and process Exceptional written and oral communication with technical and non-technical audiencesOur compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Machine Learning",
      "Deep Learning",
      "Artificial Intelligence",
      "Model Operationalization"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_022"
  },
  {
    "job_id": "machine-learning-engineer-at-bumble-inc-4314095829",
    "title": "Machine Learning Engineer",
    "company": "Bumble Inc.",
    "location": "Austin, TX",
    "posted_date": "2025-11-25",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-at-bumble-inc-4314095829?position=17&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=9re6VCivXS7Aph%2BLM9qOZw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424023",
    "description": "Inclusion at Bumble Inc. Bumble Inc. is an equal opportunity employer and we strongly encourage people of all ages, colour, lesbian, gay, bisexual, transgender, queer and non-binary people, veterans, parents, people with disabilities, and neurodivergent people to apply. We're happy to make any reasonable adjustments that will help you feel more confident throughout the process, please don't hesitate to let us know how we can help.In your application, please feel free to note which pronouns you use (For example: she/her, he/him, they/them, etc).As a Senior Machine Learning Engineer focused on scalability and productionisation, you will bring advanced machine learning models to life in production, from content understanding systems that interpret profiles, photos and text, to recommendation models that shape every match. You will build and scale the pipelines, infrastructure and automation that transform experimentation into reliable, high-impact features for our members.What you'll doDesign, build and optimise ML pipelines and production systems that train, evaluate and serve recommendation models efficiently and at scaleWork in a cross-functional team alongside data scientists, machine learning scientists, software engineers and both technical and non-technical stakeholdersPartner with ML Scientists to translate research models into efficient, maintainable, and well-tested production systemsImplement monitoring, observability, and retraining strategies to ensure continuous model performance in a dynamic, global environmentContribute to the evolution of our ML infrastructure, including CI/CD, model registries, and feature storesDiagnose and resolve production ML issues, such as data inconsistencies and model drift, to identify and resolve infrastructure bottlenecksChampion engineering best practices for scalability, reliability, and reproducibility across the ML lifecycleMinimum requirements2+ years of relevant industry experienceAn advanced degree in Computer Science, Mathematics or a similar quantitative disciplineStrong software engineering background. You write clean, scalable, and maintainable code in Python or similar languagesProven experience deploying and operating ML systems in production environmentsDeep understanding of MLOps and infrastructure concepts: CI/CD for ML, feature stores, model serving, observability, and versioningExperience with modern ML frameworks (e.g. PyTorch, TensorFlow) and orchestration tools (e.g. Airflow, Kubeflow, SageMaker, Ray)Familiarity with containerisation and cloud-native environments (e.g. Docker, Kubernetes, GCP/AWS)Skilled at debugging complex, distributed ML systems and optimising for performance at scaleExcellent communicator and collaborator. You communicate effectively with scientists, engineers, and non-technical stakeholdersInterested in contributing to the responsible development of ML and AI, with a focus on building systems that are fair, equitable and accountableWhy join usOwn meaningful projects that directly impact millions of Bumble usersLearn and grow in a high-performing engineering team committed to mentorship and learningBe part of a culture that values respect, excellence, curiosity, courage and joy. Enjoy competitive compensation, equity, and world-class benefitsLocationThis role is based in Austin, and we ask that you’re within a commutable distance to this office, so that you’re able to come onsite regularly to collaborate across engineering teams. We have a hybrid environment that requires you to be in the office Monday - Wednesday. Please note: We are unable to offer Visa sponsorship at this timeAbout UsBumble Inc. is the parent company of Bumble Date, BFF, and Badoo. The Bumble platform enables people to build healthy and equitable relationships, through Kind Connections. Founded by Whitney Wolfe Herd in 2014, Bumble was one of the first dating apps built with women at the center and connects people across dating (Bumble Date) and friendship (BFF). BFF is a friendship app where people in all stages of life can meet people nearby and create meaningful platonic connections and community based on shared interests. Badoo, which was founded in 2006, is one of the pioneers of web and mobile dating products. AI in Bumble Inc. Hiring At Bumble, we may use AI tools to support parts of our recruitment process — such as helping us record, transcribe, and summarize conversations, and supporting job alignment by comparing resumes and job descriptions to highlight skills and potential roles that may be a good match. These tools help us work more efficiently and stay focused on you during our conversations. Importantly, all hiring decisions are made by people. AI is used only to support our team’s efficiency and improve the candidate experience — not to evaluate or decide on your candidacy. Participation in AI-supported interviews and conversations is completely voluntary and will not impact your candidacy. If you’d prefer to opt out, simply let your recruiter or interviewer know at the start of a call, or anytime during the interview or conversation. Summaries and related data are retained only as long as needed in line with our internal data retention policies. If at any point you’d like a transcription or summary deleted, please contact your recruiter directly.For further information on how we hold and manage your data, please refer to our Privacy Policy.For base compensation, we set standard ranges for all roles based on function, level, and geographic location. This position is also typically eligible to participate in our short- and long-term incentive programs. Benefits include Medical, Dental, Vision, 401(k) match, Unlimited Paid Time Off Policy.Maven Fertility: $10,000 lifetime benefit for fertility, adoption, abortion care, and more.26 Weeks Parental Leave: For both primary and secondary caregivers.Family & Compassionate Leave: Inclusive of domestic violence recovery.Unlimited Paid Time Off: Take the time you need.Company-wide Week Off: Annual collective rest for the entire company.Focus Fridays: No meetings, emails, or deadlines—just deep work.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "TensorFlow",
      "PyTorch",
      "Airflow",
      "Kubeflow",
      "SageMaker",
      "Ray",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "MLOps",
      "Feature Stores",
      "Model Serving"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_023"
  },
  {
    "job_id": "machine-learning-engineer-ai-for-member-systems-at-netflix-4118831761",
    "title": "Machine Learning Engineer, AI for Member Systems",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-11-20",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-ai-for-member-systems-at-netflix-4118831761?position=20&pageNum=0&refId=wJWHXXNZJeJoLoJkhrQVQQ%3D%3D&trackingId=ay006%2FdQnWWP1qrG4E5BWw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424026",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.As Netflix continues to grow, so do the opportunities to enhance our personalization systems and algorithms. We're looking for a passionate and talented Machine Learning Engineer to join our Al for Member Systems. In this role, you will apply your expertise in machine learning and software engineering to design, develop, and scale solutions that power the Netflix experience.Key ResponsibilitiesCollaborate with cross-functional teams, including researchers, engineers, data scientists, and product managers, to develop and implement machine learning algorithms that improve personalization, recommendations, and member experiences.Create scalable, production-ready ML solutions, taking algorithms from initial concept through to deployment in Netflix's large-scale, real-time systems.Optimize the performance and scalability of machine learning models, ensuring they can handle the diverse tastes and behaviors of our global member base.Design and conduct offline experiments and A/B tests to validate the impact of algorithmic changes on key business metrics.Contribute to the ongoing improvement of our ML infrastructure and tooling, ensuring that we stay at the cutting edge of industry practices.Engage in continuous learning and development, staying up-to-date with the latest advances in machine learning and software engineering.What We Are Looking For5+ years of experience in applying machine learning in an industrial setting, with a track record of delivering impactful results.PhD or Masters in Computer Science, Statistics, or a related fieldExpertise in machine learning algorithms and frameworks, with hands-on experience in training, tuning, and deploying models in production environments.Excellent software design and development skills in Python along with Scala, Java, C++, or C#Experience in one or more of the following applied fields: Recommendations, Personalization, Long-term Reward Modeling, Bandits, Transformers, Large-Scale Language Models, LLM evaluation, RLHF reward modeling/alignmentGreat interpersonal skills including strong written and verbal communicationPreferred QualificationsExperience building or enhancing personalization systems, search engines, or similar large-scale machine learning applications.Background in neural networks, natural language processing, or causal inferenceContributions to open-source projects in machine learning or related fields.Experience working with cross functional teamsLinksNetflix Research siteOur cultureOur long term business viewOur compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $100,000 - $720,000.Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off.NOTE: This job posting is inclusive of a variety of positions within our AI for Member Systems (AIMS) Engineering group. Based on your background, expertise and interests, we will route you to the appropriate team(s). All teams may not be hiring at the same time.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Python",
      "Scala",
      "Java",
      "C++",
      "C#",
      "Machine Learning",
      "Transformers",
      "Large Language Models",
      "RLHF",
      "Neural Networks",
      "Natural Language Processing"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_024"
  },
  {
    "job_id": "ai-ml-engineer-at-chubb-4347318862",
    "title": "AI/ML Engineer",
    "company": "Chubb",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-25",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-chubb-4347318862?position=4&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=q5ECahwqhUxehL8KkgR83w%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424030",
    "description": "About ChubbChubb is a world leader in insurance. With operations in 54 countries and territories, Chubb provides commercial and personal property and casualty insurance, personal accident and supplemental health insurance, reinsurance and life insurance to a diverse group of clients. The company is defined by its extensive product and service offerings, broad distribution capabilities, exceptional financial strength and local operations globally. Parent company Chubb Limited is listed on the New York Stock Exchange (NYSE: CB) and is a component of the S&P 500 index. Chubb employs approximately 43,000 people worldwide. Additional information can be found at: www.chubb.com.About Chubb IndiaAt Chubb India, we are on an exciting journey of digital transformation driven by a commitment to engineering excellence and analytics. We are proud to share that we have been officially certified as a Great Place to Work® for the third consecutive year, a reflection of the culture at Chubb where we believe in fostering an environment where everyone can thrive, innovate, and grow.With a team of over 2500 talented professionals, we encourage a start-up mindset that promotes collaboration, diverse perspectives, and a solution-driven attitude. We are dedicated to building expertise in engineering, analytics, and automation, empowering our teams to excel in a dynamic digital landscape.We offer an environment where you will be part of an organization that is dedicated to solving real-world challenges in the insurance industry. Together, we will work to shape the future through innovation and continuous learning.Position Details:Function/Department: Advanced AnalyticsLocation: Bangalore, IndiaEmployment Type: Full-timeRole Overview – AI/ML EngineerChubb is seeking a highly skilled and experienced Deep Learning Engineer with Generative AI experience to develop and scale our Generative AI capabilities. The ideal candidate will be responsible for designing, finetuning and training large language models and developing Generative AI systems that can create and improve conversational abilities and decision-making skills of our machinesResponsibilities:Develop and improve Generative AI systems to enable high quality decision making, to refine answers for queries, and to enhance automated communication capabilities.Own the entire process of data collection, training, and deploying machine learning models.Continuous research and implementation of cutting-edge techniques in deep learning, NLP and Generative AI to build state-of-the-art models.Work closely with Data Scientists and other Machine Learning Engineers to design and implement end-to-end solutions.Optimize and streamline deep learning training pipelines.Develop performance metrics to track the efficiency and accuracy of deep learning models.Requirements : Minimum of 4 years of industry experience in developing deep learning models with a focus on NLP and Generative AI.Expertise in deep learning frameworks such as Tensorflow, PyTorch and Keras.Experience working with cloud-based services such as Azure for training and deployment of deep learning models.Experience with Hugging Face's Transformer libraries.Expertise in developing and scaling Generative AI systems.Experience in large dataset processing, including pre-processing, cleaning and normalization.Proficient in programming languages such as Python ( preferred ) /R.Experience with natural language processing (NLP) techniques and libraries. Why Chubb?Join Chubb to be part of a leading global insurance company!Our constant focus on employee experience along with a start-up-like culture empowers you to achieve impactful results.Industry leader: Chubb is a world leader in the insurance industry, powered by underwriting and engineering excellenceA Great Place to work: Chubb India has been recognized as a Great Place to Work® for the years 2023-2024 and 2024-2025Laser focus on excellence: At Chubb we pride ourselves on our culture of greatness where excellence is a mindset and a way of being. We constantly seek new and innovative ways to excel at work and deliver outstanding resultsStart-Up Culture: Embracing the spirit of a start-up, our focus on speed and agility enables us to respond swiftly to market requirements, while a culture of ownership empowers employees to drive results that matterGrowth and success: As we continue to grow, we are steadfast in our commitment to provide our employees with the best work experience, enabling them to advance their careers in a conducive environment Employee BenefitsOur company offers a comprehensive benefits package designed to support our employees’ health, well-being, and professional growth. Employees enjoy flexible work options, generous paid time off, and robust health coverage, including treatment for dental and vision related requirements. We invest in the future of our employees through continuous learning opportunities and career advancement programs, while fostering a supportive and inclusive work environment. Our benefits include:Savings and Investment plans: We provide specialized benefits like Corporate NPS (National Pension Scheme), Employee Stock Purchase Plan (ESPP), Long-Term Incentive Plan (LTIP), Retiral Benefits and Car Lease that help employees optimally plan their financesUpskilling and career growth opportunities: With a focus on continuous learning, we offer customized programs that support upskilling like Education Reimbursement Programs, Certification programs and access to global learning programs.Health and Welfare Benefits: We care about our employees’ well-being in and out of work and have benefits like Hybrid Work Environment, Employee Assistance Program (EAP), Yearly Free Health campaigns and comprehensive Insurance benefits.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Consulting and Research",
      "Industries": "Insurance, Data Infrastructure and Analytics, and IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "R",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "Azure",
      "Hugging Face",
      "Transformer",
      "Deep Learning",
      "NLP",
      "Generative AI",
      "Data Processing"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_031"
  },
  {
    "job_id": "ai-ml-engineer-%E2%80%93-xr-software-all-levels-at-qualcomm-4273838318",
    "title": "AI/ML Engineer – XR Software (All levels))",
    "company": "Qualcomm",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-14",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-%E2%80%93-xr-software-all-levels-at-qualcomm-4273838318?position=5&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=%2FWADbpxvNe4mF5Fh2k2vyg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424033",
    "description": "CompanyQualcomm India Private LimitedJob AreaEngineering Group, Engineering Group > Systems EngineeringGeneral SummaryWe are seeking a passionate and skilled AI/ML Engineer to join our cutting-edge Extended Reality (XR) Software team. In this role, you will work on next-generation XR products that blend the physical and digital worlds, leveraging artificial intelligence and machine learning to create immersive, intelligent, and responsive experiences.You will collaborate with cross-functional teams of researchers, engineers, and designers to build real-time AI/ML software optimized for XR platforms. A strong background in C++ or embedded firmware development is essential, as you will be working close to hardware and performance-critical systems.Key ResponsibilitiesDesign, develop, and optimize AI/ML models for XR applications such as computer vision, sensor fusion, gesture recognition, and spatial understanding.Implement real-time inference pipelines on embedded or edge devices.Collaborate with firmware and hardware teams to integrate ML models into XR systems.Analyze system performance and optimize for latency, power, and memory.Stay up to date with the latest research and trends in AI/ML and XR technologies.Contribute to the full lifecycle of product development—from prototyping to production.Required QualificationsBachelor’s or Master’s degree in Computer Science, Electrical Engineering, or a related field.1–10 years of industry experience in AI/ML engineering or embedded systems.Proficiency in C++ and/or embedded firmware development.Solid understanding of machine learning fundamentals and experience with frameworks like TensorFlow, PyTorch, or ONNX.Experience with deploying ML models on edge devices Familiarity with XR technologies (AR/VR/MR), sensor data processing, or 3D spatial computing.Minimum Qualifications Bachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.ORMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.ORPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.Applicants: Qualcomm is an equal opportunity employer. If you are an individual with a disability and need an accommodation during the application/hiring process, rest assured that Qualcomm is committed to providing an accessible process. You may e-mail disability-accomodations@qualcomm.com or call Qualcomm's toll-free number found here. Upon request, Qualcomm will provide reasonable accommodations to support individuals with disabilities to be able participate in the hiring process. Qualcomm is also committed to making our workplace accessible for individuals with disabilities. (Keep in mind that this email address is used to provide reasonable accommodations for individuals with disabilities. We will not respond here to requests for updates on applications or resume inquiries).Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.To all Staffing and Recruiting Agencies: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.If you would like more information about this role, please contact Qualcomm Careers.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Telecommunications"
    },
    "skills": [
      "C++",
      "Embedded Firmware",
      "TensorFlow",
      "PyTorch",
      "ONNX",
      "Machine Learning",
      "Computer Vision",
      "Edge Devices",
      "XR",
      "AR",
      "VR"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_032"
  },
  {
    "job_id": "ai-ml-engineer-at-the-value-maximizer-4338181441",
    "title": "AI/ML Engineer",
    "company": "The Value Maximizer",
    "location": "Navi Mumbai, Maharashtra, India",
    "posted_date": "2025-11-07",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-the-value-maximizer-4338181441?position=7&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=JRdNW8xc%2FXvjnaOAWzPR1g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424035",
    "description": "We are seeking a highly skilled Machine Learning Engineer to join our dynamic team. You will be responsible for designing, developing, and deploying machine learning models and AI solutions that address complex challenges. The ideal candidate is proficient in Python, PyTorch, and statistical modeling and has a strong passion for leveraging AI to create impactful tools.Key Responsibilities Design, develop, and optimize machine learning models and algorithms Implement and fine-tune deep learning models using frameworks like PyTorch and TensorFlow Analyze large, complex datasets to extract insights and identify patterns Develop scalable machine learning pipelines for training, validation, and deployment Collaborate with cross-functional teams to integrate ML models into production systems Stay up-to-date with the latest advancements in machine learning, deep learning, and AI technologies Document processes and model performance to ensure reproducibility and compliance. Qualifications Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field 3+ years of experience in machine learning, deep learning, or AI tool development Proficiency in Python and experience with frameworks such as PyTorch and Tensorflow Solid understanding of statistical modeling, probability, and optimization techniques Experience with data preprocessing, feature engineering, and handling large datasets Strong problem-solving skills and attention to detail Excellent communication and teamwork abilities Ability to work in a fast-paced, dynamic environment and manage multiple priorities",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "PyTorch",
      "TensorFlow",
      "Machine Learning",
      "Deep Learning",
      "Statistical Modeling",
      "Feature Engineering",
      "Data Pipelines"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_033"
  },
  {
    "job_id": "ai-ml-engineer-at-terralogic-4338525238",
    "title": "AI/ML ENGINEER",
    "company": "Terralogic",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-23",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-terralogic-4338525238?position=10&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=l3LnBDQQgmijkrR1vtkx9g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424037",
    "description": "OverviewWe are building our core AI team and looking for highly skilled AI Engineers who can design, develop, and deploy cutting-edge AI systems. The ideal candidate will have strong foundations in software engineering, hands-on experience with AI frameworks, and a passion for solving real-world problems using intelligent agents and generative AI.Total Experience3–6 years (industry experience in AI/Software Development)Job SkillsMaster’s degree in Computer Science, Artificial Intelligence, Machine Learning, or related fieldStrong software development background (Python, APIs, microservices, cloud deployment, etc.)Experience with LLMs, vector databases, embeddings, and orchestration frameworksProven ability to build and scale AI applications in productionFamiliarity with LangChain, LangGraph, AutoGen, or similar ecosystemsGood understanding of data pipelines, MLOps, and evaluation metricsNice-to-HaveContributions to open-source AI frameworksExperience with distributed systems and large-scale data processingKnowledge of reinforcement learning or advanced ML researchResponsibilitiesDesign and implement Retrieval-Augmented Generation (RAG) pipelines for enterprise use casesBuild, optimize, and deploy AI agents using frameworks like LangGraph, AutoGen, or similarDevelop and maintain scalable AI solutions in production environmentsCollaborate with cross-functional teams (Design, Product, Data, Engineering) to integrate AI into applicationsResearch, prototype, and evaluate new AI/LLM techniques to enhance system performanceApply Now",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Information Technology & Services"
    },
    "skills": [
      "Python",
      "APIs",
      "Microservices",
      "Cloud Deployment",
      "LangChain",
      "LangGraph",
      "AutoGen",
      "LLMs",
      "Vector Databases",
      "Embeddings",
      "RAG",
      "MLOps",
      "Reinforcement Learning",
      "Data Pipelines"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_034"
  },
  {
    "job_id": "ai-ml-engineer-at-ringcentral-4334405012",
    "title": "AI/ML Engineer",
    "company": "RingCentral",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-06",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-ringcentral-4334405012?position=12&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=X4nmOPEuPPi6LOLMDA4B6Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424039",
    "description": "Job Description:We are seeking an experienced AI Engineer with a strong background in Natural Language Understanding (NLU) who is passionate about pushing the boundaries of Conversational AI. In this role, you will design, develop, and deploy scalable AI solutions leveraging LLMs, Retrieval-Augmented Generation (RAG), and prompt engineering techniques to power intelligent products and services.As part of our ML/AI team, you’ll own the full lifecycle of model development — from data preparation and fine-tuning to inference optimization and deployment in production environments.Responsibilities:Design, fine-tune, and deploy LLM-based applications for Conversational AI use casesBuild scalable retrieval-augmented generation (RAG) pipelines that combine LLMs with structured/unstructured data sourcesDevelop prompt engineering strategies, templates, and evaluation frameworks for LLM-driven workflowsCollaborate with cross-functional teams to identify and implement AI-driven solutions to business problemsOptimize models for low-latency inference using quantization, distillation, and other model optimization techniques (e.g., ONNX, TensorRT)Build robust data processing, labeling, and augmentation pipelines to improve model performanceImplement monitoring and evaluation systems for deployed LLMs, ensuring reliability, fairness, and safetyStay current with emerging trends in LLMs, retrieval systems, and generative AI frameworksRequirements:2-4 years of hands-on experience in NLP/LLM.Strong proficiency in Python and PyTorch and related frameworks (like Hugging Face Transformers, Sentence Transformers etc.)Proven experience developing and deploying NLP or LLM pipelines in production environments at scaleSolid understanding of transformer architectures and attention mechanismsProficiency in using LLM provider APIs such as OpenAI, Gemini etc.including prompt design, fine-tuning, and evaluationExperience with model optimization techniques such as quantization, pruning, ONNX, TensorRT, or model distillationBachelor’s or Master’s degree in Computer Science, Artificial Intelligence, or a related fieldNice to Have:Hands-on experience with RAG and vector databases (e.g., FAISS, Qdrant, pgVector etc. )Prior work on LLM fine-tuning, alignment, or evaluationExperience with LLM orchestration frameworks such as LlamaIndex or similar toolsFamiliarity with multi-provider LLM orchestration, integrating APIs from OpenAI, Gemini etc. and others for fallbacks, routing, or ensemble strategiesKnowledge of MLOps for LLMs, including model serving and monitoringUnderstanding of embedding models, context management, and token optimization for scalable LLM applications",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Design",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "PyTorch",
      "Hugging Face",
      "Transformers",
      "ONNX",
      "TensorRT",
      "LLMs",
      "RAG",
      "APIs",
      "MLOps",
      "Vector Databases",
      "Data Processing"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_035"
  },
  {
    "job_id": "senior-python-ai-ml-engineer-at-endava-4340254710",
    "title": "Senior Python AI/ML Engineer",
    "company": "Endava",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-13",
    "job_url": "https://in.linkedin.com/jobs/view/senior-python-ai-ml-engineer-at-endava-4340254710?position=17&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=SkV0Sf6K1zbRUxleA55bPg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424041",
    "description": "Company DescriptionTechnology is our how. And people are our why. For over two decades, we have been harnessing technology to drive meaningful change.By combining world-class engineering, industry expertise and a people-centric mindset, we consult and partner with leading brands from various industries to create dynamic platforms and intelligent digital experiences that drive innovation and transform businesses.From prototype to real-world impact - be part of a global shift by doing work that matters.Job DescriptionPosition Overview:We are seeking a highly skilled Senior Python Engineer with a strong background in AI/ML and GenAI to join our team.The ideal candidate will have a deep understanding of natural language processing, machine learning, and prompt engineering, and will be able to apply their expertise to develop innovative solutionsAbility to work independently and as part of a teamStrong communication and interpersonal skills.QualificationsStrong proficiency in Python programming.Experience with natural language processing libraries and frameworks (e.g., NLTK, spaCy, Transformers).Experience with machine learning frameworks (e.g., TensorFlow, PyTorch).Deep understanding of prompt engineering principles, best practices, and RAG concepts.Familiarity with OpenAI's language models (e.g., GPT-3, GPT-4).Experience with DevOps practices and tools (Orchestrator, Splunk, Dynatrace etc).Knowledge of vector stores and RAG concepts.Experience with vector store libraries and frameworks.Excellent problem-solving and analytical skills.Experience with cloud platforms AWS and OpenShift.Additional InformationUrgently need Sr. Python AI/ML EngineersAt Endava, we’re committed to creating an open, inclusive, and respectful environment where everyone feels safe, valued, and empowered to be their best. We welcome applications from people of all backgrounds, experiences, and perspectives—because we know that inclusive teams help us deliver smarter, more innovative solutions for our customers. Hiring decisions are based on merit, skills, qualifications, and potential. If you need adjustments or support during the recruitment process, please let us know.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "TensorFlow",
      "PyTorch",
      "NLTK",
      "spaCy",
      "Transformers",
      "Prompt Engineering",
      "RAG",
      "OpenAI",
      "GPT-3",
      "GPT-4",
      "DevOps",
      "Orchestrator",
      "Splunk",
      "Dynatrace",
      "Vector Stores",
      "AWS",
      "OpenShift"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_036"
  },
  {
    "job_id": "ai-ml-gcp-engineer-at-endava-4340263600",
    "title": "AI/ML GCP Engineer",
    "company": "Endava",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-13",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-gcp-engineer-at-endava-4340263600?position=20&pageNum=0&refId=O8XmPhQs6yyARpv4fM8IHA%3D%3D&trackingId=odkfstYVRAw%2B268WrHGKdA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424044",
    "description": "Company DescriptionTechnology is our how. And people are our why. For over two decades, we have been harnessing technology to drive meaningful change.By combining world-class engineering, industry expertise and a people-centric mindset, we consult and partner with leading brands from various industries to create dynamic platforms and intelligent digital experiences that drive innovation and transform businesses.From prototype to real-world impact - be part of a global shift by doing work that matters.Job DescriptionJob SummaryWe are looking for a Machine Learning Engineer (AI/ML) with 3-5 years of experience to develop and deploy scalable AI models. The ideal candidate has hands-on experience with machine learning algorithms, deep learning frameworks, and cloud-based ML solutions. You will work on real-world AI applications, optimize ML models, and collaborate with data scientists, software engineers, and product teams to deliver AI-powered solutions.Key ResponsibilitiesDevelop, train, and deploy ML models for applications in NLP, computer vision, recommendation systems, or predictive analytics.Design and implement ML pipelines for model training, validation, and deployment.Preprocess and analyze large datasets to extract meaningful insights and improve model performance.Optimize and fine-tune ML models using techniques like feature engineering, hyperparameter tuning, and distributed training.Deploy ML models in production using MLOps best practices with cloud platforms (GCP, AWS, or Azure).Collaborate with cross-functional teams to integrate AI models into production systems.Monitor and maintain deployed models, ensuring their performance and retraining when necessary.Stay up-to-date with industry trends, emerging AI/ML technologies, and best practices.QualificationsBachelor’s or Master’s degree in Computer Science, Data Science, AI, or a related field.3-5 years of experience in machine learning, AI, or data science roles.Strong programming skills in Python (TensorFlow, PyTorch, Scikit-learn, Pandas, NumPy).Experience in building and deploying ML models on cloud platforms (Google Cloud Platform, AWS, or Azure).Hands-on experience with ML algorithms (classification, regression, clustering, reinforcement learning).Familiarity with deep learning architectures (CNNs, RNNs, Transformers, GANs).Understanding of MLOps practices (CI/CD pipelines, model monitoring, and retraining).Experience working with large-scale datasets using SQL, BigQuery, or Spark.Knowledge of containerization and orchestration using Docker and Kubernetes.Additional InformationDiscover some of the global benefits that empower our people to become the best version of themselves:Finance:Competitive salary package, share plan, company performance bonuses, value-based recognition awards, referral bonus; Career Development:Career coaching, global career opportunities, non-linear career paths, internal development programmes for management and technical leadership;Learning Opportunities:Complex projects, rotations, internal tech communities, training, certifications, coaching, online learning platforms subscriptions, pass-it-on sessions, workshops, conferences;Work-Life Balance:Hybrid work and flexible working hours, employee assistance programme;Health:Global internal wellbeing programme, access to wellbeing apps;Community:Global internal tech communities, hobby clubs and interest groups, inclusion and diversity programmes, events and celebrations.At Endava, we’re committed to creating an open, inclusive, and respectful environment where everyone feels safe, valued, and empowered to be their best. We welcome applications from people of all backgrounds, experiences, and perspectives—because we know that inclusive teams help us deliver smarter, more innovative solutions for our customers. Hiring decisions are based on merit, skills, qualifications, and potential. If you need adjustments or support during the recruitment process, please let us know.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "TensorFlow",
      "PyTorch",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "SQL",
      "NLP",
      "Computer Vision",
      "Reinforcement Learning",
      "Feature Engineering",
      "BigQuery",
      "AWS",
      "Azure",
      "Google Cloud Platform",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "MLOps",
      "Recommendation Systems",
      "Containerization"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_038"
  },
  {
    "job_id": "machine-learning-engineer-4-at-hackajob-4321068476",
    "title": "Machine Learning Engineer 4",
    "company": "hackajob",
    "location": "Chennai, Tamil Nadu, India",
    "posted_date": "2025-11-07",
    "job_url": "https://in.linkedin.com/jobs/view/machine-learning-engineer-4-at-hackajob-4321068476?position=10&pageNum=0&refId=hGD4TG8C5%2FrpvSiBw77VFw%3D%3D&trackingId=sJcD21qBesliGgr6qQPIAA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424046",
    "description": "hackajob is collaborating with Comcast to connect them with exceptional tech professionals for this role.Comcast brings together the best in media and technology. We drive innovation to create the world's best entertainment and online experiences. As a Fortune 50 leader, we set the pace in a variety of innovative and fascinating businesses and create career opportunities across a wide range of locations and disciplines. We are at the forefront of change and move at an amazing pace, thanks to our remarkable people, who bring cutting-edge products and services to life for millions of customers every day. If you share in our passion for teamwork, our vision to revolutionize industries and our goal to lead the future in media and technology, we want you to fast-forward your career at Comcast.Job SummaryAs part of Privacy and Data Protection Team the Machine Learning Engineer will be responsible for researching, building, and designing ML systems to build and automate predictive models at enterprise level. Candidate should have the ability to rapidly grasp new technologies and abstractions and apply them in a meaningful way.Job DescriptionCore ResponsibilitiesResearch, design, and implement ML algorithms and tools.Review and select appropriate data sets in a data warehouse.Select appropriate data representation and visualization methods.Identify and understand data distributions that affects model performance.Verify data quality with a small/large number of data samples.Transform and convert ML prototypes and models, e.g. change from SVM to Random Forest.Test and evaluate machine learning models and using results to improve them.Train and retrain systems when needed. Knowledge in active learning is a plus.Extending machine learning libraries if needed.Persist ML models for production environments.Identify technology issues, design resolutions, and proactive communication.Experienced in interpreting project requirements and technical specifications.Employees At All Levels Are Expected ToDegree in computer science, math, statistics, or a related degree.5 years of relevant experience with building ML models and data pipelines.Experience in supervised and un-supervised ML models.Proficient in persisting ML models and deployment in production environment (operationalizing ML models).Data science certificates in machine learning, neural networks, deep learning, or related fields.Strong analytical, problem-solving and teamwork skills.At least 2 years of experience in any data engineering python frameworks like Pandas/Pyspark.Software engineering skills and strong experience in data science coding and programming languages, including Python, SQL, NoSQLStrong knowledge and experience working with Python-based ML libraries and packages such as NumPy, SciPy, Pandas, etc.Extensive experience in working with ML frameworks, e.g. scikit-learn and Keras.Experience working with data visualization, e.g. Matplotlib.Understand data structures, data modeling and software architecture.Experience with version control frameworks, GIT preferred.At least 1 year of experience in LLM, NER and NLP based modelsExperience with text extraction using OCR, data parsing and storageAdditional SkillsExtensive experience in working with advanced ML frameworks, e.g. TensorFlow, PyTorch, Spark ML, and Torch.Experience working deploying model with MLFlow.Experience working with Databricks/ AWS MLExperience is additional visualization tools, e.g. , Seaborn, Plotly, pydot, Dash, etc.DisclaimerThis information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.Comcast is an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law.Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits to eligible employees. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.EducationBachelor's DegreeWhile possessing the stated degree is preferred, Comcast also may consider applicants who hold some combination of coursework and experience, or who have extensive related professional experience.Relevant Work Experience7-10 Years",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "TensorFlow",
      "PyTorch",
      "Keras",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "SQL",
      "NoSQL",
      "NLP",
      "LLM",
      "NER",
      "Neural Networks",
      "MLflow",
      "Matplotlib",
      "Seaborn",
      "Plotly",
      "Databricks",
      "AWS",
      "GIT",
      "PySpark",
      "Data Modeling",
      "Data Visualization"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251127_039"
  },
  {
    "job_id": "data-analyst-at-innodata-lanka-4340967442",
    "title": "Data Analyst",
    "company": "Innodata Lanka",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/data-analyst-at-innodata-lanka-4340967442?position=1&pageNum=0&refId=m9tN9Y2qYSCxuuONamjTtg%3D%3D&trackingId=EJnRX7WPgwLC%2Fli6%2FmBIVA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424048",
    "description": "📊 Data Analyst (Contract) – Colombo | Immediate JoinerFull-Time | OnsiteWe are seeking a detail-oriented, analytical, and tech-savvy Data Analyst to support our expanding data and reporting operations.🔍 Key Responsibilities✨ Analyze structured & unstructured datasets to uncover trends, patterns, and insights📊 Develop, update, and maintain Power BI, Tableau, and Excel dashboards✔️ Ensure accuracy, consistency, and timely delivery of all reports🤝 Collaborate closely with internal and global teams to drive data-backed initiatives📈 Present findings clearly with strong business relevance and storytelling🎓 Candidate Profile🎓 Bachelor’s degree in Business Analytics, Statistics, Financial Mathematics, Industrial Statistics, or related fields💼 Minimum 1 year of experience in data analysis & visualization (Power BI, Tableau, Excel required)🧠 Strong analytical mindset with the ability to simplify complex data🗣️ Excellent communication skills & sharp attention to detail⚡ Ability to work in a fast-paced, deadline-driven environment🌟 What We Offer🌍 Exposure to global data & analytics projects🤝 A collaborative, supportive, and continuous learning environment🛠️ Opportunity to work with advanced reporting tools & large datasets💰 Competitive compensation for a contractual role🚀 Immediate onboarding📩 How to ApplyApply directly via LinkedIn by submitting your CV.Turn data into actionable insights with us!#DataAnalytics #PowerBI #Tableau #Excel #CareerOpportunity",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Project Management and Analyst",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Power BI",
      "Tableau",
      "Excel"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_001"
  },
  {
    "job_id": "graduate-trainees-%E2%80%93-data-analyst-fixed-term-contract-at-hatton-national-bank-plc-4324586092",
    "title": "Graduate Trainees – Data Analyst (Fixed Term Contract)",
    "company": "Hatton National Bank PLC",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-27",
    "job_url": "https://lk.linkedin.com/jobs/view/graduate-trainees-%E2%80%93-data-analyst-fixed-term-contract-at-hatton-national-bank-plc-4324586092?position=3&pageNum=0&refId=m9tN9Y2qYSCxuuONamjTtg%3D%3D&trackingId=k%2FIFX%2BNhPVCKgnEj2txyDQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424053",
    "description": "Kickstart Your Analytics Career with HNBHatton National Bank PLC is building the next generation of analytics talent. We are inviting high-potential graduates to join us as Graduate Trainees – Data Analysts (Contract Basis – 1 year, renewable).This opportunity provides hands-on exposure to BI, analytics, data visualization, and real banking datasets while being mentored by experts from HNB, Leap-TMO, and BCG.What You Will DoWork on real analytics use cases across Retail, SME, Wholesale, Savings, and Branch Network.Support data extraction, cleaning, validation, and preparation.Develop dashboards and reports using Power BI/Tableau.Conduct basic data analysis and exploratory work to identify trends and opportunities.Support data preparation for predictive models and machine-learning initiatives.Collaborate with IT, business units, and the Data Science team.What We Are Looking ForBachelor’s degree in Data Science, Business Analytics, Statistics, IT, Finance Analytics, Mathematics, or a related field.Knowledge of SQL and Python/R.Familiarity with BI tools such as Power BI or Tableau.Strong analytical skills and attention to detail.Good communication and teamwork abilities.A strong willingness to learn and grow within the analytics field.Why Join HNBStructured training program with real project exposure.Mentorship from senior analytics teams and external consultants.Opportunity to progress into BI, data analytics, or AI roles.A strong foundation for a long-term career in data and analytics.If you are eager to begin your career in analytics, we welcome your application.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Contract",
      "Job function": "Information Technology, Analyst, and Finance",
      "Industries": "Banking"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Power BI",
      "Tableau"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_003"
  },
  {
    "job_id": "market-data-compliance-analyst-at-lseg-4322775861",
    "title": "Market Data Compliance Analyst",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/market-data-compliance-analyst-at-lseg-4322775861?position=9&pageNum=0&refId=m9tN9Y2qYSCxuuONamjTtg%3D%3D&trackingId=A2J0c%2FHFeXE1ymAWhtGYaw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424055",
    "description": "Role ProfileThe Real Time Market Data Business is a critical function to retain and grow revenues cross existing products and services, such as FTSE Russell, LSE, Turquoise, RNS, SEDOL products. The function is tasked with growing revenues by diversifying into new product development and commercial partnerships to benefit the London Stock Exchange Group’s market data business.Key ResponsibilitiesAct as a primary point of contact on behalf of the Market Data Reporting team in relation to queries, reconciliation and all static data changes made on Real Time accounts.Account handling for all Real Time clients and build an ongoing end user relationship to maintain all clients are licensed and billed accurately.Handling the Market Data Reporting Email Inbox, ensuring all emails are logged and respond in a timely manner. This involves assigning queries to the right teams for investigation, monitoring outstanding queries; ensuring clients receive regular updates and prompt resolution.Collaborating closely with respective teams and vendors in order to process new clients and those who wish to cancel their service. This requires processing all vital paperwork, collaborating closely with clients throughout the new client or termination cycle and ensuring the process is completed with relevant departments.Collate received vendor reports and upload electronically. Report to business - variances - increase, decrease, same, no reply - against prior year contract.Once a year do a completeness check by reconciling the vendor reports and clients report to ensure the clients has been covered under the correct license.Working closely with team to ensure that all invoicing is accurate and in line with the correct usage and commercial terms agreed with the client. Skills & QualificationGraduate or of graduate calibre with appropriate work experience.In depth knowledge of real time market data policies globally.Previous experience in a similar position, with proven experience of taking care of internal and external customers.An organised and proactive/solution driven demeanour.Good interpersonal skillsExcellent Excel skillsJoin us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Excel"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_004"
  }
,
  {

 "job_id": "devops-engineer-at-qlub-4347014040",
    "title": "DevOps Engineer",
    "company": "qlub",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-20",
    "job_url": "https://lk.linkedin.com/jobs/view/devops-engineer-at-qlub-4347014040?position=1&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=7GhRxn9Qg4p8fvI4SNt5gg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424131",
    "description": "...",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "Amazon Web Services",
      "Google Cloud Platform",
      "EC2",
      "RDS",
      "ECS",
      "ALB",
      "GKE",
      "Route53",
      "Docker",
      "Kubernetes",
      "Helm",
      "GitHub Actions",
      "ArgoCD",
      "GitOps",
      "Terraform",
      "Prometheus",
      "Thanos",
      "Grafana",
      "Loki",
      "ELK Stack",
      "CI/CD Pipelines"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_001"
  },
 

 {
    "job_id": "lead-devops-engineer-at-intervest-software-technologies-private-limited-4324347311",
    "title": "Lead Devops Engineer",
    "company": "Intervest Software Technologies (Private) Limited",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-25",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-at-intervest-software-technologies-private-limited-4324347311?position=7&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=rjP0ZndzMtYsEoAOP8pU8Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424141",
    "description": "...",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Amazon Web Services",
      "CI/CD Pipelines",
      "Terraform",
      "Datadog",
      "MySQL",
      "ETL Pipelines",
      "GraphQL",
      "React",
      "React Native"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_006"
  },
  {
    "job_id": "business-data-analyst-at-capgemini-4323870887",
    "title": "Business Data Analyst",
    "company": "Capgemini",
    "location": "New Jersey, United States",
    "posted_date": "2025-11-21",
    "job_url": "https://www.linkedin.com/jobs/view/business-data-analyst-at-capgemini-4323870887?position=4&pageNum=0&refId=Gs7iTLWMPnQUFS3AFK25Yw%3D%3D&trackingId=rDNo0HVZjOtmuIKqrOs8hQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424061",
    "description": "Job Description:We are seeking a highly motivated and detail-oriented Business/Data Analyst to join our team. The ideal candidate will have strong SQL skills, a foundational understanding of Capital Markets, and a proactive attitude toward problem-solving and collaboration. This role offers an exciting opportunity to work closely with stakeholders across business and technology teams to drive data-driven decision-making and support strategic initiatives.Key Responsibilities:Collaborate with business stakeholders to gather and analyze requirements related to Capital Markets processes and data.Write complex SQL queries to extract, manipulate, and analyze large datasets from various sources.Translate business needs into actionable insights and data models.Support data quality initiatives and ensure accuracy and consistency across reporting and analytics.Create and maintain documentation for data flows, business rules, and reporting logic.Work with cross-functional teams including developers, product managers, and QA to deliver high-quality solutions.Identify opportunities for process improvement and automation using data-driven approaches.Required Skills & Qualifications:6+ years of experience as a Business Analyst or Data Analyst in financial services, preferably within Capital Markets.Strong proficiency in SQL – ability to write and optimize complex queries.Familiarity with Capital Markets concepts such as trading, settlements, risk, and compliance.Excellent analytical and problem-solving skills.Strong communication and interpersonal skills with a collaborative mindset.Ability to work independently and manage multiple priorities in a fast-paced environment.Preferred Qualifications:Experience with data visualization tools (e.g., Tableau, Power BI).Knowledge of Python or other scripting languages is a plus.Understanding of regulatory requirements in Capital Markets (e.g., MiFID, Dodd-Frank).Life at Capgemini:Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:• Flexible work• Healthcare including dental, vision, mental health, and well-being programs• Financial well-being programs such as 401(k) and Employee Share Ownership Plan• Paid time off and paid holidays• Paid parental leave• Family building benefits like adoption assistance, surrogacy, and cryopreservation• Social well-being benefits like subsidized back-up child/elder care and tutoring• Mentoring, coaching and learning programs• Employee Resource Groups• Disaster ReliefDisclaimer:Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-laSalary Transparency:Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role.This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees.Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "SQL",
      "Python",
      "Tableau",
      "Power BI"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_009"
  },
  {
    "job_id": "business-intelligence-data-analyst-at-simplepractice-4274385912",
    "title": "Business Intelligence Data Analyst",
    "company": "SimplePractice",
    "location": "United States",
    "posted_date": "2025-11-24",
    "job_url": "https://www.linkedin.com/jobs/view/business-intelligence-data-analyst-at-simplepractice-4274385912?position=8&pageNum=0&refId=Gs7iTLWMPnQUFS3AFK25Yw%3D%3D&trackingId=q%2Fy3%2FHy9tNKqf%2B6viXjLWw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424063",
    "description": "About UsAt SimplePractice, we are improving access to quality care by equipping health and wellness clinicians with all the tools they need to thrive in private practice. More than 250,000 providers trust SimplePractice to build their business through our industry-leading software with powerful tools that simplify every part of practice management. From admin work to clinical care, our suite of innovative solutions work together to reduce administrative burden—empowering solo and small group practitioners to thrive alongside their clients. Recognized by MedTech Breakthrough as the Best Practice Management Solution Provider in 2024 and the Digital Health Awards in 2023, SimplePractice is proud to pave the future of health tech.The RoleWe are looking for a skilled and analytical Business Intelligence Data Analyst with 3+ years of experience to join our Customer Success team. In this role, you will turn data into insights to drive decisions, improve customer outcomes, and help scale our Customer Success operations. Your expertise in SQL and data storytelling will be key to identifying trends, supporting key initiatives, and building impactful dashboards and reports.Key ResponsibilitiesPartner with Customer Success leadership to define, track, and analyze key performance indicators (KPIs)Build and maintain SQL-based queries, reports, and dashboards using BI tools (e.g., Tableau, Looker, PowerBI)Translate business needs into analytical frameworks and actionable insightsMonitor and report on customer engagement, retention, onboarding, and different channel (phone, chat, email) support metricsCollaborate cross-functionally with Product, Engineering and Data Engineering teams to access and model relevant dataEnsure data accuracy, integrity, and consistency across reporting sourcesDesired Skills & Experience A bachelor's degree in Computer Science, Information Systems, Data Science, Business Analytics, or a related field (Masters degree preferred) . 6+ years of experience in a data analyst, business intelligence, or related roleAdvanced SQL skills and experience working with relational databasesHands-on experience with BI/reporting tools (e.g., Tableau, Looker, Power BI)Strong analytical thinking and ability to distill complex data into clear insightsExperience working with or supporting Customer Success, Customer Experience, or similar customer-facing teamsExcellent communication and stakeholder management skillsAbility to work independently and manage multiple priorities in a fast-paced environmentBonus Points Experience with customer lifecycle analysisFamiliarity with dbt, Snowflake, or cloud data warehousesBase Compensation Range$100,000 - $125,000 annuallyBase salary is one component of total compensation. Employees may also be eligible for an annual bonus or commission. Some roles may also be eligible for overtime pay.The above represents the expected base compensation range for this job requisition. Ultimately, in determining your pay, we’ll consider many factors including, but not limited to, skills, experience, qualifications, geographic location, and other job-related factors.BenefitsWe offer a competitive benefits program including:Medical, dental, vision, life & disability insurance401(k) plan with company matchFlexible Time Off (FTO), wellbeing days, paid holidays, and summer FridaysMental health resourcesPaid parental leave & Backup CareTuition reimbursementEmployee Resource Groups (ERGs)California Job Applicant Privacy NoticeThank you for your interest in opportunities at SimplePractice LLC (“SimplePractice” or “us” or “we” or “our”). Please note that when you submit your resume or application materials to us for employment purposes, you are subject to the SimplePractice California Job Applicant Privacy Notice. For more information about our privacy practices, please contact us at privacy@simplepractice.com.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Research, Analyst, and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "SQL",
      "Snowflake",
      "dbt",
      "Tableau",
      "Power BI",
      "Looker"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_012"
  },
  {
    "job_id": "data-analyst-at-insight-global-4324387319",
    "title": "Data Analyst",
    "company": "Insight Global",
    "location": "Houston, TX",
    "posted_date": "2025-11-25",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-insight-global-4324387319?position=11&pageNum=0&refId=Gs7iTLWMPnQUFS3AFK25Yw%3D%3D&trackingId=YtDvRrYJXFD15tPcRe9dww%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424065",
    "description": "Job Description:Insight Global is seeking a Data Analyst II for a large utility company in Houston, Texas. The Data Analyst will support the Enterprise Risk Management and Insurance Risk Management offices by leading modeling efforts around project risk management, asset health, and operations risk. This role involves collaborating with senior management, technical teams, and clients to determine data requirements and implement best practices for advanced data manipulation, storage, and analysis. Responsibilities include writing and coding logical and physical database descriptions, specifying database identifiers for management systems, and developing local databases integrated with internal applications and external sources to query, store, and process data. Requirements:Experience with database technologiesKnowledge of at least one scripting language including Python and related packages (e.g.NumPy, etcStrong written and oral communication skillsStrong troubleshooting and problem solving skillsDemonstrated history of successDesire to be working with data and helping businesses make better data driven decisionsBasic knowledge of statistics and Monte Carlo simulation techniquesBachelor's degree in a technical field such as computer science, computer engineering, or related field required2-4 years applicable experience This role is a 3 month contract with extension and offering a hourly pay range of $45 - $48.50.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Contract",
      "Job function": "Business Development",
      "Industries": "Utilities"
    },
    "skills": [
      "Python",
      "NumPy",
      "Statistics"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_014"
  },
  {
    "job_id": "data-analyst-at-kpmg-india-4338690745",
    "title": "Data Analyst",
    "company": "KPMG India",
    "location": "Gurugram, Haryana, India",
    "posted_date": "2025-11-24",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-kpmg-india-4338690745?position=2&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=XffqRdqIL9MMhEk6QKvkeQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424069",
    "description": "KPMG entities in India are professional services firm(s). These Indian member firms are affiliated with KPMG International Limited. KPMG was established in India in August 1993. Our professionals leverage the global network of firms, and are conversant with local laws, regulations, markets and competition. KPMG has offices across India in Ahmedabad, Bengaluru, Chandigarh, Chennai, Gurugram, Jaipur, Hyderabad, Jaipur, Kochi, Kolkata, Mumbai, Noida, Pune, Vadodara and Vijayawada. KPMG entities in India offer services to national and international clients in India across sectors. We strive to provide rapid, performance-based, industry-focused and technology-enabled services, which reflect a shared knowledge of global and local industries and our experience of the Indian business environment.Location: Gurugoan/Bangalore/PuneFunctional SkillsDetermining, creating, and implementing internal process improvements, such as redesigning infrastructure for increased scalability, improving data delivery, and automating manual procedures.Building analytical tools that make use of the data flow and offer a practical understanding of crucial company performance indicators like operational effectiveness and customer acquisition.Helping stakeholders, including the data, design, product, and executive teams, with technical data difficulties.Working on data-related technical challenges while collaborating with stakeholders, including the Executive, Product, Data, and Design teams, to support their data infrastructure needs.Remaining up to date with developments in technology and industry norms can help you to produce higher-quality results.Technical Skills:Analyze large datasets to derive actionable insights and support decision-making processes.Develop and maintain data pipelines using PySpark and other data processing tools.Write efficient SQL queries to extract, transform, and load data from various sources.Implement data models and schemas to organize and optimize data storage and retrieval.Perform data normalization and denormalization to ensure data integrity and accessibility.Collaborate with data engineers to centralize and manage data assets.Ensure data quality through validation and cleansing processes.Utilize CI/CD pipelines to streamline data deployment and maintain continuous integration.Qualifications:Proven experience in data analytics and working with large datasets.Strong SQL skills for querying and managing databases.Experience with PySpark for large-scale data processing.Basic understanding of Hadoop and its ecosystem.Familiarity with data engineering concepts and best practices.Knowledge of data modeling, including schemas, normalization, and denormalization techniques.Understanding of data centralization, cardinality, and data quality principles.Good to have experience in CI/CD pipelines and toolsBankingDeep understanding of banking operations, financial products, and regulatory frameworksExperience with data modeling, ETL processes, and statistical analysisPrior experience in retail or corporate banking analyticsAnalyze banking data including customer transactions, loan performance, and financial statementsSupport credit risk analysis and fraud detection initiativesMaintain and optimize banking databases and data pipelinesKPMG India has a policy of providing equal opportunity for all applicants and employees regardless of their color, caste, religion, age, sex/gender, national origin, citizenship, sexual orientation, gender identity or expression, disability or other legally protected status. KPMG India values diversity and we request you to submit the details below to support us in our endeavor for diversity. Providing the below information is voluntary and refusal to submit such information will not be prejudicial to you.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "SQL",
      "PySpark",
      "Hadoop",
      "ETL",
      "CI/CD"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_017"
  },
  {
    "job_id": "data-analyst-at-nestaway-4323172884",
    "title": "Data Analyst",
    "company": "Nestaway",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-18",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-nestaway-4323172884?position=3&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=TUcij26wi2PPpADsZGSlNg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424071",
    "description": "Job Title: Data Analyst Company: Nestaway Technologies Pvt. Ltd. Location: HSR, Bangalore (On-site) Experience: 2+ YearsAbout NestawayNestaway is one of India’s leading co-living and rental housing platforms, simplifying long-term stays through technology-led solutions and strong operational networks. We are building a seamless and trusted rental experience for tenants and homeowners across major cities.Role OverviewWe are seeking a Data Analyst who is detail-oriented, analytical, and passionate about turning data into meaningful insights. You will work closely with Operations, Sales, Finance, and Leadership teams to support data-driven decision-making across the organization.Key ResponsibilitiesCollect, clean, transform, and analyze data from multiple internal systems.Build dashboards, automated reports, and visualization models (Power BI / Tableau / Google Data Studio).Identify trends, patterns, and insights to support business planning and performance reviews.Collaborate with cross-functional teams (Operations, Sales, Growth, Finance) to understand business requirements and provide data-backed recommendations.Monitor and maintain key business metrics and performance KPIs.Support process optimization through data-driven problem solving.Prepare and present findings to internal stakeholders and leadership teams.Required SkillsStrong analytical and problem-solving abilities.Proficiency in Excel (advanced), SQL (intermediate to strong), and at least one BI tool (Power BI / Tableau / Looker / GDS).Basic understanding of Python or R for data manipulation is a plus.Ability to work with large datasets and draw actionable insights.Strong communication skills with the ability to explain data-driven insights clearly.Preferred QualificationsBachelor’s degree in Engineering, Mathematics, Statistics, Economics, Business Analytics, or a related field.1–2 years of hands-on experience in a Data Analyst or Business Analyst role.Experience in consumer tech, real-estate, SaaS, or operations-led organizations is an advantage.What We OfferOpportunity to work directly with leadership teams and drive real business impact.Fast-growing environment with learning and development opportunities.Ownership, autonomy, and a transparent work culture.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Analyst",
      "Industries": "Hospitality"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Tableau",
      "Power BI",
      "Looker",
      "Google Data Studio",
      "Excel"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_018"
  },
  {
    "job_id": "data-analyst-at-easemytrip-com-4347002051",
    "title": "Data Analyst",
    "company": "EaseMyTrip.com",
    "location": "Haryana, India",
    "posted_date": "2025-11-20",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-easemytrip-com-4347002051?position=6&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=DYVS%2BlUjFeRSlPI4qN1jOQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424072",
    "description": "About the RoleAs a Data Analyst at EaseMyTrip.com, you will be crucial in analyzing travel data to drive business insights and decisions. Your role involves harnessing large sets of data to identify trends, forecast demand, and optimize our services to enhance customer satisfaction. You will collaborate closely with various departments, including marketing, sales, and customer service, to support our mission of delivering exceptional travel experiences. This position is key to driving data-driven strategies that improve our operational efficiency and market positioning.Role & ResponsibilitiesData Collection and Management: Gather data from multiple sources, ensuring accuracy and integrity in data handling.Statistical Analysis: Apply statistical techniques to analyze data and generate useful business insights.Trend Identification: Identify patterns and trends in complex data sets to aid in prediction and decision-making processes.Reporting: Develop regular reports on key metrics for internal teams to monitor and analyze business performance.Data Visualization: Create effective charts, graphs, and dashboards to represent data visually for easier comprehension and presentation.Collaborative Analysis: Work with cross-functional teams to address business challenges and identify data-driven solutions.Performance Monitoring: Track the effectiveness of data-driven initiatives and recommend improvements based on outcomes.Advanced Analytics: Use advanced analytic techniques such as machine learning or predictive modeling to enhance business forecasts and strategies.Database Management: Maintain databases, ensuring both the security of sensitive data and the accessibility for user queries.Ad Hoc Analysis: Perform ad hoc analysis as needed to assist with urgent business decisions or strategic planning.Preferred Candidate ProfileAnalytical Skills: Strong background in statistical analysis, data interpretation, and turning data into actionable insights.Technical Proficiency: Proficient with SQL databases, Python or R, and data visualization tools such as Tableau or PowerBI.Experience with Big Data: Familiarity with big data technologies and frameworks, including Hadoop or Spark.Detail-Oriented: Ability to meticulously analyze complex data while maintaining accuracy and focus on minute details.Problem-Solving: Excellent problem-solving skills to identify solutions based on data analysis.Communication Skills: Strong ability to communicate complex data in a clear and effective manner to non-technical stakeholders.Educational Background: Preferably a degree in Statistics, Mathematics, Computer Science, or a related field.Project Management: Experience in managing projects, including planning, executing, and tracking analytics projects.Team Collaboration: Ability to work effectively in team environments, collaborating with both technical and non-technical team members.Industry Knowledge: Knowledge of the travel industry is a plus, with an understanding of its data sources and key performance metrics.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Travel Arrangements"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Machine Learning",
      "Hadoop",
      "Spark",
      "Tableau"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_020"
  },
  {
    "job_id": "staff-forecasting-data-analyst-at-linkedin-4339212886",
    "title": "Staff Forecasting & Data Analyst",
    "company": "LinkedIn",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-27",
    "job_url": "https://in.linkedin.com/jobs/view/staff-forecasting-data-analyst-at-linkedin-4339212886?position=12&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=oCgw2fWvYOC6zL5BhtfkuQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424082",
    "description": "Company DescriptionLinkedIn is the world’s largest professional network, built to create economic opportunity for every member of the global workforce. Our products help people make powerful connections, discover exciting opportunities, build necessary skills, and gain valuable insights every day. We’re also committed to providing transformational opportunities for our own employees by investing in their growth. We aspire to create a culture that’s built on trust, care, inclusion, and fun – where everyone can succeed.Join us to transform the way the world works.Job DescriptionAs a Staff Forecasting & Data Analyst, you will lead the analytical and modeling efforts that inform long-term workforce strategy and investment decisions. This role sits at the intersection of data science, business strategy, and operational planning, blending quantitative rigor with strategic foresight to align the deployment of human and financial resources with the Trust’s competitive strategy, efficiency plans, and budget.You’ll partner cross-functionally with Operations, Product, Data Science, Finance, and Engineering to design forecasting frameworks that anticipate change—whether driven by product innovation, policy shifts, or market dynamics—and translate those insights into actionable workforce strategies.At LinkedIn, our approach to flexible work is centered on trust and optimized for culture, connection, clarity, and the evolving needs of our business. The work location of this role is hybrid, meaning it will be performed both from home and from a LinkedIn office on select days, as determined by the business needs of the team.Responsibilities:Own long-range forecasting models that project volume, capacity, and productivity across Trust lines of business.Maintain quarterly cross-correlation analysis tied to company growth and cross-functional initiatives.Analyze historical and emerging trends in product, policy, and user behavior to anticipate operational impact.Develop strategic scenarios that inform resource allocation, efficiency targets, and workforce investments.Partner with cross-functional leaders to align planning assumptions with business priorities, budget constraints, and growth opportunities.Translate data into strategy: distill complex modeling outcomes into clear, actionable recommendations for executives.Design scalable data infrastructure and forecasting tools in partnership with Data Science and Engineering.Automate data integration and updates in operational systems (e.g., NICE IEX, internal data tables).Monitor guardrail metrics (utilization, forecast accuracy, productivity) to ensure sustainable operational health and early detection of risk.Mentor analysts across the Resource Planning team, uplifting the analytical bar and fostering a culture of strategic thinking and data excellence.QualificationsBasic Qualifications: Bachelor's degree in Engineering, Business, Statistics, Operations Management, Economics, or related field.8+ years of experience in forecasting, workforce planning, or predictive analytics within large-scale, global operations.Expertise in forecast modeling techniques (e.g., time-series, regression, scenario simulation) using SQL, Python, R, or similar tools.Background in business fundamentals with the ability to connect data insights to strategic decisions and operational levers.Proven ability to simplify complex systems, identify leading indicators, and communicate implications clearly to executives.Experience collaborating across Product, Finance, Data Science, and Operations organizations.Exceptional communication and storytelling skills with an ability to influence at senior levels.A passion for efficiency, scalability, and sustainable growth.Good communication skills to collaborate with cross-functional teams and present business insights effectively.Detail-oriented and organized, with the ability to handle large datasets and manage multiple priorities and tasks in a fast-paced environment.Ability to challenge incoming requests, value, and impact, driving data-driven decisions.Flexibility and adaptability to respond to changing business needs and priorities.Preferred Qualifications:Strong predictive analytical and strategic thinking skills with experience in long-range forecasting and scenario planning.Ability to translate complex data into clear business insights and executive recommendations.Skilled at identifying trends, risks, and opportunities that inform workforce and investment strategiesProficient in SQL, Excel, and Power BI, Tableau; working knowledge of Python or R for statistical analysis and automation.5+ years of experience in forecasting methodologies (time-series, regression, simulation).Comfortable working with large data sets and partnering with Data Science and Engineering on model design.Excellent communication, influence, and storytelling skills for senior audiences.Passion for simplification, scalability, and continuous improvement.KafkaGitHub KnowledgeExperience with workforce management software and toolsKnowledge of workforce management principles, operations, and industry best practices.Suggested Skills:Data Analytics & AutomationStatistical & Quantitative AnalysisForecasting Modeling & TechniquesCommunication & StorytellingDecision Support & Problem SolvingYou will Benefit from our Culture:We strongly believe in the well-being of our employees and their families. That is why we offer generous health and wellness programs and time away for employees of all levels.Additional InformationIndia Disability Policy LinkedIn is an equal employment opportunity employer offering opportunities to all job seekers, including individuals with disabilities. For more information on our equal opportunity policy, please visit https://legal.linkedin.com/content/dam/legal/Policy_India_EqualOppPWD_9-12-2023.pdfGlobal Data Privacy Notice for Job Candidates Please follow this link to access the document that provides transparency around the way in which LinkedIn handles personal data of employees and job applicants: https://legal.linkedin.com/candidate-portal.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Statistics",
      "SSIS",
      "ETL",
      "Power BI"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_001"
  },
  {
    "job_id": "data-engineer-at-otelier-4321805448",
    "title": "Data Engineer",
    "company": "Otelier",
    "location": "Colombo District, Western Province, Sri Lanka",
    "posted_date": "2025-11-11",
    "job_url": "https://lk.linkedin.com/jobs/view/data-engineer-at-otelier-4321805448?position=3&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=zglZdOuRAosZtnk3TlETEA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424093",
    "description": "DescriptionWe’re looking for a hands-on Data Engineer to join our team. In this role, you’ll be responsible for ensuring the accuracy and performance of our data pipelines and reporting tools, used daily by hotel groups for revenue management. You'll troubleshoot the platform, analyse data issues, and work closely with developers and customer support to keep everything running smoothly.RequirementsWhat you’ll doAnalyse and resolve data issues affecting reports and business logic Maintain and improve data pipelines using Microsoft SQL Server, SSIS and SSAS Monitor data loads and investigate discrepancies or failures Work closely with developers to test and validate changes to stored procedures, models and business rules Support customer support teams by investigating technical issues raised by users Assist with building and maintaining Power BI dashboards and datasets Help improve internal tools, documentation and monitoring processes What You Bring3+ years of experience in data engineering or a similar role Strong T-SQL skills and proven experience developing and optimising complex stored procedures in MS SQL Server Experience with SSIS and SSAS Familiarity with Power BI and building or maintaining reports Solid troubleshooting skills with a proactive approach to solving technical issues Experience with Git and version-controlled environments Ability to understand and work with legacy code (VB.NET and/or C#) is a plus Clear and confident communication in English (spoken and written) A calm, reliable and collaborative working style.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Hospitality"
    },
    "skills": [
      "SQL",
      "SQL Server",
      "Git",
      "SSIS",
      "Power BI"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_003"
  },
  {
    "job_id": "senior-data-engineer-at-gallagher-4324284761",
    "title": "Senior Data Engineer",
    "company": "Gallagher",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-25",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-at-gallagher-4324284761?position=10&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=wT9PIRNXoOZSJS7c8mUl8w%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424096",
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_004"
  },
  {
    "job_id": "data-engineer-at-axiata-digital-labs-4336111832",
    "title": "Data Engineer",
    "company": "Axiata Digital Labs",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-14",
    "job_url": "https://lk.linkedin.com/jobs/view/data-engineer-at-axiata-digital-labs-4336111832?position=11&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=aKA1vsx4UJjU%2B8o0GUVFXg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424098",
    "description": "Key ResponsibilitiesData Operations & Pipeline SupportAssist in ingesting, collecting, validating, and storing structured/unstructured batch data coming through Edge nodes or direct DB connectionsSupport ETL/ELT jobs running on Hadoop, Hive, Impala, and SparkMonitor daily data loads, troubleshoot failures, and ensure data availability for analytics use casesMaintain HDFS directory structure, Hive tables, and data partitionsPerform file-level data quality checks and checksum validations and table level validations for data consistencyPlatform & Infrastructure OperationsSupport the operation of on-prem Hadoop clusters (Cloudera)Assist in OS-level tasks: log checks, service restarts, disk usage monitoring, user/permission handlingAssist in regular Big Data cluster health checksSupport platform upgrades, patches, configuration changes, and security hardening efforts managed by the senior engineerWork with network and system teams during installation, troubleshooting, or hardware issuesTools & TechnologiesAssist in running and maintaining data flows involving Hive, Impala, HDFS, Spark, Kafka (basic), HBase (basic), and Linux environmentsUse tools like NiFi/SFTP for data movement with NiFi flow development & NiFi cluster managementSupport API-based data push/pull if required for integrationsData Governance & DocumentationMaintain metadata, data dictionary updates, and platform documentationEnsure compliance with Kerberos/LDAP authentication and Cloudera Navigator governance processesRecord operational runbooks and incident logsCollaboration & SupportWork under the senior engineer to ensure continuous operations of the client environmentParticipate in joint troubleshooting with Client team during data-source onboardingProvide L1/L2 support for data ingestion, cluster operations, and daily job executionsWork Complexity and Role ExpectationWork on assigned operational tasks within the Big Data platform under guidanceSupport development, testing, and automation of simple data flowsInvolve in routine batch workloads, testbed validationsParticipate as a team member in platform enhancements, monitoring improvements, and data integration activitiesPerson SpecificationsEducationBachelors degree in computer science, IT, Electronics/Telecom Engineering, or a related fieldTechnical SkillsBasic knowledge of Hadoop ecosystem: HDFS, Hive, Spark, Yarn (hands-on exposure is an added benefit)Familiarity with Linux shell commands; ability to navigate logs and servicesGood understanding of SQL able to write and troubleshoot complex queriesExposure to Python/Scala/Java is an added advantageBasic understanding of data pipelines, ETL processes, and batch data workflowsExposure to Cloudera platform is a plusExperience1 - 2 years of experience in Data Engineering, Database operations, or Big Data platform supportExperience in telecom domain or enterprise data environments is an added advantageSoft SkillsGood analytical and troubleshooting mindsetAbility to collaborate with senior engineers and follow structured operational practicesEffective communication and willingness to learn complex distributed systems",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Contract",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Java",
      "Scala",
      "SQL",
      "Linux",
      "Hadoop",
      "HDFS",
      "Hive",
      "HBase",
      "Kafka",
      "ETL",
      "ELT"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_005"
  },
  {
    "job_id": "data-engineer-at-qoria-sri-lanka-4336413918",
    "title": "Data Engineer",
    "company": "Qoria Sri Lanka",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/data-engineer-at-qoria-sri-lanka-4336413918?position=12&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=DGyq383buTecfG109rljnA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424100",
    "description": "Want to deliver tech with purpose, with people who care?Join us in our mission to create solutions that help keep children safe online.Who are we?Headquartered in Perth, Australia, with offices globally including in Colombo, Sri Lanka, Qoria is an ASX listed global leader in child digital safety technology and services. We are a purpose-driven business, operating under the ‘Linewize’ brand in North America and Asia Pacific, the ‘Smoothwall’ brand in the UK, 'Octopus BI' in Sri Lanka and the ‘Qoria’ brand in EMEA. Our solutions are utilised by schools, school districts, and parental communities to protect children from seeing harmful content online, identify children at risk based on their digital behaviours and ensure teachers maintain focus and safe learning in the digital classroom. 30,000 schools and 7 million parents depend on our solutions to keep 25 million children safe in 180 countries around the world.What’s the opportunity?We are seeking a highly motivated and skilled Data Engineer with strong expertise in SQL, Java, Python, and cloud-based data platforms to join our growing data team. In this role, you will be responsible for designing, developing, and optimizing data pipelines, warehouses, and analytics solutions on GCP and big data platforms. You will collaborate closely with BI teams to support data modeling, reporting, and analytics initiatives while gaining hands-on experience with advanced data engineering technologies.This role is ideal for professionals with prior experience in data engineering who are looking to solve complex analytical problems and work with large-scale data systems.Key ResponsibilitiesDesign, develop, and optimize SQL queries and scripts for data transformation, aggregation, and integration.Build, maintain, and enhance scalable ETL/ELT pipelines on Big Data platforms.Support development and optimization of relational and NoSQL databases, data warehouses, and data lakes.Work with cloud-native GCP services, including BigQuery, Cloud Spanner, Workflow and Dataflow, to enable high-performance data processing.Apply version control and collaborative development practices using tools like Git.Implement workflow orchestration and support data modeling efforts with the BI team.Collaborate with cross-functional teams to ensure data quality, integrity, and security.Solve complex analytical problems leveraging SQL, data engineering tools, and programming expertise with Java and Python.Participate in sprint planning, code reviews, and quality assurance processes.Stay current with modern data engineering tools, machine learning workflows, and best practices.RequirementsBachelor’s degree in Computer Science, Data Science, or a related technical field.Strong experience in SQL with hands-on expertise in writing optimized queries.Proficiency in Java and Python for data engineering and analytics tasks.Hands-on experience with cloud platforms, particularly GCP.Experience in OLTP and OLAP databases.Knowledge of ETL/ELT development, workflow orchestration, and data modeling.Familiarity with version control tools (e.g., Git).Experience solving complex analytical problems using data engineering tools.Experience with Apache data engineering services. (e.g., Apache Beam, Spark, Kafka, Airflow). The experience with Apache Beam will be an added advantage.Exposure to machine learning languages and frameworks.Familiarity with statistical methods for data analysis and reporting.Career Growth PathThis role is designed to evolve into a senior Data Engineer, Analytics Engineer, or Data Scientist role, offering increasing responsibility in designing scalable data solutions, advanced analytics, and machine learning workflows.",
    "criteria": {
      "Seniority level": "Executive",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Technology, Information and Internet, IT System Data Services, and Data Infrastructure and Analytics"
    },
    "skills": [
      "Python",
      "Java",
      "SQL",
      "Machine Learning",
      "BigQuery",
      "NoSQL",
      "Data Modeling",
      "GCP",
      "Dataflow",
      "Git",
      "Kafka",
      "Apache Beam",
      "Airflow",
      "ETL",
      "ELT"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_006"
  },
  {
    "job_id": "senior-data-engineer-databricks-at-alp-consulting-ltd-4323480397",
    "title": "Senior Data Engineer - Databricks",
    "company": "Alp Consulting Ltd.",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-20",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-databricks-at-alp-consulting-ltd-4323480397?position=19&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=RuPCvRTQ6EmDX68J78t3Yw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424102",
    "description": "We are seeking an AWS Data Engineer Senior with a strong background in AWS, PySpark, and Redshift. The ideal candidate will have hands-on experience in building and optimizing data pipelines, developing robust ETL workflows, and leveraging modern data engineering tools and platforms. Exposure to dbt (Data Build Tool) is a plus, as the role involves collaboration on end-to-end data transformation and modelling workflows. Must have experience: Design, build, and maintain scalable pipelines using PySpark on AWS.Knowledge of Databricks on AWS is a mustHave work with AWS services such as S3, Glue, EMR, and Redshift for data storage, transformation, and querying.Hands-on experience with Redshift, including performance tuning and data modelling. Strong SQL skills with experience in querying and optimizing large datasets.Manage and monitor data workflows using orchestration tools like Apache AirflowKnowledge of CI/CD workflows for data engineering projects.Utilize Git for version control, ensuring proper collaboration and tracking of code changes.Establish and follow best practices for repository management, branching, and code reviews.Good to have DBT Exposure -Contribute to DBT transformations and assist in setting up data modeling workflows.Working experience on Agile and Scrum methodologiesWhat We Offer:Competitive salary and benefits package.Hybrid work environment, offering flexibility in how you work.Opportunity to work with global industry leaders.A dynamic and collaborative team environment where your contributions are valued and impactful.Ongoing professional development and career growth opportunities.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology, Consulting, and Other",
      "Industries": "Staffing and Recruiting, Software Development, and Information Services"
    },
    "skills": [
      "SQL",
      "Redshift",
      "Databricks",
      "Data Modeling",
      "AWS",
      "S3",
      "CI/CD",
      "Git",
      "PySpark",
      "dbt",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_008"
  },
  {
    "job_id": "azure-data-engineer-at-dijital-team-4322691222",
    "title": "Azure Data Engineer",
    "company": "Dijital Team",
    "location": "Sri Lanka",
    "posted_date": "2025-11-14",
    "job_url": "https://lk.linkedin.com/jobs/view/azure-data-engineer-at-dijital-team-4322691222?position=21&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=K5M0dvq8h8EciSM8ityz5Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424105",
    "description": "We are seeking an experienced and dynamic Azure Data Engineer to lead data engineering engagements, design scalable data solutions, and help clients unlock the full potential of their data. You will act as a trusted advisor, providing technical leadership and strategic guidance while working on cutting-edge Microsoft Azure technologies.Duties And ResponsibilitiesTechnical Leadership Design and implement scalable, secure, and high-performing data pipelines and data platforms on Microsoft Azure. Lead solution architecture discussions for Azure-based data engineering solutions, including data lakes, data warehouses, and data integration pipelines. Advise clients on best practices, governance frameworks, and modern data architecture strategies. Drive innovation by leveraging Microsoft services such as Microsoft Fabric, Azure Synapse, Azure Data Factory, Azure Databricks, Azure Data Lake, and Azure Purview. Technical Management & Delivery Oversee the end-to-end delivery of data engineering projects, ensuring quality, scope, and timelines are met. Manage project teams, ensuring efficient task delegation and mentoring team members in Azure tools and techniquesCollaborate with stakeholders to define technical requirements and deliver solutions aligned with business goalsClient Engagement Act as a trusted advisor to clients, providing insights and recommendations for data strategy and architecture. Conduct workshops, technical demonstrations, and proof-of-concept (POC) projects to showcase Azure's capabilities. Foster long-term client relationships and identify opportunities for future engagements. Innovation & Knowledge SharingStay updated on emerging trends in Azure Data and AI technologies and share knowledge with internal teams. Develop reusable frameworks, accelerators, and best practices to enhance project delivery efficiency. Contribute to thought leadership initiatives, including whitepapers, blogs, and conference presentations. Collaborate with Microsoft and other partners to secure funding and co-develop innovative solutionsPractice Growth: Support pre-sales efforts by crafting proposals, developing demos, and estimating project delivery costs. Contribute to Agile Insights' thought leadership by participating in industry events, panels, and conferences. Build and nurture a network of client relationships, identifying opportunities to expand Agile Insights’ presence in the market. Required Experience/SkillsRequired Skills & Qualifications Experience: 5+ to 8+ years of experience in data engineering, with at least 5 years working with Microsoft Azure technologies. Proven experience in delivering large-scale data solutions for enterprise clients. Technical Expertise: Hands-on experience with Azure Synapse Analytics, Azure Data Factory, Azure Databricks, Azure Data Lake, and Azure SQL Database. Strong proficiency in data modelling, ETL/ELT processes, and designing scalable data pipelines. Proficiency in Python, PySpark, SQL, or similar programming languages. Knowledge of cloud security, compliance, and governance frameworks. Knowledge on Microsoft Fabric is highly desirable. Hands-on experience on CI/CD deployments using Azure DevOps. Familiarity with BI tools like Power BI is a plus. Certifications (preferred): Microsoft Certified: Azure Data Engineer Associate Microsoft Certified: Azure Solutions Architect Expert Microsoft Certified: Fabric Analytics Engineer Associate Other relevant Azure certifications We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Transportation, Logistics, Supply Chain and Storage"
    },
    "skills": [
      "Python",
      "SQL",
      "Databricks",
      "Azure",
      "Azure DevOps",
      "Azure Synapse",
      "Azure Data Factory",
      "Microsoft Fabric",
      "CI/CD",
      "PySpark",
      "ETL",
      "Power BI"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_009"
  },
  {
    "job_id": "senior-data-engineer-snowflake-at-alp-consulting-ltd-4322925352",
    "title": "Senior Data Engineer - Snowflake",
    "company": "Alp Consulting Ltd.",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-alp-consulting-ltd-4322925352?position=32&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=CQrx4GvV1tpaqQUXzJcZ6Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424107",
    "description": "We’re looking for candidates with strong technology and data understanding in data engineering space, having proven delivery capability. This is a fantastic opportunity to be part of a leading firm as well as a part of a growing Data and Analytics team.To qualify for the role, you must haveBe a computer science graduate or equivalent with 3 to 7 years of industry experienceHave working experience in an Agile base delivery methodology (Preferable)Flexible and proactive/self-motivated working style with strong personal ownership of problem resolution.Good analytical skills and enjoys solving complex technical problemsProficiency in Software Development Best Practices Good debugging and optimization skillsGood communicator (written and verbal formal and informal).What We Offer:Competitive salary and benefits package.Hybrid work environment, offering flexibility in how you work.Opportunity to work with global industry leaders.A dynamic and collaborative team environment where your contributions are valued and impactful.Ongoing professional development and career growth opportunities.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology, Consulting, and Other",
      "Industries": "Staffing and Recruiting, Information Services, and Software Development"
    },
    "skills": [
      "Analytics",
      "Agile"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_011"
  },
  {
    "job_id": "senior-data-engineer-snowflake-at-alp-consulting-ltd-4322907141",
    "title": "Senior Data Engineer- Snowflake",
    "company": "Alp Consulting Ltd.",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-snowflake-at-alp-consulting-ltd-4322907141?position=41&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=aqe3zEAFMocDsS0xmce%2BFQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424109",
    "description": "We’re looking for candidates with strong technology and data understanding in data engineering space, having proven delivery capability. This is a fantastic opportunity to be part of a leading firm as well as a part of a growing Data and Analytics team. Your key responsibilitiesDevelop & deploy snowflake DW in a cloud environment on AWS or AzureSource System Analysis, Data Modelling, ETL development, and deployment to Cloud ServiceInteract with Onshore, understand their business goals, contribute to the delivery of the workstreamsContribute towards EY Snowflake competency building initiatives outside your project.Skills and attributes for success3 to 7 years of Hands-on experience in the field of data warehousing, ETL Hands on development experience in Snowflake. Experience in Snowflake modelling - roles, schema, databases. Experience in Integrating with third-party tools, ETL, DBT tools Experience in Snowflake advanced concepts like setting up resource monitors and performance tuning would be preferableStrong programming knowledge in SQLApplying object-oriented and functional programming styles to real-world problems using Scala/PythonStrong knowledge in implementing Snowflake core features such as Cloning, Sharing, Streams, Tasks and Pipes.Develop data pipelines to perform batch and Real - Time/Stream analytics on structured and unstructured data. Basic understanding of AWS S3, Lambda, EMR, Glue Good understanding of different file format (ORC, Parquet, AVRO) to optimize queries/processing and compression techniques Familiar with DevOps. Preferable – having deployment knowledgeTo qualify for the role, you must haveBe a computer science graduate or equivalent with 3 to 7 years of industry experienceHave working experience in an Agile base delivery methodology (Preferable)Flexible and proactive/self-motivated working style with strong personal ownership of problem resolution.Good analytical skills and enjoys solving complex technical problemsProficiency in Software Development Best Practices Good debugging and optimization skillsGood communicator (written and verbal formal and informal).",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Consulting, Information Technology, and Other",
      "Industries": "Staffing and Recruiting, Technology, Information and Media, and Software Development"
    },
    "skills": [
      "Scala",
      "SQL",
      "Snowflake",
      "AWS",
      "S3",
      "Lambda",
      "dbt",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_012"
  },
  {
    "job_id": "senior-data-engineer-architect-at-therighttalent-4324813751",
    "title": "Senior Data Engineer/Architect",
    "company": "Therighttalent",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-27",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-architect-at-therighttalent-4324813751?position=50&pageNum=0&refId=u0fc8jvymK%2FSedaXyW5mbg%3D%3D&trackingId=NcGqOPb9B%2BEzbow88a7IRw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424111",
    "description": "About Our Client PartnerOur client is a leading, diversified conglomerate with major operations spanning in diverse industries. The organization is undergoing a significant digital and AI transformation, establishing a robust data foundation to power enterprise-wide decision-making and next-generation analytics. This role sits within a centralized Group function, responsible for designing and building the scalable, cloud-native data platforms that connect business data to strategic insights.Role SummaryWe are seeking an experienced Data Engineers to lead the design, construction, and optimization of the Group's enterprise data platform and ETL/ELT pipelines. This pivotal role will define the technical architecture for the movement and storage of data, ensuring it is readily available, governed, and performant for consumption by the Group AI & Advanced Analytics team and various business applications. The Architect will bridge the gap between business requirements and scalable cloud infrastructure.Key ResponsibilitiesData Architecture and Platform DesignDesign and implement the Group-wide, cloud-native data architecture (e.g., Data Lake, Data Warehouse, Data Mesh principles) to support analytics, reporting, and Machine Learning workloads.Define technical standards and best practices for data storage, security, quality, and governance across all data assets.Select and evaluate technologies for the data stack, ensuring compatibility with major cloud platforms (e.g., Azure/AWS/GCP).Data Pipeline Development (ETL/ELT)Build, manage, and optimize scalable ETL/ELT pipelines to ingest data from diverse source systems (e.g., SAP ERP, CRM, operational databases) into the centralized data platform.Implement robust data quality checks, monitoring, and error handling within data pipelines.Utilize modern data processing frameworks (e.g., Spark, Databricks) and orchestration tools (e.g., Airflow) for automation and efficiency.Solution Architecture and IntegrationAct as the technical Solution Architect for analytics projects, translating data science models (from the AI team) and business requirements into concrete data flow designs and production-ready deployments.Ensure seamless integration between the core data platform and consumption layers, including BI tools (Power BI), internal APIs, and front-end applications.Partner with IT and Security teams to ensure all data solutions meet enterprise-level security and compliance standards.Mentorship and DocumentationProvide technical leadership and mentorship to junior data engineers, fostering skills in cloud data services and modern data modeling techniques.Develop and maintain comprehensive technical documentation, including data dictionaries, platform diagrams, and ETL/ELT process flows.RequirementsTypically 3-8 years of experience in Data Engineering, Data Architecture, or a related role, with proven experience designing and deploying end-to-end data solutions in a cloud environment preferred.Technical Expertise:Programming: Advanced proficiency in SQL and Python is mandatory.Cloud: Hands-on experience designing and operating services in at least one major cloud platform (Azure preferred, AWS, or GCP), specifically involving data services (e.g., Azure Data Factory, Azure Synapse, S3/Redshift).Data Modeling: Strong expertise in relational and non-relational database design and modern data modeling techniques (e.g., dimensional modeling, Data Vault).Systems Knowledge: Familiarity with enterprise systems, particularly SAP ERP data structures, is highly desirable.Education: Bachelor’s or Master’s degree in Computer Science, Engineering, Information Systems, or a related quantitative field.Attributes: Strong analytical and problem-solving skills, excellent communication abilities to clearly articulate technical designs to both technical and business stakeholders.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology, Other, and Project Management",
      "Industries": "Software Development, Information Services, and IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "SQL",
      "Machine Learning",
      "Redshift",
      "Databricks",
      "Data Modeling",
      "AWS",
      "Azure",
      "GCP",
      "S3",
      "Azure Synapse",
      "Azure Data Factory",
      "Data Lake",
      "Airflow",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_013"
  },
  {
    "job_id": "python-data-engineer-at-deloitte-4340656301",
    "title": "Python Data Engineer",
    "company": "Deloitte",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-15",
    "job_url": "https://in.linkedin.com/jobs/view/python-data-engineer-at-deloitte-4340656301?position=1&pageNum=0&refId=k8j52IhU5PF9%2B2e07g9vNg%3D%3D&trackingId=ZOJrw64w9FfW8Jodvphq3w%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424120",
    "description": "Your potential, unleashed.India’s impact on the global economy has increased at an exponential rate and Deloitte presents an opportunity to unleash and realize your potential amongst cutting edge leaders, and organizations shaping the future of the region, and indeed, the world beyond.At Deloitte, your whole self to work, every day. Combine that with our drive to propel with purpose and you have the perfect playground to collaborate, innovate, grow, and make an impact that matters.The TeamDeloitte’s Technology & Transformation practice can help you uncover and unlock the value buried deep inside vast amounts of data. Our global network provides strategic guidance and implementation services to help companies manage data from disparate sources and convert it into accurate, actionable information that can support fact-driven decision-making and generate an insight-driven advantage. Our practice addresses the continuum of opportunities in business intelligence & visualization, data management, performance management and next-generation analytics and technologies, including big data, cloud, cognitive and machine learning.Work you’ll doTotal Experience - 7 to 11 YearsRelevant Experience - 5+Location - BangaloreRoles and Responsibilities:The Data Engineer will work on data engineering projects for various business units, focusing on delivery of complex data management solutions by leveraging industry best practices. They work with the project team to build the most efficient data pipelines and data management solutions that make data easily available for consuming applications and analytical solutions. A Data engineer is expected to possess strong technical skills.Experience: -Knowledge of and skills in various programming languages primarily PythonMust have knowledge on Back-end frameworks, Pandas, Numpy, Matplotlib/SeabornThorough understanding of containers and functions. Deployment experience with Kubernetes (K8s) or Functions is highly desirable.Experience using Cloud Native CI/CD tools (Azure Pipelines/Circle CI/Jenkins X).Experience deploying workloads to AWS or Azure with strong knowledge and understanding of the cloud provider's API / associated services and infrastructureExperience in test driven development & writing of unit and integration tests is a mustKnowledge of other Cloud (Google Cloud Platform, Cloudera etc), and Integration services technologies is highly desirable.Experience working in agile teams with demonstrated application of the principles.Demonstrable proficiency in developing complex JavaScript applications.Experience of working with lean startup/agile development methodologiesStrong analytical, problem-solving, and troubleshooting skills.Experienced with modern coding, testing, debugging and automation techniques.Rave about the benefits of CI/CDHave a high bar for user experience and quality.You are data driven and customer obsessed.Good communication skills.Key CharacteristicsAvailability to solve production issues/taking ownership of interfaces deployed on prod etcUnderstanding in RDBMS and NoSQL databases (e.g., PostgreSQL, MongoDB).Ability to troubleshoot and resolve database issues.In-depth knowledge and experience in RESTful API interfaces.Comprehensive understanding of ETL processes from end-to-end.Technology champion who constantly pursues skill enhancement and has inherent curiosity to understand work from multiple dimensions.Interest and passion in Big Data technologies and appreciates the value that can be brought in with an effective data management solution.Has worked on real data challenges and handled high volume, velocity, and variety of data.Is proficient in designing data integrations and data processes across different types of architecture patterns using native cloud services, or custom application codesExcellent analytical & problem-solving skills, willingness to take ownership and resolve technical challenges.Contributes to community building initiatives like CoE, CoP.Mandatory SkillsProgramming Languages: Proficiency in Python and PySpark is paramount. Should have knowledge of data processing using Pandas, Numpy and relevant libraries to handle data.Databases: Strong knowledge of SQL and NoSQL databasesBig Data Technologies: Experience with frameworks like Apache Spark, Hadoop, and Kafka for processing large datasetsCloud Computing: Familiarity with cloud platforms like Azure(preferred)/AWS(good to have) and their data services (e.g., Data Factory, Databricks, Synapse, Redshift)ETL/ELT & Data Warehousing: Expertise in designing and implementing ETL (Extract, Transform, Load) processes, and data modelling for efficient data warehousingData Pipelines: Ability to develop, optimize, and maintain robust and scalable data pipelinesShould have a good understanding of optimization techniques and able to resolve performance bottlenecksKnowledge of web frameworks and API is beneficialHow you’ll growAt Deloitte, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn. We offer opportunities to help build world-class skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal developmentPrograms at Deloitte University, our professionals have a variety of opportunities to continue to grow throughout their career. Explore Deloitte University, The Leadership Centre.BenefitsAt Deloitte, we know that great people make a great organization. We value our people and offer employees a broad range of benefits. Learn more about what working at Deloitte can mean for you.Our purpose Deloitte is led by a purpose: To make an impact that matters.Every day, Deloitte people are making a real impact in the places they live and work. We pride ourselves on doing not only what is good for clients, but also what is good for our people and the communities in which we live and work—always striving to be an organization that is held up as a role model of quality, integrity, and positive change. Learn more about Deloitte's impact on the worldInterview tipsWe want job seekers exploring opportunities at Deloitte to feel prepared and confident. To help you with your interview, we suggest that you do your research: know some background about the organization and the business area you’re applying to. Check out recruiting tips from Deloitte professionals.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering, Information Technology, and Consulting",
      "Industries": "IT Services and IT Consulting, Software Development, and Business Consulting and Services"
    },
    "skills": [
      "Python",
      "JavaScript",
      "SQL",
      "Machine Learning",
      "Pandas",
      "NumPy",
      "Matplotlib",
      "PostgreSQL",
      "MongoDB",
      "Redshift",
      "Databricks",
      "NoSQL",
      "AWS",
      "Azure",
      "Google Cloud",
      "Data Factory",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Apache Spark",
      "PySpark",
      "Hadoop",
      "Kafka",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_026"
  },
  {
    "job_id": "data-engineer-at-deloitte-4340443717",
    "title": "Data Engineer",
    "company": "Deloitte",
    "location": "Mumbai, Maharashtra, India",
    "posted_date": "2025-11-13",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-at-deloitte-4340443717?position=4&pageNum=0&refId=k8j52IhU5PF9%2B2e07g9vNg%3D%3D&trackingId=bINzRPZerl7AaotVewGepA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424126",
    "description": "Your potential, unleashed.India’s impact on the global economy has increased at an exponential rate and Deloitte presents an opportunity to unleash and realise your potential amongst cutting edge leaders, and organisations shaping the future of the region, and indeed, the world beyond.At Deloitte, your whole self to work, every day. Combine that with our drive to propel with purpose and you have the perfect playground to collaborate, innovate, grow, and make an impact that matters.Job SummaryWe are seeking a skilled and detail-oriented Data Engineer with deep expertise in Azure, SQL Server, and Databricks to design, build, and manage scalable data pipelines and enterprise data solutions. This role will be critical in supporting our analytics, reporting, and data science initiatives by delivering high-quality, reliable, and performant data systems.Key ResponsibilitiesDesign, develop, and manage ETL/ELT pipelines using Azure Data Factory (ADF) and Databricks for batch and real-time data processing.Integrate data from various structured and unstructured sources including SQL Server, Azure SQL Database, Azure Data Lake Storage (ADLS), and external APIs.Build and maintain data models, data marts, and data warehouses using SQL Server and Azure Synapse Analytics.Write efficient and optimized SQL queries, stored procedures, views, and triggers in SQL Server.Use Databricks (Spark with Python/Scala) to process large datasets for transformation and analytics.Ensure data quality, integrity, security, and compliance across the pipeline using data validation, monitoring, and auditing techniques.Collaborate with data analysts, data scientists, and business stakeholders to define and deliver data solutions.Implement CI/CD pipelines using Azure DevOps .Monitor and optimize the performance of data pipelines and queries across Azure and SQL Server environments.Required Skills & Qualifications:Bachelor’s degree in Computer Science, Engineering, Information Systems, or related field.5+ years of experience in data engineering or related roles.Proven experience with:Azure Data Services: Data Factory, ADLS, Azure SQL, Azure SynapseDatabricks (Azure implementation), including experience with Spark (Python or Scala).Microsoft SQL Server: Writing advanced SQL, stored procedures, and performance tuning.Strong understanding of data warehousing concepts, ETL/ELT best practices, and data modelling (star/snowflake schema).Familiarity with data governance, RBAC, and data security practices in Azure.Experience with CI/CD tools like Azure DevOps and version control with Git.Excellent problem-solving skills and the ability to work collaboratively in a fast-paced environment.How you’ll growConnect for impactOur exceptional team of professionals across the globe are solving some of the world’s most complex business problems, as well as directly supporting our communities, the planet, and each other. Know more in our Global Impact Report and our India Impact Report.Empower to leadYou can be a leader irrespective of your career level. Our colleagues are characterised by their ability to inspire, support, and provide opportunities for people to deliver their best and grow both as professionals and human beings. Know more about Deloitte and our One Young World partnership.Inclusion for allAt Deloitte, people are valued and respected for who they are and are trusted to add value to their clients, teams and communities in a way that reflects their own unique capabilities. Know more about everyday steps that you can take to be more inclusive. At Deloitte, we believe in the unique skills, attitude and potential each and every one of us brings to the table to make an impact that matters. Drive your careerAt Deloitte, you are encouraged to take ownership of your career. We recognise there is no one size fits all career path, and global, cross-business mobility and up / re-skilling are all within the range of possibilities to shape a unique and fulfilling career. Know more about Life at Deloitte.Everyone’s welcome… entrust your happiness to us Our workspaces and initiatives are geared towards your 360-degree happiness. This includes specific needs you may have in terms of accessibility, flexibility, safety and security, and caregiving. Here’s a glimpse of things that are in store for you. Interview tipsWe want job seekers exploring opportunities at Deloitte to feel prepared, confident and comfortable. To help you with your interview, we suggest that you do your research, know some background about the organisation and the business area you’re applying to. Check out recruiting tips from Deloitte professionals.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting, Information Services, and Business Consulting and Services"
    },
    "skills": [
      "Python",
      "Scala",
      "SQL",
      "SQL Server",
      "Snowflake",
      "Databricks",
      "Azure",
      "Azure DevOps",
      "Azure Synapse",
      "Azure Data Factory",
      "CI/CD",
      "Git",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_029"
  },
  {
    "job_id": "data-engineer-at-procter-gamble-4298716828",
    "title": "Data Engineer",
    "company": "Procter & Gamble",
    "location": "Hyderabad, Telangana, India",
    "posted_date": "2025-11-12",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-at-procter-gamble-4298716828?position=7&pageNum=0&refId=k8j52IhU5PF9%2B2e07g9vNg%3D%3D&trackingId=6ql5ggF5sV6dPnJPNpeTxw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424127",
    "description": "Job LocationHYDERABAD OFFICE APACJob DescriptionProcter & Gamble is one of the largest FMCG (Fast Moving Consumer Goods) company in the world with strong brands like Pampers, Ariel, Always, Gillette and Oral B just to name a few. For more information about P&G the company and our brands please visit www.pg.com and our career website at pgcareers.comAre you ready to unleash your technical creativity?Innovation is the driving effort behind everything we do at P&G. Across the world, you will find thousands of scientists, engineers and developers working in manufacturing plants, innovation centers and distribution facilities.Overview Of The JobThis role reports to IT Director and will be located in India with the broader Data Engineering Team.Your teamAbout The Data Solutions & Engineering TeamWe take pride in managing the most-valuable asset of company in Digital World, called Data. Our vision is to deliver Data as a competitive advantage for our Business, by building unified data platforms, delivering customized BI tools for managers & empowering insightful business decisions through AI in Data.In this role, you'll be constantly learning, staying up to date with industry trends and emerging technologies in data solutions. You'll have the chance to work with a variety of tools and technologies, including big data platforms, machine learning frameworks, and data visualization tools, to build innovative and effective solutions.So, if you're excited about the possibilities of data, and eager to make a real impact in the world of business, a career in data solutions might be just what you're looking for. Join us and become a part of the future of digital transformation.About P&G ITDigital is at the core of P&G’s accelerated growth strategy. With this vision, IT in P&G is deeply embedded into every critical process across business organizations comprising 11+ category units globally creating impactful value through Transformation, Simplification & Innovation. IT in P&G is sub-divided into teams that engage strongly for revolutionizing the business processes to deliver exceptional value & growth - Digital GTM, Digital Manufacturing, Marketing Technologist, Ecommerce, Data Sciences & Analytics, Data Solutions & Engineering, Product Supply.Responsibilities Of The RoleUnderstand the business requirements and convert into technical design of data pipelines and data modelsWrite code to ingest, transform and harmonize raw data into usable refined modelsAnalyze multiple data sets associated with the use cases in-scope in order to effectively design and develop the most optimal data models and transformationCraft integrated systems, implementing ELT/ ETL jobs to fulfil business deliverables.Performing sophisticated data operations such as data orchestration, transformation, and visualization with large datasets.Coordinate with data asset managers, architects, and development team to ensure that the solution is fit for use and are meeting vital architectural requirements.Demonstrate standard coding practices to ensure delivery excellence and reusabilityWhat We OfferA wide range of challenging manufacturing/engineering assignments in one of the most influential companies in the world. We don’t just offer a job; we offer a career with varying assignments and lots of development opportunitiesAn opportunity for you to develop and deliver state of the art technologies supported by multi-million capital investments.Travel opportunities to the project locations to see your design come to lifeContinuous coaching– you will work with passionate people and receive both formal training as well as day-to-day mentoring from your coach and managerDynamic and respectful international work environment– employees are at the core, we value every individual and encourage initiatives, promoting agility and work/life balance.A competitive compensation package, in line with your qualifications and experienceJob QualificationsRole Requirements At least 3 years of experience in Data EngineeringHands-on experience in building data models, data pipelines, data ingestion, harmonization along with data governance.Hands-on experience in scripting language like Python, R or ScalaBackend Development expertise on SQL Database, SQL Data Warehouse or any data warehousing solutions in cloudHands-on experience of reporting tools like Power BI or TableauKnowledge in DevOps Tools and CICD tools (e.g. Azure DevOps and Github)Knowledge in cloud technologies (Azure Cloud) – at least 2 years inclusive of software engineering experience.Cloud Native application development using Angular and .Net.Knowledge in Agile or Scrum methodologies with proven track record of successful projectsGraduate of Engineering or IT related courseJust So You KnowWe are an equal opportunity employer and value diversity at our company. Our mission of Diversity and Inclusion is: “Everyone valued. Everyone included. Everyone performing at their peak”.At P&G, the hiring journey is personalized every step of the way, thereby ensuring equal opportunities for all, with a strong foundation of Ethics & Corporate Responsibility guiding everything we do.All the available job opportunities are posted either on our website - pgcareers.com, or on our official social media pages, for the convenience of prospective candidates, and do not require them to pay any kind of fees towards their application.”Job ScheduleFull timeJob NumberR000137874Job SegmentationExperienced Professionals",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Project Management, Design, and Information Technology",
      "Industries": "Manufacturing"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Angular",
      "Machine Learning",
      "Azure",
      "Azure DevOps",
      "GitHub",
      "ETL",
      "ELT",
      "Data Warehousing",
      "Power BI"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_031"
  },
  {
    "job_id": "data-engineer-at-pwc-india-4324121291",
    "title": "Data Engineer",
    "company": "PwC India",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-22",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-at-pwc-india-4324121291?position=8&pageNum=0&refId=k8j52IhU5PF9%2B2e07g9vNg%3D%3D&trackingId=9fFRT9XvQPY1rt8PX8uw8g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424129",
    "description": "About the Company: We are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. You’ll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.Level: Manager/ Senior AssociatesYears of experience: 6-11 yearsLocation: BangaloreNotice: Immediate joiners/ Serving notice periodAbout the Role: Hiring for Azure Data Engineer/Architect (Databricks)Responsibilities:Design and implement ETL/ELT pipelines using Databricks and PySpark.Work with Unity Catalog to manage data governance, access controls, lineage, and auditing across data assets.Develop high-performance SQL queries and optimize Spark jobs.Collaborate with data scientists, analysts, and business stakeholders to understand data needs.Ensure data quality and compliance across all stages of the data lifecycle.Implement best practices for data security and lineage within the Databricks ecosystem.Participate in CI/CD, version control, and testing practices for data pipelines.Qualifications:Proven experience with Databricks and Unity Catalog (data permissions, lineage, audits).Strong hands-on skills with PySpark and Spark SQL.Solid experience writing and optimizing complex SQL queries.Familiarity with Delta Lake, data lakehouse architecture, and data partitioning.Experience with cloud platforms like Azure or AWS.Understanding of data governance, RBAC, and data security standards.Preferred Skills:Databricks Certified Data Engineer Associate or Professional.Experience with tools like Airflow, Git, Azure Data Factory, or dbt.Exposure to streaming data and real-time processing.Knowledge of DevOps practices for data engineering.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "Business Consulting and Services, IT Services and IT Consulting, and Software Development"
    },
    "skills": [
      "SQL",
      "Databricks",
      "AWS",
      "Azure",
      "Azure Data Factory",
      "Delta Lake",
      "CI/CD",
      "Git",
      "PySpark",
      "Spark SQL",
      "Airflow",
      "dbt",
      "ETL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251127_032"
  },
  {
    "job_id": "devops-engineer-at-nimi-4336736251",
    "title": "DevOps Engineer",
    "company": "Nimi",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/devops-engineer-at-nimi-4336736251?position=2&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=TjK00YeNd9CvqPU3p6I8vQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424134",
    "description": "Apply NowRemote/ColomboFull timeApply NowAbout The RoleWe are looking for an experienced DevOps Engineer to join our team.Key ResponsibilitiesAs aDevOps Engineer,you WillThis is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.Develop, maintain, and enhance CI/CD pipelines to streamline deployment and infrastructure management.Automate and manage cloud infrastructure, optimizing for performance, cost, and scalability.Collaborate with software engineers to integrate DevOps best practices and tooling into the development process.Write and maintain Python scripts and applications to automate operational processes.Troubleshoot and resolve production issues, ensuring high availability and reliability of our services.Monitor and optimize system performance, implementing alerts and handling incidents.Ensure security best practices are followed across infrastructure and deployment pipelines.What We’re Looking ForMust-Have QualificationsThis is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.2+ years of experience in DevOps, SRE, or a similar role.Proficiency in Python for scripting and automation.Strong experience with CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).Hands-on experience with cloud platforms (AWS, Google Cloud Platform, or Azure).Solid understanding of infrastructure as code (IaC) tools like Terraform or CloudFormation.Experience with containerization and orchestration (Docker, Kubernetes).Knowledge of Linux administration and networking.Familiarity with monitoring tools (Prometheus, Grafana, Datadog) and logging systems.Strong problem-solving skills, with a proactive approach to managing system reliability and performance.Preferred SkillsThis is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.2+ years of experience in DevOps, SRE, or a similar role.Proficiency in Python for scripting and automation.Strong experience with CI/CD tools (e.g., Jenkins, GitLab CI, GitHub Actions).Hands-on experience with cloud platforms (AWS, Google Cloud Platform, or Azure).Solid understanding of infrastructure as code (IaC) tools like Terraform or CloudFormation.Experience with containerization and orchestration (Docker, Kubernetes).Knowledge of Linux administration and networking.Familiarity with monitoring tools (Prometheus, Grafana, Datadog) and logging systems.Strong problem-solving skills, with a proactive approach to managing system reliability and performance.What You’ll GetThis is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.This is some text inside of a div block.Why Join Us?Innovative Environment: Be part of a team that's building groundbreaking solutions.Professional Growth: Opportunities for training and career advancement.Flexible Work Arrangements: We offer flexible hours and remote work options.If you're a passionate backend developer who thrives in a collaborative environment and is eager to make an impact, we'd love to hear from you!",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "AWS",
      "Azure",
      "Google Cloud Platform",
      "CloudFormation",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Linux",
      "GitHub",
      "GitLab",
      "GitHub Actions",
      "GitLab CI",
      "Prometheus",
      "Grafana",
      "Datadog",
      "IaC",
      "SRE",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_002"
  },
  {
    "job_id": "senior-devops-engineer-at-fortude-4337671048",
    "title": "Senior DevOps Engineer",
    "company": "Fortude",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-20",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-fortude-4337671048?position=3&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=IV3q1jDnLPOh%2Fe%2BManTVig%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424136",
    "description": "ResponsibilitiesOwning Infra architecture and non-functional requirements for set of projects.Experience in Design and Integrating Cloud Architecture with Cloud-Native Solutions.Runs common infrastructure best practices focused on security, operational efficiency & cost efficiency.Strong Microservices based architecture knowledge.Strong understanding of Kubernetes and Docker.Understand usage of SecOps Practices.Demonstrated experience in developing CICD pipeline to enable faster build with quality, security automated (such as GitOps Practices would be added advantage).Experience in enabling observability embedded in the platform.Experience building & deploying cloud IAC in an AWS ( Either CrossPlane, Terraform , Cloud Formation ).Desired SkillsGood understanding of scripting and automation skills.Exposure to Linux and Windows based environments.Experience in DevOps Engineering including automation experience with configuration management tools (e.g., Ansible, Kutomize etc).Experience in CI/CD processes and Agile development.Experience in toolchains will be an added advantage (e.g., Containerization, Container Orchestrations, CI /CD, SecOps).Should be a good communicator, competent to effectively and timely communicate with all technical and nontechnical teams from different territories.Attention to detail, and good problem-solving skills.Learn new technologies and theories and apply them when necessary.Should be a good team player.Prioritize work effectively, handle multiple tasks with critical deadlines to deliver on time.EducationBachelor's degree in computer science or software engineeringExperienceMinimum 3 years of experience in DevOpsExpertise in containerization with Docker and KubernetesHands-on experience working with AWS technologies.Behavioral CompetenciesCommunicationCustomer CentricityBusiness and Market AcumenPsychological SafetyEmpathyGrowth Mindset and Learning AgilityEthical & VigilantOperational ExcellenceTeamworkAnalytical Thinking Equal Opportunity EmployerEveryone can grow at Fortude; regardless of their identity. Join us, and be a part of an organization, where we’re all proud to belong.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "AWS",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "Terraform",
      "Ansible",
      "Linux",
      "IaC",
      "GitOps",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_003"
  },
  {
    "job_id": "devops-engineer-at-mitra-ai-4324912940",
    "title": "DevOps Engineer",
    "company": "Mitra AI",
    "location": "Moratuwa, Western Province, Sri Lanka",
    "posted_date": "2025-11-27",
    "job_url": "https://lk.linkedin.com/jobs/view/devops-engineer-at-mitra-ai-4324912940?position=4&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=GeGCuS3HQ0FPnhC1v%2FGU5Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424139",
    "description": "Job Overview:We are seeking a dynamic and detail-oriented Senior Engineer who has hands-on experience in DevOps practices and a strong understanding of IT Service Management (ITSM) based on the ITIL framework. The ideal candidate will work closely with cross-functional teams to streamline processes, automate workflows, and apply DevOps principles to ensure reliable, scalable, and efficient solutions, while ensuring service delivery aligns with ITIL best practices.Key Responsibilities:DevOps Responsibilities:Design, implement, and maintain CI/CD pipelines to automate build, test, and deployment processes.Monitor and optimize infrastructure performance using tools like Jenkins, GitLab CI/CD, or Azure DevOps.Manage and support containerized environments using Docker and orchestration tools like Kubernetes.Develop infrastructure as code (IaC) using tools like Terraform or Ansible.Implement and maintain monitoring and alerting systems for application and infrastructure health.Collaborate with development and operations teams to ensure seamless integration of DevOps processes.ITIL/ITSM Responsibilities:Apply ITIL principles to manage the lifecycle of all services, including service design, transition, and operation.Contribute to the development and maintenance of ITIL processes such as Incident Management, Problem Management, Change Management, and Service Level Management (SLM).Ensure all DevOps automation and tooling align with defined ITIL/ITSM processes.Work with service owners to define and maintain Service Level Agreements (SLAs) and Operational Level Agreements (OLAs).Conduct post-incident reviews (PIRs) and implement preventative measures as part of Problem Management.Facilitate and coordinate change requests across teams, adhering to the Change Management process.Qualifications:Education & Experience:Bachelor's degree in Computer Science, Information Technology, or a related field.2 – 4 years of experience in DevOps engineering and/or IT Service Management roles.Technical Skills:Proficiency in programming/scripting languages (e.g., Python, JavaScript, Bash).Hands-on experience with DevOps tools (Jenkins, Git, Docker, Kubernetes, Terraform, Ansible, etc.)Strong understanding of IT Service Management (ITSM) principles and the ITIL framework.Strong understanding of RESTful APIs and integration techniques.Knowledge of cloud platforms (AWS, Azure, GCP) is a plus.",
    "criteria": {
      "Seniority level": "Executive",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "JavaScript",
      "Bash",
      "Jenkins",
      "Git",
      "GitLab",
      "GitLab CI",
      "Docker",
      "Kubernetes",
      "Terraform",
      "Ansible",
      "AWS",
      "Azure",
      "GCP",
      "CI/CD",
      "IaC",
      "RESTful APIs"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_004"
  },

  {
    "job_id": "devops-engineer-at-lseg-4307022354",
    "title": "DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-11",
    "job_url": "https://lk.linkedin.com/jobs/view/devops-engineer-at-lseg-4307022354?position=8&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=1CwRX0yVAQQ6qZiFmhJvXA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424143",
    "description": "Role ProfileThe role is for a DevOps Engineer within the LSEG Markets Technology Services division. We strive for our engineers to work within small, agile, self-managed teams that emphasise standard process and believe quality is everyone’s responsibility. A key aim of the role is to maintain maximum availability, reliability and resiliency of important Markets services.The ideal candidate will possess broad experience covering application and infrastructure observability with some exposure to scripting, automation and debugging. The role is best suited to candidates willing to embrace a demanding and varied but balanced and flexible work pattern, which would include participating in the on-call rota and supporting weekend testing according to project requirements. Dive Deep: optimize processes, proactively troubleshoot issues, become a subject matter expert in multiple areas Build with purpose: drive client satisfaction and business value by identifying and development process improvement and automation initiatives Engineering Excellence: define measurable success criteria and routinely assess service availability and reliabilityCandidate ProfileExperience in AWS, Linux, Terraform, GitLab, Ansible, Observability tooling (e.g. Datadog or Prometheus), Scripting (Python / bash / Powershell), Control-M, Jira, ConfluenceA passion for building and maintaining robust and reliable cloud-based infrastructureExperience in application and infrastructure observabilityAn open and collaborative attitudeJoin us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "PowerShell",
      "AWS",
      "Terraform",
      "Ansible",
      "Linux",
      "GitLab",
      "Prometheus",
      "Datadog",
      "Agile",
      "DevOps",
      "JIRA"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_007"
  },
  {
    "job_id": "senior-devops-engineer-at-lseg-4322572635",
    "title": "Senior DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-14",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-lseg-4322572635?position=14&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=w%2B0xvTiCFu4mhSZFV9JWdA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424145",
    "description": "Role ProfileSenior DevOps Engineer is an objective driven individual responsible for configuration, automation and executing of the tools and processes that enable faster and repetitive software development with minimum guidance. The engineer will work closely and collaboratively with cross functional teams to implement, automate, test, maintain and deploy different DevOps tools and carryout non-functional testing.The candidate must contribute in the following capacities:Configure DevOps tools to build automated Continues Integration and Continues Delivery pipelines. Ability to troubleshoot and fix issues with minimum guidance or supervision. Automate infrastructure and application environment deployment in CloudUnderstand simple change requirement and implement solution. This may involve designing simple solution to optimise workflows.Involve in Application operational cycle configuration and automation and optimisationAutomated and execute performance and fault tolerance test casesRelease packaging and deploymentApplication, CI/CD and infrastructure monitoring and troubleshootingHelp implement DevOps tools and proactively support the development infrastructure by monitorHelp standardise our Continues Integration and Continues Delivery tools and processesRequired Skills and Experience: Two years or more experience in a similar capacityModerate scripting (e.g. Python) and automation skillsModerate skills in at least one object-oriented programming language (Eg: Java)Exposure to Linux based development environmentsSolid experience in DevOps Engineering including automation experience with configuration management tools.Experience in cloud technologies and key conceptsExperience in CI/CD processesOther Candidate Requirements:Ability to communicate effectively to audiences with differing levels of domain expertise (presentations, reports, justification)Detail-oriented individual with the ability to rapidly learn new concepts and technologiesStrong problem-solving skills, including providing simple solutions to complex situations.Strong team playerStrong organizational skills and attention to detail with the ability to prioritize effectively, handle multiple objectives under tight deadlines, identify/ flag/resolve potential issues early onTakes initiative and demonstrates a high level of enthusiasmEducational Requirements:Bachelor’s Degree from a recognised university or equivalentDiversity & InclusionPeople are at the heart of what we do and drive the success of our business. Our colleagues thrive personally and professionally through our shared values of Integrity, Partnership, Innovation and Excellence are at the core of our culture. We embrace diversity and actively seek to attract people with unique backgrounds and perspectives. We are always looking at ways to become more agile so we meet the needs of our teams and customers. We believe that an inclusive collaborative workplace is pivotal to our success and supports the potential and growth of all colleagues at LSEG.About UsLondon Stock Exchange Group (LSE.L) is a diversified international market infrastructure and capital markets business sitting at the heart of the world's financial community. The Group can trace its history back to 1698.The Group operates a broad range of international equity, bond and derivatives markets, including London Stock Exchange; Borsa Italiana; MTS, Europe's leading fixed income market; and Turquoise, a pan-European equities MTF. It is also home to one of the world’s leading growth markets for SMEs, AIM. Through its platforms, the Group offers international business and investors unrivalled access to Europe's capital markets.Post trade and risk management services are a significant part of the Group’s business operations. In addition to majority ownership of multi-asset global CCP operator, LCH Group, LSEG operates CC&G, the Italian clearing house; Monte Titoli, the T2S-ready European settlement business; and globeSettle, the Group’s newly established CSD based in Luxembourg.The Group is a global leader in indexing and analytic solutions. FTSE Russell offers thousands of indexes that measure and benchmark markets around the world. The Group also provides customers with an extensive range of real time and reference data products, including SEDOL, UnaVista, and RNS.London Stock Exchange Group is a leading developer of high performance trading platforms and capital markets software for customers around the world. In addition to the Group’s own markets, over 35 other organisations and exchanges use the Group’s MillenniumIT trading, surveillance and post trade technology.Headquartered in London, with significant operations in North America, Italy, France and Sri Lanka, the Group employs approximately 4,700 people.Values & BehavioursIntegrity: My word is my bond. Integrity underpins all that we do – from unshakable commitment to building and supporting global markets based on transparency and trust, to every transaction across our business with each and every stakeholder. We are a source of enduring confidence in the financial system, so when we say that our work is our bond – we mean it.Partnership: We collaborate to succeed. We pride ourselves on working together as proactive partners, building positive relationships with our colleagues, customers, investors, regulators, governments and shareholders – for our mutual success and the benefit of all.Innovation: We nurture new ideas. We are ambitious and forward-looking – a pioneering Group of market innovators, driven by fresh thinking that has kept us ahead of change. We prudently and proactively invest to make sure that out markets and services constantly moving forward, developing and evolving with advances in technology.Excellence: We are committed to quality. We have a fundamental commitment to developing talented teams who deliver to the highest standards in all that we do. By collaborating together, we will sustain industry-leading levels of excellence, setting the benchmarks that inspire ever better performance.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "CI/CD",
      "Linux"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_008"
  },
  {
    "job_id": "senior-devops-engineer-at-lseg-4256733142",
    "title": "Senior DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-07",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-lseg-4256733142?position=16&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=Puz9pKScyAfDOPJrluwWfw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424148",
    "description": "Role PurposeThis role is within the Trade Data Team which sits within the Application Services Division. You will be part of a DevOps engineering team working in a pod model spread across both Equities and FX.We strive for our engineers to work within agile, self-managed teams that emphasise standard process and believe quality is everyone’s responsibility. You will bring an enthusiastic “ build it you run it” mentality whilst making sure they share their knowledge while removing constraints.You will have the opportunity to drive how we craft, build, and implement cloud solutions. It goes hand in hand that improving the environments and ensuring service availability will be a key part of this role.Role ResponsibilitiesDesign and build scalable and robust infrastructure solutions ensuring reliability, performance and security in line with project requirements.Drive automation across development, testing and deployment processes to enhance efficiency and reduce manual intervention.Build, Implement and optimise CI/CD pipelines (Jenkins / GitLab) to streamline software delivery and improve deployment frequency.Integrate new DevOps tooling (Gitlab) and technologies to support the development and operational needs of the organisation.Champion the use of IaC principles and tools to provision and manage infrastructure (Terraform) in a repeatable and efficient manner.Implement robust monitoring and logging solutions (Datadog, BigPanda) to ensure proactive issue detection and resolution.Collaborate with security teams to implement and maintain secure DevOps practises ensuring compliance with the organisation’s standards and policiesProvide incident response escalation, troubleshooting complex issues and implement preventative measures (ServiceNow, Jira)Contribute to cost-effective infrastructure management and resource allocation.Ensure comprehensive and up-to-date documentation of infrastructure, processes and configurations (Confluence, Jira)Minimum Requirements5+ years AWS knowledge and experience of services (common + serverless, PrivateLink, SNS, SQS, WAF, API GW, integrations between services, EKS, ECS)Terraform - write deployments from scratch, organise/optimise code & modules.Scripting (more experience with programming, Bash, PowerShell, Python, Groovy, Go)Jenkins - build complex pipelines using various strategies and the ability to build a shared library’s (Groovy)GitLab - can understand GitLab functionalities (SVC, CI/CD, RBAC, API; integrations with other systems)Knowledge of testing tools/frameworks for Terraform codeGIT (ability to develop branching strategies & organise/optimise code or GIT usage)Basic networking skills (subnets, DNS, firewalls, basic solving: eg. Telnet, nc, check used ports)Linux knowledge (basic + experience with multiple distributions, understand boot process, fix system services, cloud-init)Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "PowerShell",
      "Groovy",
      "AWS",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Linux",
      "Git",
      "GitLab",
      "Datadog",
      "IaC",
      "Firewalls",
      "Serverless",
      "JIRA",
      "Confluence",
      "DNS",
      "Networking",
      "ServiceNow"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_009"
  },
  {
    "job_id": "senior-devops-engineer-azure-ifs-ultimo-at-ifs-4336660716",
    "title": "Senior DevOps Engineer (Azure) - IFS Ultimo",
    "company": "IFS",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-azure-ifs-ultimo-at-ifs-4336660716?position=19&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=l0Vd1Il43ZeCzn9CA4ybPQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424149",
    "description": "IFS is a billion-dollar revenue company with 7000+ employees on all continents. Our leading AI technology is the backbone of our award-winning enterprise software solutions, enabling our customers to be their best when it really matters–at the Moment of Service™. Our commitment to internal AI adoption has allowed us to stay at the forefront of technological advancements, ensuring our colleagues can unlock their creativity and productivity, and our solutions are always cutting-edge.At IFS, we’re flexible, we’re innovative, and we’re focused not only on how we can engage with our customers but on how we can make a real change and have a worldwide impact. We help solve some of society’s greatest challenges, fostering a better future through our agility, collaboration, and trust.We celebrate diversity and understand our responsibility to reflect the diverse world we work in. We are committed to promoting an inclusive workforce that fully represents the many different cultures, backgrounds, and viewpoints of our customers, our partners, and our communities. As a truly international company serving people from around the globe, we realize that our success is tantamount to the respect we have for those different points of view.By joining our team, you will have the opportunity to be part of a global, diverse environment; you will be joining a winning team with a commitment to sustainability; and a company where we get things done so that you can make a positive impact on the world.We’re looking for innovative and original thinkers to work in an environment where you can #MakeYourMoment so that we can help others make theirs. With the power of our AI-driven solutions, we empower our team to change the status quo and make a real difference.If you want to change the status quo, we’ll help you make your moment. Join Team Purple. Join IFS.Job DescriptionWe’re introducing a DevOps Engineer role in the Ultimo Product Development Group to centralize and elevate how we manage our internal environments and pipelines. This role takes ownership of responsibilities currently spread across teams, bringing them together under one accountable function. You’ll be the connecting party between all stages of development, ensuring our environments scale reliably, our pipelines run seamlessly, and our DevOps foundation evolves as we modernize our engineering organization.Your primary focus will be on building, optimizing, and maintaining our deployment pipeline (the backbone of efficient, secure, and reliable software delivery) while also supporting QA infrastructure as a secondary responsibility. You’ll have the opportunity to make a real mark on how Ultimo teams will work in the future by creating a clear vision for DevOps excellence and taking the lead in driving it forward, rather than simply following established processes. This role calls for someone who combines hands-on technical expertise with strategic thinking; someone who can set direction, influence best practices, and lead by example in building a mature, forward-looking DevOps culture.We’re also on an AI journey, embedding intelligent automation and data-driven decision-making into our processes and products. As a DevOps Engineer, you’ll play an important role in ensuring our infrastructure and delivery processes are ready to support and scale with this transformation.This position combines hands-on technical work with process ownership and collaboration, ensuring that IFS Ultimo continues to deliver reliable, secure, and scalable enterprise software solutions.Duties and Accountabilities Manage and maintain all key deployment hardware, develop and QA environments, ensuring availability and stability.Roll out and continuously improve the development process, ensuring alignment between Development, QA and OperationsDesign, implement, and maintain CI/CD pipelines (GitLab, Jenkins) to support testing and release activities.Automate and optimize build and deployment processes to increase efficiency and reduce errors.Collaborate with software development teams to promote DevOps best practices within the organization.Monitor, analyze, and troubleshoot environment performance, deployment stability, and test data integrity.Ensure compliance with security, quality, and operational standards across all development environments.Create and maintain technical documentation, training material, and process descriptions.Share knowledge, guide, and support colleagues in adopting new tools and practices. QualificationsRequired Experience and Skills: A university degree in Software Engineering, Computer Science, or a related field.4+ years of demonstrable experience in DevOps with a strong understanding of CI/CD principles, infrastructure automation, and environment managementStrong understanding of Microsoft Azure or similar cloud environments.Deep hands-on experience with CI/CD ecosystems (GitLab, Jenkins), including pipeline design, automation, and integration across multi-environment deployments.Expertise in scripting in PowerShell, Bash, or Python.Proven experience managing on-premises and virtualized hardware used for software deployment and testing.Solid understanding of software development processes, release processes, and test automation.Excellent verbal communication skills and documentation skills.Proactive, analytical, and detail-oriented with a strong sense of ownership.Preferred Experience and Skills: Experience with enterprise-scale SaaS deployment models.Knowledge of Windows Server and Linux environments.Familiarity with networking, security, and environment monitoring (Grafana, Prometheus, Azure Monitor).Additional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Bash",
      "PowerShell",
      "Azure",
      "Jenkins",
      "CI/CD",
      "Linux",
      "GitLab",
      "Prometheus",
      "Grafana",
      "Test Automation"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_010"
  },
  {
    "job_id": "senior-devops-engineer-at-lseg-4317464517",
    "title": "Senior Devops Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-13",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-lseg-4317464517?position=22&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=e3UGPFGte1JFq%2FBscE8TNw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424151",
    "description": "About us:LSEG (London Stock Exchange Group) is more than a diversified global financial markets infrastructure and data business. We are dedicated, open-access partners with a dedication to excellence in delivering the services our customers expect from us. With extensive experience, deep knowledge and worldwide presence across financial markets, we enable businesses and economies around the world to fund innovation, manage risk and create jobs. It’s how we’ve contributed to supporting the financial stability and growth of communities and economies globally for more than 300 years. Through a comprehensive suite of trusted financial market infrastructure services – and our open-access model – we provide the flexibility, stability and trust that enable our customers to pursue their ambitions with confidence and clarity.LSEG is headquartered in the United Kingdom, with significant operations in 70 countries across EMEA, North America, Latin America and Asia Pacific. We employ 25,000 people globally, more than half located in Asia Pacific. LSEG’s ticker symbol is LSEG.Our people:People are at the heart of what we do and drive the success of our business. Our culture of connecting, creating opportunity and delivering excellence shape how we think, how we do things and how we help our people fulfil their potential. We embrace diversity and actively seek to attract individuals with unique backgrounds and perspectives. We break down barriers and encourage teamwork, enabling innovation and rapid development of solutions that make a difference. Our workplace generates an enriching and rewarding experience for our people and customers alike. Our vision is to build an inclusive culture in which everyone feels encouraged to fulfil their potential.We know that real personal growth cannot be achieved by simply climbing a career ladder – which is why we encourage and enable a wealth of avenues and interesting opportunities for everyone to broaden and deepen their skills and expertise. As a global organisation spanning 70 countries and one rooted in a culture of growth, opportunity, diversity and innovation, LSEG is a place where everyone can grow, develop and fulfil your potential with meaningful careers.Role summary:An experienced Senior DevOps engineer is required to join the Technical Services (TTO) team within LSEG Markets & Risk Intelligence. This is a chance to be part of a team and help us build the future of financial services on blockchain technology. The team is responsible for the delivery and support of production environments which are typically housed within Azure, as well as integrating software changes into the enterprise environment as part of ongoing project work. The role includes participation in an on-call rota to ensure coverage during business hours, with plans to expand support coverage as the business scales. Occasional weekend work may be required to support release testing and deployment activities.DMI (Digital Markets Infrastructure) is an ambitious project: large-scale, complex and uses a range of blockchain architecture patterns, with numerous stakeholders (internal and external) and use cases. The work is focussed on the tokenisation of financial instruments, i.e. as digital assets. We seek candidates with an interest in the financial markets with experience working on large projects. This is a chance to work on an innovative, intellectually challenging project backed by the influential reach of the London Stock Exchange Group.The ideal candidate will play a vital role in developing, maintaining and enhancing our continuous integration and continuous deployment (CI/CD) infrastructure, supporting application, ensuring high-quality software delivery and uptime.What you'll be doing:Implement, manage, and optimize Cloud deployments and automations of DMI applications.Design and manage container orchestration solutions using Kubernetes and similar technologies.Implement, maintain, and optimize containerization for DMI services (e.g. via Docker).Automate infrastructure provisioning and scaling (e.g. Terraform).Integrate security best practices into the DevOps lifecycle, ensuring robustness against vulnerabilities.Collaborate closely with software engineers, QA, and other teams to ensure efficient deployment, monitoring, and maintenance of applications.Keep up to date with the latest industry trends, tools, and best practices in DevOps and cloud infrastructure.What you'll bring:Computer science, software engineering, or relevant technical background required.5 + years of professional experience in DevOps and infrastructure management.5+ years of specific experience with Cloud platforms (AWS/Azure/GCP)Proficient in Kubernetes, Docker, and Terraform.Experience with the Azure cloud platform, managing workloads, provisioning & deployments.Deep knowledge of security best practices in cloud and DevOps contexts.Proven knowledge of scaling, availability and cloud resiliency models, patterns and designs.Ability to anticipate potential infrastructure challenges and provide innovative solutions.Interest in new technologies and continuous improvement methodologies.Familiarity with blockchain/DLT desirable.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce. You will be part of a collaborative and creative culture where we encourage new ideas and are committed to sustainability across our global business. You will experience the critical role we have in helping to re-engineer the financial ecosystem to support and drive sustainable economic growth. Together, we are aiming to achieve this growth by accelerating the just transition to net zero, enabling growth of the green economy and creating inclusive economic opportunity.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Go",
      "AWS",
      "Azure",
      "GCP",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "Terraform",
      "Container Orchestration",
      "QA",
      "Continuous Integration",
      "Continuous Deployment",
      "Blockchain",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_011"
  },
  {
    "job_id": "lead-devops-engineer-gcp-at-virtusa-4347014854",
    "title": "Lead DevOps Engineer - GCP",
    "company": "Virtusa",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-20",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-gcp-at-virtusa-4347014854?position=24&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=XIGhsWuadk8Hd4Y4XDOorg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424152",
    "description": "GCP(Cloud builds, Cloud deploy), Terraform/IaC, VPC design, Cloud storage, Docker/Kubernetes, GitHub Actions, monitoring/logging, and secure secrets managementWe are seeking a smart proactive and quick thinking DevOps Engineer to join our team and help drive the success of our cloud native application platform.This role is ideal for someone who thrives in fast paced environments is comfortable juggling multiple priorities and can seamlessly switch contexts especially when working across complex integrations involving Salesforce middleware and cloud infrastructureYoull be responsible for managing and optimizing a platform that integrates Salesforce with Kubernetes Kafka Spring Boot Mulesoft and Google Cloud Platform GCP services Strong communication skills and the ability to collaborate across teams are essentialDesign implement and manage cloud infrastructure on GCP including Cloud Run Pub Sub GCS IAM Redis Load Balancing and Vertex AISupport and optimize Salesforce development workflows and tools like SFDX Salesforce CLI and Force.com Migration ToolManage containerized microservices using Kubernetes Docker and Cloud Run integrated with Kafka Spring Boot and MulesoftBuild and maintain CI CD pipelines using GitHub Actions Jenkins Maven SonarQube Checkmarx and JFrog ArtifactoryCollaborate with cross functional teams to support agile development testing and deployment processesParticipate in incident response root cause analysis and continuous improvement initiativesLearn new technologies and stay up to date with latest industry trends",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Management and Manufacturing",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Spring Boot",
      "Redis",
      "Google Cloud",
      "GCP",
      "Cloud Run",
      "Cloud Storage",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "Terraform",
      "GitHub",
      "GitHub Actions",
      "IaC",
      "Load Balancing",
      "Kafka",
      "IAM",
      "Salesforce"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_012"
  },
  {
    "job_id": "lead-devops-engineer-at-lseg-4322835759",
    "title": "Lead DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-at-lseg-4322835759?position=29&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=NFbABl%2BXGEcwyQV4J160CQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424154",
    "description": "Associate Lead DevOps EngineerPosition SummaryThe role will encompass experimenting with various technologies to determine solutions and improvements to existing DevOps infrastructure. The candidate will also design, develop, deploy, automat, test and maintain the DevOps infrastructure. The role requires the candidate to have hands-on technical experience and a can-do approach towards environment automation / management and continuous improvement.Role ResponsibilitiesDeploying, automating, maintaining and managing DevOps infrastructure, to ensure the availability, performance, scalability and security of the infrastructure.Carryout acceptance testing to help assure the quality of services.Troubleshooting and problem solving across the DevOps infrastructure.Suggesting architecture improvements, recommending process improvements.Evaluate new technology options and vendor products.Work in cloud technologies and porting existing systems to cloud and automate them.Automation of build, integrate and test cycles related to the product (using Atlassian product suit).Preferred Skills And ExperienceBachelor’s Degree from a recognised university or equivalent.4 years or more experience in a similar capacity.Strong scripting (e.g. Python) and automation skills.Moderate skills in at least one object-oriented programming language (Eg: Java).Exposure to Linux based development environments.Proven experience in DevOps Engineering including automation experience with configuration management tools (Eg: Ansible).Experience in cloud deployment and technologies.Experience in DevOps tools.Experience working in an Agile environment (Eg: scrum/kanban).Ability to communicate effectively to audiences with differing levels of domain expertise (presentations, reports, justification).Meticulous individual with the ability to rapidly learn new concepts and technologies.Strong problem-solving skills, including providing simple solutions to complex situations.Strong teammate.Strong organizational skills and attention to detail with the ability to prioritize effectively, balance multiple objectives under tight deadlines, identify/ flag/resolve potential issues early on.Takes initiative and demonstrates a high level of passion.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "Ansible",
      "Linux",
      "Scrum",
      "Kanban"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_013"
  },
  {
    "job_id": "lead-devops-engineer-at-lseg-4324086911",
    "title": "Lead DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-24",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-at-lseg-4324086911?position=30&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=bT3IKTUF8g8gH2Flpw43ZA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424156",
    "description": "Position SummarySenior DevOps Lead will be responsible for designing, developing and managing LSEG's suite of SDLC and DevOps related tooling, including integrations with third party tools used for development, quality assurance and operations. The opportunity at Millennium Platform Development Team offers you the challenge to discover and learn new technologies in creating solutions that drive continuous improvement of our processes and tools. This role would require the engagement of multiple teams across the enterprise in order to discover and cater to opportunities where tooling and automation can improve efficiency and quality of deliveries, across the full software development lifecycle including analyzing, designing, coding, testing and deploying the solutions being developed.Role ResponsibilitiesStudy, understand and master the processes and tools used by various teams in engineering and testing products for capital market deployment.Work closely with these teams in order to discover problems and opportunities for improvement.Analyze, design, implement, test, deploy and maintain high quality solutions to be used by internal teams.Proactively drive innovation with new ideas and options made available by new technologies.Provide technical leadership to the Tools development team and take ownership of deliveries.Take initiative and think outside the assigned role.Preferred Skills And ExperienceComputer Science or Engineering degree from a recognized, accredited university.Should have worked in a team lead capacity for 2 - 3 years.Very good understanding of object-oriented analysis and design.Hands on experience in Java and Python.C/C++ experience would be an added advantage.Experience in building solutions by integrating open source and other third-party components.Experience in leading development teams and delivering client solutions will be highly valuable.Strong and effective interpersonal and communication skills and the ability to interact professionally with a diverse group of clients, staff and vendors.Experience in Configuration Management related to CI/CD and Automation.Solid experience in DevOps Engineering including automation experience with configuration management tools.Lead DevOps EngineerStrong Cloud technology knowledge. Configure and oversee DevOps tools for continuous integration and delivery, utilizing cloud technology.Evaluate and recommend cloud-based tools and technologies to optimize DevOps processes as directed.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "CI/CD"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_014"
  },
  {
    "job_id": "lead-devops-engineer-site-reliability-engineering-at-lseg-4278915804",
    "title": "Lead DevOps Engineer Site Reliability Engineering",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-16",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-site-reliability-engineering-at-lseg-4278915804?position=31&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=YlArHgWNeT6Nvbuzp1BaHg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424159",
    "description": "Role ProfileThe role is within the Trading Technology Application Services team which sits within the Capital Markets Application Services Division. We strive for our engineers to work within small, agile, self-managed teams that emphasise standard process and believe quality is everyone’s responsibility. They bring an enthusiastic “you build it you run it” attitude whilst making sure they share their knowledge while removing constraints.The aim of the role is to strengthen our ability to plan, engineer and support Millennium Technologies (MIT) FXI exchange systems, to evolve the system to meet new requirements, proactively prevent and resolve issues that may impact these services and to provide reactive support in a critically important environment. The right person will possess a broad ability covering DevOps and application support, as well as in-depth knowledge and experience of the MIT trading and risk platforms. The role is most suited to people willing to embrace a fast paced and varied but balanced and flexible work pattern, which would include covering on-site shifts, participating in the 24x7 on-call rota and supporting weekend testing according to project requirements.A large part of the role is project based, including playing a key part in improving and evolving our MIT application systems, develop the operational life cycle, upgrading existing systems and implementing integration into the operations architecture toolset. The candidate will also be responsible for take part in DevOps activities for the team and work on AWS based implementations and CI/CD deploymentsTech ProfileMillennium Exchange, Linux, AWS, Terraform, Ansible, Jenkins, Datadog, Moogsoft, Big Panda, Git, Bitbucket, Elastic Search, Scripting Technologies (Bash / Python / PowerShell), Control-M, Jira, Confluence.Key ResponsibilitiesProvide technical feedback into the design and implementation of re-engineering efforts on our MIT systems, including the exchange, risk, surveillance and price dissemination platforms.Act as the operations SME for one or more of the supported MIT equities applicationsDevelop training materials and provide seminars and workshops on the support of MIT applications to colleagues.Provide Level 2 technical advice and risk assessment based on knowledge of applications, databases and system software.Ensure that all operational responsibilities are performed including monitoring systems and deploying releasesProvide effective customer concern and resolution of issues and problems to customersGain an in-depth knowledge of the unit’s processesLevel 2 support for critically important trading systems and meet SLAs for supported services.Identify and implement operational improvements for processes, performance and reliability.Experience in developing cloud native applicationsExperience in automating infrastructure provisioning and application deployment Build CI/CD pipelines orchestrating the promotion of code Define and implement cloud native operational requirements Open and collaborative attitude keeping artifacts up to date and relevant while actively promoting knowledge sharing Hands-on experience in AWS, Kubernetes and micro services implementations.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce. You will be part of a collaborative and creative culture where we encourage new ideas and are committed to sustainability across our global business. You will experience the critical role we have in helping to re-engineer the financial ecosystem to support and drive sustainable economic growth. Together, we are aiming to achieve this growth by accelerating the just transition to net zero, enabling growth of the green economy and creating inclusive economic opportunity.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Management and Manufacturing",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "PowerShell",
      "AWS",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Ansible",
      "Linux",
      "Git",
      "Bitbucket",
      "Datadog",
      "JIRA",
      "Confluence"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_015"
  },
  {
    "job_id": "lead-gcp-devops-engineer-at-virtusa-4341349204",
    "title": "Lead GCP DevOps Engineer",
    "company": "Virtusa",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-gcp-devops-engineer-at-virtusa-4341349204?position=39&pageNum=0&refId=g5yo1%2BM4I8w%2BdbjTdOEO9A%3D%3D&trackingId=z%2FhD2DGTm47PI6Ky3c4FMA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424160",
    "description": "We are seeking a smart proactive and quick thinking DevOps Engineer to join our team and help drive the success of our cloud native application platform This role is ideal for someone who thrives in fast paced environments is comfortable juggling multiple priorities and can seamlessly switch contexts especially when working across complex integrations involving Salesforce middleware and cloud infrastructure. You'll be responsible for managing and optimizing a platform that integrates Salesforce with Kubernetes Kafka Spring Boot Mulesoft and Google Cloud Platform GCP services Strong communication skills and the ability to collaborate across teams are essentialKey ResponsibilitiesDesign implement and manage cloud infrastructure on GCP including Cloud Run Pub Sub GCS IAM Redis Load Balancing and Vertex AISupport and optimize Salesforce development workflows and tools like SFDX Salesforce CLI and Force.com Migration ToolManage containerized microservices using Kubernetes Docker and Cloud Run integrated with Kafka Spring Boot and MulesoftBuild and maintain CI CD pipelines using GitHub Actions Jenkins Maven SonarQube Checkmarx and JFrog Artifactory Collaborate with cross functional teams to support agile development testing and deployment processesParticipate in incident response root cause analysis and continuous improvement initiatives Learn new technologies and stay up to date with latest industry trends5 years of experience in DevOps cloud infrastructure or platform engineering rolesProficiency with source control continuous integration and testing pipelines using tools such as GitHub GitHub ActionsJenkins Maven SonarQube and CheckmarxStrong hands on experience with GCP and cloud native architecturesProficiency in Salesforce development and deployment Apex LWC and tooling SFDX CLIExperience with middleware platforms Kafka Spring Boot MulesoftSolid understanding of container orchestration Kubernetes Docker and CI CD pipelinesProficient in scripting languages Python Bash GroovyFamiliarity with REST JSON and GraphQL APIsStrong grasp of cloud security IAM and networking principlesExperience with monitoring and observability toolsAbility to thrive in fast paced environments with frequent context switching and complex integration challengesExcellent multitasking skills and the ability to manage several workstreams simultaneouslyProven ability to analyze complex requirements and provide innovative solutionsExperience following Agile development practices with globally distributed teamsExcellent communication skills Able to communicate effectively with a range of stakeholders from management to other engineers and present to both technical and non technical audiences Solid organizational time management and judgment skillsAbility to work independently and in a team environmentCertifications in GCP AWS or AzureCertification in SalesforceExperience with AI ML services like Vertex AI CCAI or Dialogflow",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Bash",
      "Spring Boot",
      "GraphQL",
      "Redis",
      "AWS",
      "Google Cloud",
      "GCP",
      "Cloud Run",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "GitHub",
      "GitHub Actions",
      "Container Orchestration",
      "Load Balancing",
      "Kafka",
      "IAM",
      "Agile",
      "DevOps",
      "Continuous Integration",
      "Microservices",
      "Cloud Native",
      "Communication",
      "Time Management",
      "Networking",
      "Salesforce"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_019"
  },
  {
    "job_id": "devops-engineer-at-infstones-4339342430",
    "title": "DevOps Engineer",
    "company": "InfStones",
    "location": "Texas, United States",
    "posted_date": "2025-11-27",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-at-infstones-4339342430?position=1&pageNum=0&refId=7xJvY1TzTcqipbsmiqXL9Q%3D%3D&trackingId=fhX6aCRSz1WdtcnfX2phGQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424162",
    "description": "Job Position: DevOps EngineerLocation: Dallas, TX, USA (Remote Acceptable - USA Applicants Only)Company: https://infstones.com/Contact: recruiter-usa@infstones.comAbout CompanyInfStones is an advanced, enterprise-grade Platform as a Service (PaaS) blockchain infrastructure provider trusted by the top blockchain companies in the world. InfStones’ AI-based infrastructure provides developers worldwide with a rugged, powerful node management platform alongside an easy-to-use API. With over 20,000 nodes supported on over 80 blockchains, InfStones gives developers all the control they need - reliability, speed, efficiency, security, and scalability - for cross-chain DeFi, NFT, GameFi, and decentralized application development. InfStones is trusted by the biggest blockchain companies in the world including Binance, CoinList, BitGo, OKX, Chainlink, Polygon, Harmony, and KuCoin, among a hundred other customers. InfStones is dedicated to developing the next evolution of a better world through limitless Web3 innovation.To date, InfStones has raised over $110 million in capital and is backed by Softbank, GGV Capital, Susquehanna International Group (SIG), Dragonfly Capital, Qiming Venture Partners, Plug and Play, and many renowned institutional investors. InfStones is proud to offer medical, vision, dental, short-term and long-term disability insurance, 401(k) plan with company matching, FSA, and other benefits to all full-time employees, along with flexible paid time off, sick days, and holidays.We are seeking a highly skilled and motivated DevOps Engineer to join our dynamic team. If you are passionate about DevOps, GitLab, Amazon EKS, security, and observability, we invite you to be a part of our innovative journey. If you enjoy being on the cutting edge of technology, we encourage you to apply!Job DescriptionAs a DevOps Engineer at InfStones, you will play a crucial role in ensuring the reliability, security, and scalability of our infrastructure. You will work closely with cross-functional teams to design, implement, and maintain our DevOps processes and practices. Your expertise in Cloud, Kubernetes, Security, and Observability will be instrumental in achieving our goals.Key Responsibilities Work closely with cross-functional teams, design, implement, and maintain DevOps processes and practices Manage CI/CD pipelines, automate infrastructure provisioning, and maintain cloud environments while applying expertise in cloud technologies, Kubernetes, security, and observability Design, build, and maintain, scalable and reliable infrastructure and automation tools supporting multiple applications across multiple clouds Architect, deploy and manage Cloud Platforms like AWS and Linux-based systems Develop and manage CI/CD pipelines using GitLab for automated testing and deployment Automate infrastructure provisioning and configuration management using tools like Cloudformation, Terraform, or Ansible Architect, deploy and maintain applications and services on Kubernetes, especially EKS Implement and maintain security best practices across all environments Automate repetitive tasks and processes to enhance the efficiency, reliability, and availability of our cloud and infrastructure platform while adhering to the “everything as code” approach Monitor system performance and troubleshoot issues to ensure high availability and performance through the use of various observability and alerting tools like Cloudwatch, Prometheus, Grafana, ELK Stack, and OpenSearch Continuously optimize infrastructure for performance, scalability, and cost-effectiveness Participate in on-call rotations to provide 24/7 support as needed across multiple teams across multiple time zonesQualifications Bachelor’s degree in Computer Science, Engineering, or a related field, or equivalent of 5 years experience in DevOps, Software Development, Systems Engineering, Site Reliability Engineering, QA and Test Engineering, IT Architecture, or any of their combination At least 3 years of experience with cloud platforms, preferably in AWS and Linux based Systems, as well as CI/CD tools such as GitLab, Jenkins, Harness, and Git version control Expertise in deployment and management of Kubernetes, especially EKS, as well as the applications running on it In-depth knowledge of infrastructure as code (IaC) and tools like Ansible, Terraform, or CloudFormation Experience with security best practices and implementing security measures in a DevOps environment Proficiency with monitoring and observability tools such as Prometheus, Grafana, ELK Stack, or equivalents Proficient in common programming and scripting languages such as Python, Golang, Shell, Java, and JavaScript Strong problem-solving skills and attention to detail, capable of completing tasks with minimal guidance Proficient in cross-cultural communication and effective collaboration across multiple time zones on an international teamPrefers (Nice to have) Relevant certifications such as AWS Certified DevOps Engineer, GitLab Certified Professional, or Certified Kubernetes Administrator (CKA) Previous experience with microservices architecture Familiarity with serverless computing (e.g., AWS Lambda) Understanding of agile methodologies and continuous improvement practices Knowledge of blockchainWe may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "Java",
      "JavaScript",
      "AWS",
      "Lambda",
      "CloudFormation",
      "CloudWatch",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Ansible",
      "Linux",
      "Git",
      "GitLab",
      "Prometheus",
      "Grafana",
      "ELK Stack",
      "IaC",
      "QA",
      "Site Reliability Engineering",
      "Microservices",
      "Serverless",
      "Web3"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_020"
  },
  {
    "job_id": "devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139",
    "title": "DevOps Cloud Engineer Based in U.S.A",
    "company": "Advancio",
    "location": "United States",
    "posted_date": "2025-11-24",
    "job_url": "https://www.linkedin.com/jobs/view/devops-cloud-engineer-based-in-u-s-a-at-advancio-4324442139?position=8&pageNum=0&refId=7xJvY1TzTcqipbsmiqXL9Q%3D%3D&trackingId=UHGWiRJmaJq%2FWIvC1nVZUg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424164",
    "description": "This is a remote position.Who We Are:At Advancio, we are passionate about technology and its ability to transform the world. We are rapidly expanding and building a company where we serve exceptional businesses, hire top talent, and have a lot of fun doing what we love! Job Summary: We are seeking a skilled DevOps Cloud Engineer to design, implement, and manage scalable cloud-based infrastructure and DevOps processes. The ideal candidate will have extensive experience with cloud platforms, CI/CD pipelines, and automation tools, ensuring the efficient deployment and operation of applications. What will you do: Design, deploy, and manage cloud infrastructure on platforms such as AWS, Azure, or Google Cloud Platform (GCP). Build and maintain CI/CD pipelines to streamline development and deployment processes. Automate infrastructure provisioning, configuration, and monitoring using tools like Terraform, Ansible, or similar. Ensure system reliability, availability, and performance through robust monitoring and alerting. Collaborate with development teams to optimize the delivery and scalability of applications. Manage containerized workloads using Docker and orchestration platforms such as Kubernetes. Implement security best practices for cloud environments, including identity management, encryption, and compliance adherence. Stay updated with the latest DevOps tools and methodologies to enhance team efficiency. Requirements 5+ years of experience in DevOps, cloud engineering, or related roles. Advanced English communication skills, both verbal and written. Proficiency in at least one major cloud platform (AWS, Azure, or GCP). Hands-on experience with CI/CD tools (e.g., Jenkins, GitLab CI/CD, CircleCI). Strong scripting skills in Python, Bash, or similar languages. Solid knowledge of infrastructure-as-code (IaC) tools like Terraform or CloudFormation. Experience with containerization (Docker) and orchestration (Kubernetes). Familiarity with monitoring and logging tools like Prometheus, Grafana, or ELK Stack. Strong understanding of networking, security, and system architecture.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Nanotechnology Research"
    },
    "skills": [
      "Python",
      "Bash",
      "AWS",
      "Azure",
      "Google Cloud",
      "GCP",
      "CloudFormation",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Ansible",
      "GitLab",
      "CircleCI",
      "GitLab CI",
      "Prometheus",
      "Grafana",
      "ELK Stack",
      "IaC",
      "Encryption",
      "Networking",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_026"
  },
  {
    "job_id": "devops-engineer-at-radcube-4323194999",
    "title": "DevOps Engineer",
    "company": "RADcube",
    "location": "Indianapolis, IN",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-at-radcube-4323194999?position=2&pageNum=0&refId=7xJvY1TzTcqipbsmiqXL9Q%3D%3D&trackingId=sMBozY%2BNoSwUIjn%2FPgxlJA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424167",
    "description": "Our Client is seeking a DevOps Engineer to join our growing Platform team. This role will play a key role in building and maintaining secure, reliable, and scalable infrastructure, primarily on Azure. This position will focus on implementing cloud automation, CI/CD pipelines, Databricks platform enablement, and supporting migrations of client workloads across clouds. This is a collaborative position designed for someone who enjoys working closely with developers, data engineers, and platform team members, in addition to, managing documentation processes and platform standards for consistent adoption. The ideal candidate is committed to continuous learning and enjoys staying current with evolving DevOps and data platform practices. DevOps Engineer with Databricks Location: Indianapolis, IN (Hybrid) ResponsibilitiesIn this role, you will support the following:Cloud Infrastructure & Automation Implement and manage Azure cloud infrastructure using Infrastructure-as-Code (Bicep, Terraform, GitHub Actions) Develop and maintain CI/CD pipelines to automate builds, tests, and deployments Support containerization and orchestration efforts Databricks Platform Engineering Build and maintain Databricks infrastructure (workspaces, clusters, Unity Catalog) Support migration of client Databricks workspaces from other cloud platforms into Azure Implement governance policies, role-based access control, and secure volume management for Databricks Partner with data teams to ensure scalable, compliant, and cost-efficient use of Databricks Operations & Reliability Monitor infrastructure and Databricks workloads for performance, cost, and availability Contribute to disaster recovery, backups, and high-availability solutions Maintain observability and alerting frameworks across Azure and Databricks environments Security & Compliance Enforce IAM, RBAC, and least-privilege practices across Azure and Databricks platforms Implement compliance checks and controls aligned with HITRUST, HIPAA, and SOC 2 to maintain audit readiness across the platform Qualifications Hands-on experience with Microsoft Azure and Databricks Knowledge of containerization and orchestration Scripting skills in PowerShell, Bash, or Python Knowledge of agile methodologies and practices Strong problem-solving, troubleshooting, and collaboration skills RequirementsRequired: Bachelor's degree in computer science, engineering, or a related field 3+ years of experience as a DevOps Engineer, or in a similar software engineering role, managing: Databricks: workspace management, Unity Catalog, cluster governance, and cross-cloud migrations Git and GitHub workflows Infrastructure as code (IaC) using Terraform, Bicep, or similar tools Preferred: Certification in cloud platforms",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Bash",
      "PowerShell",
      "Databricks",
      "Azure",
      "CI/CD",
      "Terraform",
      "Git",
      "GitHub",
      "GitHub Actions",
      "IaC",
      "IAM",
      "SOC 2",
      "Unity",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_021"
  },
  {
    "job_id": "devops-engineer-2-at-jar-4339240571",
    "title": "Devops Engineer - 2",
    "company": "Jar",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-26",
    "job_url": "https://in.linkedin.com/jobs/view/devops-engineer-2-at-jar-4339240571?position=1&pageNum=0&refId=yJwB33fwpwWOZ%2BxsQFntyg%3D%3D&trackingId=njzgZfgY6R0soyRQUzyp1g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424169",
    "description": "About UsJar is India’s leading Daily Saving app that helps people build strong saving habits—one small step at a time. Our goal is to make saving simple, rewarding, and truly life-changing. Founded in 2021 by Misbah Ashraf and Nishchay AG, Jar is a Bengaluru-based startup with one simple belief: saving a little every day in 24K Digital Gold can truly transform your future.Today, 20 million+ Indians trust Jar as their saving partner. With flexible saving options—Daily, Weekly, Monthly, and Instant Saving—we have made it easy for everyone to save in their own way and withdraw anytime. We are one of the leaders in UPI autopay transactions, crossing more than 1 million transactions per day. In 2023, we expanded our vision with Nek, our jewelry brand crafted to bring together luxury and affordability, it has since surpassed ₹100 crore in revenue.We have a big dream of bringing “Har Ghar Sona”. Small, consistent savings are just the start. We’re here to walk alongside our users, helping Indians secure their financial future every step of the way.Backed by Tiger Global Management, Arkam Ventures, and WEH Ventures, among others, we have raised $50 million+ in funding. In January 2025, we hit a huge milestone of becoming profitable. Now, we’re charging ahead, focused on sustainable growth and scaling impact.And this is just the beginning!What’s the role? We are hiring a DevOps Engineer 2 to lead the design, scalability, and security of our multi-cloud infrastructure across AWS, GCP, and Kubernetes. This role involves driving advanced deployment strategies, building and optimizing CI/CD pipelines, managing Kafka at scale, and leading observability and monitoring initiatives across platforms. The ideal candidate will bring deep expertise in Terraform, strong cloud operations experience, and a track record of solving complex infrastructure problems in high-growth environments.What will be your responsibilities?Design cloud infrastructure that is secure, scalable, and highly available across AWS, GCP, and other relevant cloud providersProvide maintenance and support for Kafka, ensuring its reliability, scalability, and performanceWork with containers and microservices and handle deployment and service orchestration using Kubernetes—preferably EKS, but also AKS or GKEImplement and maintain Continuous Integration and Continuous Delivery (CI/CD) pipelinesCollaborate with software engineers to define infrastructure and deployment requirementsProvision, configure, and maintain AWS cloud infrastructureEnsure compliance with configuration management tools and best practicesAdminister and troubleshoot Linux-based systemsDiagnose and resolve issues across a wide array of services and functional areasBuild and maintain operational tools for deployment, monitoring, and analysis of AWS infrastructure and systemsPerform infrastructure cost analysis and optimizationUnderstand open telemetry concepts and implement observability and tracing within the platformWhat’s required from you?3+ years of DevOps experience, with a background in operations, deploying, and maintaining multi-tiered infrastructure and applications at scaleStrong experience with Terraform for infrastructure as code (IaC), including writing, testing, and maintaining Terraform modulesHave experience managing any distributed NoSQL system (e.g., Cassandra, Scylla, etc.)Possess strong scripting skills in languages such as Python or ShellHave extensive experience and a deep understanding of Kubernetes. Tech StackYou will be working with AWS, GCP, Docker, Kubernetes, Kafka, Computer Networks, Linux, Jenkins, OpenTelemetry, Envoy, Istio, Cloud Security, SIEM stacks, and Terraform.What makes us different? We’re not just building a product—we’re shaping the future of savings in India. We seek people who bring passion, energy, and fresh ideas to help us make that happen. Experience matters, but we are a potential first organisation. We move fast, learn from our mistakes, and take bold risks to solve problems that haven’t been attempted before. If you’re excited about working in an environment where people inspire and truly support each other, you’ve found the right fit.What do we stand for? The five values that we live by :Passion: At Jar, we strive to create an environment where people love what they do, are motivated and equipped to do their best work.Equality: We bring diverse skills, ideas, and experiences to the table, supporting and challenging each other across teams to create something bigger than ourselves.Growth: When our people grow, Jar grows. We create opportunities for learning, development, and meaningful impact.Accountability: The core of our work ethic is taking ownership of our work, showing initiative, and having the freedom to ask questions.Consistency: We believe in doing the right things consistently. Big change doesn’t happen overnight,it’s built one step at a time.Join us and let’s build something amazing together!What employee benefits do we have?Glad you asked! Among other things, we haveMedical Insurance for employees and their familiesESOPs allocationPluxee meal cardSwish club card for exclusive employee discounts Advance salary plansRelocation assistanceL&D programmesPowered by JazzHR7F22xbjq6s",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Internet Publishing"
    },
    "skills": [
      "Python",
      "Cassandra",
      "NoSQL",
      "AWS",
      "GCP",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Linux",
      "Istio",
      "IaC",
      "Kafka",
      "SIEM",
      "Continuous Integration",
      "Continuous Delivery",
      "Microservices",
      "Computer Networks"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251127_032"
  },
  {
    "job_id": "consultant-web-based-dashboard-developer-at-international-water-management-institute-iwmi-4338586990",
    "title": "Consultant - Web based Dashboard Developer",
    "company": "International Water Management Institute (IWMI)",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-24",
    "job_url": "https://lk.linkedin.com/jobs/view/consultant-web-based-dashboard-developer-at-international-water-management-institute-iwmi-4338586990?position=21&pageNum=0&refId=L7Ew%2BZuTWuxYAD%2BFtKdRIw%3D%3D&trackingId=a6kubjnWixeJLgzWCnnj3g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424174",
    "description": "The International Water Management Institute (IWMI) is an international non-profit, research-for-development organization that works with governments, civil society, and private sector organizations to address water-related challenges in developing countries and scale up solutions. IWMI is headquartered in Colombo, Sri Lanka, and is a CGIAR research center with offices in 15 countries and a global network of researchers operating in approximately 56 countries.The Middle East and North Africa (MENA) region is among the most water-stressed globally, with limited freshwater resources and increasing demand driven by population growth, economic development, and climate change. Municipal wastewater presents a significant opportunity for water reuse; however, much of it remains untreated or underutilized.To address this challenge, IWMI—with support from Google.org—is developing e-ReWater, a data-driven platform that leverages AI, Earth observation, and GIS to identify and prioritize wastewater reuse opportunities in Egypt, Saudi Arabia, and the UAE.The primary objective of this consultancy is to design, develop, and deploy a user-friendly, interactive, web-based dashboard that visualizes spatial and analytical outputs in support of decision-making for wastewater reuse in the MENA region. The dashboard will enable stakeholders to explore wastewater generation, treatment, and reuse potential; assess sectoral water demands; and identify priority reuse opportunities.DUTIES & RESPONSIBILITIES:The consultant will be responsible for the end-to-end development of the e-ReWater dashboard, including:Conducting user research and finalizing functional requirementsDesigning UI/UX and visual identity aligned with IWMI brandingDeveloping a modular, scalable frontend dashboard with interactive maps and data visualizationsIntegrating spatial and tabular datasets via backend services and APIsImplementing analytical tools for prioritization scoring and visualizationDeploying the platform in a cloud environment (preferably GCP), ensuring security, performance, and accessibilityProviding documentation, training materials, and post-launch maintenance supportDELIVERABLES:User Research & Requirements Finalization - Functional Specifications Document and UI/UX user-journey map based on consultations with IWMI and project stakeholdersUI/UX Design and Branding - Wireframes, high-fidelity UI mockups, and a complete UI design kit, including branding elements and accessibility reviewDashboard Development & Frontend Implementation - Fully functional frontend dashboard with interactive maps and dynamic data visualizationsData Integration & Backend Services - Secure backend services, APIs, and optimized spatial data layers, including metadata documentationData Visualization & Analytical Computation Layer - Dynamic charts, scoring tools, and data export functionalities integrated into the dashboardDeployment, Testing, Training, and Maintenance - Deployment of the live dashboard, full testing, and delivery of training materials and providing post-launch technical supportRequirementsMINIMUM EDUCATIONAL QUALIFICATIONS & EXPERIENCE REQUIRED:Essential:University degree in Computer Science, Software Engineering, Geoinformatics, Web Development, or a related fieldMinimum of 5 years of experience in full-stack web development, including frontend and backend systemsProven experience developing interactive, GIS-enabled dashboards or web-based analytical platformsDemonstrated expertise in managing spatial data (raster and vector) and integrating geospatial servicesExperience working with international development organizations or research institutionsFamiliarity with cloud deployment (preferably Google Cloud Platform, AWS, or Azure)Desirable:Experience working with water resources, environmental, or climate-related datasetsPrior experience developing tools for public-sector or policy decision-makingKnowledge of Arabic or experience designing multilingual platformsKNOWLEDGE, SKILLS & ABILITIES:EssentialProficiency in frontend frameworks such as React, Vue, or AngularStrong skills in geospatial libraries (e.g., Leaflet, Mapbox GL JS, OpenLayers)Experience with data visualization libraries (e.g., D3.js, Plotly.js)Ability to design user-friendly, accessible interfaces (WCAG 2.1 compliance)Strong communication and collaboration skills for multidisciplinary teamworkDesirableAbility to conduct user research and translate findings into functional specificationsExperience with content management systems or admin dashboardsFamiliarity with agile development methodologies and version control systems (e.g., Git)BenefitsThis is a globally hired consultancy; therefore, individuals or firms with relevant abilities are encouraged to apply. IWMI offers a competitive rate for this assignment. The contract duration is four (04) months.How to Apply: Apply for the position by following the application instructions at https://www.iwmi.org/jobs. Applications will be accepted until 24:00 (IST) on December 06, 2025, and will be reviewed on a rolling basis. Your application must include a CV/Company profile, cover letter, three (3) references, and both a technical and financial proposal. All applications will be acknowledged, but only shortlisted candidates will be contacted.IWMI believes that diversity fuels our innovation, enhances our excellence, and is essential to our mission. We offer a multicultural, multicolor, multigenerational, and multidisciplinary working environment. We are committed to creating an inclusive organization that reflects our global character and our dedication to gender equity. We, therefore, encourage applications from individuals of all cultures, races, ethnicities, religions, sexes, national or regional origins, ages, disability statuses, sexual orientations, and gender identities.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Contract",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "React",
      "Plotly",
      "AWS",
      "Azure",
      "Google Cloud",
      "GCP",
      "Git",
      "Data Visualization",
      "Version Control",
      "UI/UX"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_003"
  },
  {
    "job_id": "lead-web-developer-at-dijital-team-4280549991",
    "title": "Lead Web Developer",
    "company": "Dijital Team",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-12",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-web-developer-at-dijital-team-4280549991?position=22&pageNum=0&refId=L7Ew%2BZuTWuxYAD%2BFtKdRIw%3D%3D&trackingId=zt9F1KrL9BflrhcHVW4n7Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424175",
    "description": "As a Web Developer, you’ll be part of a high-performing team focused on bringing these websites to life. You’ll work with strategy, content, and design teams to develop scalable, lightning-fast sites — delivering 6 websites per month, each with around 20 pages.This is an exciting opportunity to help shape a productised service offering from scratch, with space to grow your impact as the service expands. If you’ve previously worked in a content-led environment, like a marketing agency or startup, that’s a strong advantage — we move fast, collaborate deeply, and value people who understand the intersection of content, design, and technology.ResponsibilitiesLead end-to-end development of custom-designed, AIO-optimised websitesBuild :6 websites per month (20 pages each) using clean, modular codeTranslate Figma designs into responsive front-end codeOptimise websites for AI visibility (structured data, metadata, schema)Support both headless CMS and WordPress-based projectsEnsure fast performance, accessibility, and responsiveness across devicesHelp define reusable frameworks and scalable build processesCollaborate with strategy, content, and design teamsStay informed on the latest in AI search, web tech, and UX trendsKPI’s:Deliver 6 high-quality, fully functional websites per monthMaintain and improve development workflow efficiencyContribute to documentation of dev stack/processesAs the role expands, contribute to other internal builds and toolsTo be successful in this role, you will have: Technical Skills (Essential):Strong front-end development: HTML5, CSS3, JavaScript (ES6+)Experience with custom coding (no-template builds)Familiarity with Java, responsive frameworks, and CMS platformsAI/SEO optimisation: schema markup, metadata, structured contentProficient in Figma — able to interpret and occasionally refine designsUnderstanding of version control (Git), performance optimisation, site speedAbility to work across service-based websites with a design-first mindsetBonus / Nice to Have:Experience with Framer (or willing to learn)Familiarity with WordPress, Shopify, WebflowAnimation tools (e.g., GSAP, Framer Motion)Understanding of content pipelines (e.g., Markdown, CMS templating)UX/UI design sensibilityExperience embedding AI-driven tools or interfacesWeb accessibility knowledgeKnowledge of privacy, compliance, and consent frameworksSoft SkillsHigh attention to detailExcellent verbal and written communicationStrong eye for design — pixel-aware and brand-consistentSelf-driven with a desire to grow and developComfortable multitasking in a dynamic environmentCollaborative mindset with the ability to work closely with content and marketing teamsWe may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Transportation, Logistics, Supply Chain and Storage"
    },
    "skills": [
      "HTML5",
      "CSS3",
      "JavaScript",
      "Java",
      "Git",
      "Figma",
      "WordPress",
      "Shopify",
      "GSAP",
      "Framer Motion",
      "Webflow",
      "Markdown",
      "CMS",
      "Schema Markup"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_004"
  },
  {
    "job_id": "jr-web-developer-entry-level-at-planned-systems-international-4280244237",
    "title": "Jr Web Developer (Entry Level)",
    "company": "Planned Systems International",
    "location": "United States",
    "posted_date": "2025-11-23",
    "job_url": "https://www.linkedin.com/jobs/view/jr-web-developer-entry-level-at-planned-systems-international-4280244237?position=3&pageNum=0&refId=Bgp%2BtmHYD1x78b2TZ2omXA%3D%3D&trackingId=8zTbjPCa0yJGLlM4%2BcrCPw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424177",
    "description": "Planned Systems International (PSI) is an Enterprise IT services company who focuses on designing, building, securing, and operating cutting-edge software solutions that drive mission success and operational excellence for Federal Government organizations. PSI is currently seeking a dedicated and detail-oriented Junior Web Developer to join our dynamic team.Essential Functions And Job ResponsibilitiesSuccessful candidates will provide website design, development, testing, management and support of the hardware/software infrastructure for a web-based portal for our government client. Essential functions will include, but not be limited to: Performing all aspects of the development tasks, including front-end, back-end, and database development. Managing resources to ensure timely and successful deliveries. Working with clients and review panels to identify recommendations for the appropriate technical, business and human factors solutions. Commitment to clear and quality communications between team and client product managers. Commitment to promoting a collaborative work environment with team members and customers. Develop and maintain web-enabled capabilities and custom applications. Lead staff in defining and tracking project requirements, plans, and schedules. Commitment to delivery of quality products. Minimum Requirements Bachelor’s degree in Computer Science, Engineering, or closely related field. Strong understanding of user interface design principles, with proven track record of creative web site development in accordance with the design specifications, user interface style guides and established usability standards. Familiarity with J2EE/Java Frameworks, programming experience and overall Java development techniques to perform daily Java development, automated unit testing, and troubleshooting responsibilities. Must have strong experience working with a variety of technology and the ability to multi-task between different projects and workflow stages. Must have experience communicating directly with end users and the ability to gather requirements. Experience analyzing business product needs, recommending, then possibly implementing, effective software solutions in a timely manner. Experience analyzing core standards for software development, and maintaining an effective process for support. Experience providing guidance and leadership to other developers and development teams. U.S. Citizenship is required. Candidates selected must be able to successfully obtain and maintain a Public Trust security clearance. Desired Qualifications Currently holds a DHS Public Trust Clearance. Certified in Lean Software Development, Kanban, Scrum and other Agile processes. Department Homeland Security (DHS) Experience. Company BenefitsPSI offers full-time, benefits eligible employees a competitive total compensation package that includes paid leave, and options for employer sponsored group medical, dental, vision, short-term and long-term disability, life insurance, AD&D coverage, legal services, identity theft, and accident insurance. Flexible spending account and health saving account options offer pre-tax savings for qualified medical, dental, and vision expenses. The company sponsored 401(k) retirement plan has an employer contribution match that is immediately vested. We invest in the professional growth of our employees through professional courses, certifications, and tuition reimbursement programs. EEO Commitment It is company policy to promote equal employment opportunities. All personnel decisions, including, but not limited to, recruiting, hiring, training, promotion, compensation, benefits, and termination, are made without regard to race, color, religion, age, sex, sexual orientation, pregnancy, gender identity, genetic information, national origin, citizenship status, veteran status, protected veteran status, disability, or any other characteristic protected by applicable federal, state, or local law.Reasonable accommodations for applicants and employees with disabilities will be provided. If a reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Human Resources by emailing HRDepartment@plan-sys.com , or by dialing 703-575-8400.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Java",
      "J2EE",
      "JavaScript",
      "HTML",
      "CSS",
      "Unit Testing"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_005"
  },
  {
    "job_id": "junior-web-developer-at-oasis-beach-club-4324551673",
    "title": "Junior Web Developer",
    "company": "Oasis Beach Club",
    "location": "United States",
    "posted_date": "2025-11-26",
    "job_url": "https://www.linkedin.com/jobs/view/junior-web-developer-at-oasis-beach-club-4324551673?position=5&pageNum=0&refId=Bgp%2BtmHYD1x78b2TZ2omXA%3D%3D&trackingId=7Y8aXi%2FGlrAB8cw6DnKiZw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424180",
    "description": "Role DescriptionThis is a full-time remote role for a Junior Web Developer. The Junior Web Developer will be responsible for creating, updating, and maintaining websites, developing front-end user interfaces, and building reliable back-end functionalities. The role includes programming to implement web features, troubleshooting issues, and collaborating with cross-functional teams to ensure seamless web experiences. Following best practices in coding and design will be essential to maintain quality and performance standards.QualificationsSkills in Front-End Development, Web Design, and user interface implementationExperience with Back-End Web Development and creating scalable website structuresProficiency in Web Development and ProgrammingFamiliarity with debugging and optimizing website performanceStrong problem-solving abilities and attention to detailAbility to work collaboratively in a remote team environmentBachelor’s degree in Computer Science, Information Technology, or a related fieldExperience with responsive design and knowledge of modern web frameworks is a plus",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Restaurants"
    },
    "skills": [
      "HTML",
      "CSS",
      "JavaScript",
      "Web Design",
      "Front-End Development",
      "Back-End Development",
      "Responsive Design",
      "Web Frameworks"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_006"
  },
  {
    "job_id": "junior-web-developer-remote-%E2%80%8B-at-taskify-ai-4339125657",
    "title": "Junior Web Developer (Remote)",
    "company": "Taskify AI",
    "location": "United Kingdom",
    "posted_date": "2025-11-26",
    "job_url": "https://uk.linkedin.com/jobs/view/junior-web-developer-remote-%E2%80%8B-at-taskify-ai-4339125657?position=6&pageNum=0&refId=JDsaYO7633FKWzg2mMq%2BEQ%3D%3D&trackingId=QYbSvEqyI2EqT3Z%2F7d39uQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424184",
    "description": "Role: Junior Web Developer (Remote)Location: Remote (US, UK, CA, IE, AU, NZ)Pay: Competitive monthly compensation up to $10,000, based on role and performanceWe’re looking for detail-oriented professionals to support a variety of content and AI-related evaluation tasks. This role involves reviewing written material, analysing responses, and helping enhance the quality, accuracy, and clarity of AI-generated output. Work is task-based, fully remote, and flexible, allowing you to choose your hours.What You’ll Do:Review written responses for accuracy, clarity, structure, and relevanceEvaluate AI-generated content and identify areas for improvementFollow project-specific guidelines to ensure consistent qualityProvide structured feedback and written assessmentsWork on multiple task types depending on project needsWhat Makes You a Good Fit:Strong written communication and analytical abilityAbility to assess content for clarity, logic, and coherenceComfortable reviewing and improving written responsesHigh attention to detail and the ability to follow guidelinesAble to work independently and meet quality standardsWhy This Role:Remote, flexible scheduleProject-based assignmentsOpportunity to contribute to improving next-generation AI systemsWorkload based on performance and project availabilityApply today to join our team!",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Part-time",
      "Job function": "Information Technology, Education, and Project Management",
      "Industries": "Technology, Information and Media"
    },
    "skills": [
      "HTML",
      "CSS",
      "JavaScript",
      "Content Evaluation",
      "AI Systems"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_016"
  },
  {
    "job_id": "web-developer-at-obermind-ltd-4336555109",
    "title": "Web Developer",
    "company": "Obermind Ltd",
    "location": "United Kingdom",
    "posted_date": "2025-11-18",
    "job_url": "https://uk.linkedin.com/jobs/view/web-developer-at-obermind-ltd-4336555109?position=17&pageNum=0&refId=JDsaYO7633FKWzg2mMq%2BEQ%3D%3D&trackingId=gYCf%2BSZHilwfd9JQqonM4Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424186",
    "description": "Technology at ObermindBeing part of our growing Web Applications team, you will be delivering high-performance web applications and API’s required to run successful financial technology businesses. Activities range from integrating external API’s with our platform and customising our multiple API protocols, designing custom databases for our customers and producing high-performance front-end web and mobile solutions using our proprietary fintech platform and SDK. You will be trained and interact closely with engineers, traders and researchers around the globe to understand the business needs and design effective solutions. Our Web tech-stack:TypeScript, React 19, Next.js 15, Node.js, Keystatic CMS, Tailwind CSS 4, Motion (Framer Motion), PostgreSQL/SQL Server.What you’ll needMastery of TypeScript and modern React (Server Components, async/await patterns);Experience with Next.js 15 App Router and server-side rendering;Ability to write simple, clean, and semantic code;Strong understanding of Web API protocols (REST, WebSocket, GraphQL);Experience with headless CMS systems (Keystatic, Strapi, or similar);Proficiency in Tailwind CSS and responsive design principles;Experience with Figma-to-code workflows and design systems;Knowledge of i18n/multilingual implementations;Familiarity with Vercel/serverless deployments;Entrepreneurial attitude and interest in financial technology;An ambition to stay on top of things and always improving.Understanding of trading platforms or fintech products.What to expect from ObermindWe are a small team of experienced engineers and traders without any hierarchical structure. We have an energetic and collaborative work culture with ambitious and down-to-earth colleagues. We always ask ourselves how to do better, ensuring a stimulating and innovative environment. Next to a competitive salary and excellent benefits (profit-sharing structure, training opportunities, discounts on health insurances), you will get the support and tools to develop your skills on the job.About ObermindOver twenty years ago, the founders of Obermind began market making and building financial technology. Today, we are joining forces with forward-thinking trading and financial firms around the globe to build and optimise modern financial technology. We build trading front-ends, applications, exchanges, pricing/matching engines, quantitative research technology, customised hardware/network infrastructure and advanced investment and trading tools for our clients. We support a wide array of trading, payments and investment products, including FX, Equities, Futures, Cryptocurrencies, ETFs, Bonds, Managed Funds and more. We are a market-neutral firm, enabling us to objectively improve our customers’ trading technologies and infrastructure and provide efficiencies for their end users, across the globe. As a fast-growing startup, what unites us Oberminders is our mission to improve financial markets and technology. Thriving in a high performance environment, we pioneer our own financial systems using clean code and sophisticated technology. Learn more at https://obermind.com BenefitsContinuous training and development opportunitiesAccess to conferences, participation in tech and financial eventsAn international work environmentCompetitive remuneration25-30 paid vacation daysHealth insurance discounts/sponsorshipsJoel TestDo you use source control?☑Can you make a build in one step?☑Do you make daily builds?☑Do you have a bug database?☑Do you fix bugs before writing new code?☑Do you have an up-to-date schedule?☑Do you have a spec?☑Do programmers have quiet working conditions?☑Do you use the best tools money can buy?☑Do you have testers?☑Do new candidates write code during their interview?☑Do you do hallway usability testing?☑",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Information Technology & Services"
    },
    "skills": [
      "TypeScript",
      "React",
      "Next.js",
      "Node.js",
      "Keystatic CMS",
      "Tailwind CSS",
      "Framer Motion",
      "PostgreSQL",
      "SQL Server",
      "GraphQL",
      "WebSocket",
      "Vercel",
      "Serverless",
      "Figma",
      "i18n",
      "REST API"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_018"
  },
  {
    "job_id": "junior-web-developer-at-guruschools-llc-4337158225",
    "title": "Junior Web Developer",
    "company": "GuruSchools LLC",
    "location": "Jersey City, NJ",
    "posted_date": "2025-11-20",
    "job_url": "https://www.linkedin.com/jobs/view/junior-web-developer-at-guruschools-llc-4337158225?position=11&pageNum=0&refId=Bgp%2BtmHYD1x78b2TZ2omXA%3D%3D&trackingId=OWrv3J6fD6iAFmo%2FQTiCbw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424188",
    "description": "Position: Junior Web Developer Location: Jersey, New JerseyExperience: 0-4 YearsMode of Working: Remote (Work From Home)Employment Type: Full-Time Job Summary We are looking for an enthusiastic Junior Web Developer to join our development team. This role is ideal for candidates with 0-3 years of experience who want to build strong skills in front-end and back-end web development. The position includes complete on-the-job training, real-time project support, interview preparation, and continuous job assistance to help you grow as a professional Web Developer. Responsibilities Develop, maintain, and enhance websites and web applicationsWork with HTML, CSS, JavaScript, and frameworks to create responsive user interfacesAssist in building and maintaining backend APIs using technologies like Node.js, Python, PHP, or similarCollaborate with designers and senior developers to transform requirements into functional featuresPerform website testing, debugging, and optimization to ensure high performanceSupport integration with databases, third-party APIs, and backend servicesParticipate in real-time projects to gain hands-on development experienceTake part in interview preparation sessions and receive ongoing job support Required Skills0-4 years of experience in web developmentStrong understanding of HTML5, CSS3, JavaScript, and responsive designFamiliarity with at least one front-end framework (React, Angular, or Vue.js)Basic knowledge of backend development (Node.js, Python, PHP, or Java)Understanding of REST APIs, Git, and version control workflowsGood problem-solving abilities, attention to detail, and communication skillsWillingness to learn new frameworks, libraries, and web technologies",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Contract",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "HTML5",
      "CSS3",
      "JavaScript",
      "React",
      "Angular",
      "Vue.js",
      "Node.js",
      "Python",
      "PHP",
      "Java",
      "REST API",
      "Git",
      "Version Control"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_008"
  },
  {
    "job_id": "jr-front-end-web-developer-at-webfx-4333788682",
    "title": "Jr. Front-End Web Developer",
    "company": "WebFX",
    "location": "Ann Arbor, MI",
    "posted_date": "2025-11-25",
    "job_url": "https://www.linkedin.com/jobs/view/jr-front-end-web-developer-at-webfx-4333788682?position=13&pageNum=0&refId=Bgp%2BtmHYD1x78b2TZ2omXA%3D%3D&trackingId=2V8KQBp5ah9ek7acd7MrQA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424190",
    "description": "Hi there! We're WebFX, a full-funnel revenue marketing agency based in the US. We've been 9x named a Best Place To Work, and we'd love to meet you! We are a fast-growing company of more than 700 FXers, that has doubled in size over the past 5 years, with talented team members in 6 US offices, 20+ states, and now based around the globe (and representing 18+ different countries!). While WebFX and our subsidiary companies, such as Nutshell CRM, SEO.com, and TeamAI, are growing rapidly, we are committed to growing strategically and sustainably, and that starts with growing our team of the #BestCoworkers - that’s where you come in!We're looking for talented professionals to join our Ann Arbor office location - home to the Nutshell team! Nutshell is an award-winning CRM and email marketing platform, and as of 2022, WebFX and Nutshell have officially joined forces. Our teams work together closely to provide the very best products and services to our clients, and we're on the hunt for people just like you, who take pride in their work and want to be part of a company that does too.You Might Be a Great Fit For This Position if You Have…A Bachelor’s DegreeSuccessful Nutshellers in this role have majored in computer science and related fieldsGPA above 3.5 A Few Related Skills and Experiences(This is an entry-level role, and experience in every one of these areas is not required - training is provided on all core platforms, tools, and technologies you will need to know! But the following skills/experience are awesome to have, and will help get your career off to a running start:):Part-time/volunteer/internship programming experience is a mustDevelopment experience in front-end web development —Javascript, React, etcWorking knowledge of modern software development frameworks, including server-side MVC (e.g. Symfony, Rails)Strong background in SQL and relational databasesBackground and opinions on HTTP API design—we’ve got a blend of JSON-RPC, REST, and GraphQLExperience with unit testing and continuous integrationAny of these Signature Nutsheller Traits!You’re passionate about web/software development - you even find yourself spending your free time tinkering and learning new technologies!You’re committed to delivering high-quality softwareYou enjoy variety, and like the challenge of working on multiple projectsYou’re comfortable working both independently and as part of a teamYou take direction well, but aren’t afraid to take initiative and make decisionsYou see yourself as a problem-solver, and face challenges with a can-do mindsetYou put the customer and their goals firstYou have an interest in the web and stay up-to-date on new and developing technologiesYou are a professional, dependable, and independent worker with a solid work ethicYou’re self-motivated, thrive on challenges, and enjoy getting things doneYou have an eye for detail and dedication to high-quality workYou have an exceptional level of follow-throughYou possess excellent time/project management skillsYou work with a sense of urgency and can consistently meet deadlinesYou are an outstanding communicator and possess strong interpersonal skillsYou are a lifelong learner who loves to grow and stretch outside of your comfort zone, and are always looking to improve your skillsIf any of these sound like you, then we want to hear from you! We are committed to growing 1% better every day, and we believe working at Nutshell could quite possibly make your life 1(00)% better!About the JobAs a Jr. Front-End Web Developer, you’ll team up with others in various stacks at Nutshell. You can hone your skills alongside a frontend team that writes for both web and mobile in React + React Native, while you build the GraphQL and cloud infrastructure that powers our app. You’ll work with the data we store in MySQL and Solr on AWS. And with our continuous integration and rapid development stack, you’ll deploy tested, peer-reviewed code to production on your first day. Our technology stack includes:-PHP, Symfony, Nginx, MySQL, Solr, Gearman, and more, all running on AWS, managed with Ansible-React, React Native, Redux, and Webpack for web and mobile frontend tooling-Docker for local development-GitHub for code management and review-Continuous integration via JenkinsWhat You’ll Get From Us!As a product teamNutshell’s product team offers the opportunity to learn from a smart group of teammates who support and drive one another to succeed. Today, our product group comprises :15 designers, engineers, and project managers. Some have decades of experience, some are just out of college with a CS degree, and a few have entered software engineering as a second career. As a company-Opportunities to learn and thrive in a friendly, growing SaaS business-A commitment to an inclusive environment that supports our diverse team-A connection to Ann Arbor’s software and startup community through our network of friends and partners-A modern office located on Ashley Street in the heart of downtown Ann Arbor-Flexibility in working modes and locations, as we regroup at our office, and support other distributed team members-The sincerity and commitment of an established company: excellent health benefits, 401(k) matching, an experienced leadership team, and a profitable, growing financial position-The opportunity to help thousands of small businesses each day-Trust and autonomy to ensure you can be the best version of youPotential promotional path for Jr. Web Developer:Web DeveloperAssociate Web DeveloperAssociate Lead Web DeveloperLead Web DeveloperSr. Web DeveloperCompensationNegotiable based on work experiencePotential additional bonus may be offered for GPA's of 3.8+ or graduating with high honorsWhy Choose WebFX?- We've been named the Best Place To Work in our home state of Pennsylvania 9 times 🎉- We have offices in Guatemala, South Africa, St. Petersburg FL, Ft. Myers FL, Lancaster, and York, PA! AND we're continuing to grow! 🌱📈- Entry-level roles - over 90% of our openings are open to brand new college grads! 🎓 - Flexible Schedule (start your day between 8 and 10 am - when you do your best work!)- Love animals? Cool, so do we! That's why we have a Pet Friendly Office 🐶- Profit Sharing 💰 - 150% Company Match Of Personal Charity Donations- Our #FXBuilds program is set to positively impact 10,000 people around the world by 2024 - and every individual FXer’s work directly contributes! 🌍- Supplemental Insurance- 100% Company Match 401K (up to 4%) 💰 - Generous Paid Time Off 🏖- Employee Wellness Program, including a free FitBit and fitness challenges 👟- Love to learn? You sound like an FXer! FXLearns Library with hundreds of personal and professional growth books 📚- Humanitarian Trips ✈️- Health/Vision/Dental Coverage- New Parent Support 👶🏿👶- Dressing up everyday not for you? We get it! Enjoy our Casual Dress Code- Home Buyer Program 🏡- Personal Desk Fund 💰 - Green Commute Benefits- Pawternity Leave 🐱- Merit-based promotions (we promote from within, you will move up and grow here!)-The opportunity to be part of a passionate, driven team where we pride ourselves on delivering high-quality work that makes a real-world impact for our clientsCheck out our culture on social media:InstagramTwitterFacebook*You don't need to apply more than once even if you're interested in multiple positions - you can simply let us know! We consider all open roles when reviewing resumes and applications! Nutshell is an Equal Opportunity Employer, committed to providing and fostering an inclusive environment where all people, including women, minorities, LGBTQ+ and other underrepresented groups are supported, respected, and encouraged to excel within STEM careers. Our goal as an organization is to empower our team to achieve their personal best, bring people together, and provide equal opportunity to do so regardless of race, age, gender, sexual orientation, religion, physical ability or disability, or political affiliation. You can learn more on our parent company's website here!!We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development, IT Services and IT Consulting, and Biotechnology Research"
    },
    "skills": [
      "JavaScript",
      "React",
      "React Native",
      "Redux",
      "Webpack",
      "GraphQL",
      "MySQL",
      "Solr",
      "PHP",
      "Symfony",
      "Nginx",
      "Gearman",
      "AWS",
      "Ansible",
      "Docker",
      "GitHub",
      "Jenkins",
      "Unit Testing",
      "Continuous Integration"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_009"
  },
  {
    "job_id": "frontend-web-developer-at-bubblynet-4347514675",
    "title": "Frontend Web Developer",
    "company": "BubblyNet",
    "location": "Clearwater, FL",
    "posted_date": "2025-11-24",
    "job_url": "https://www.linkedin.com/jobs/view/frontend-web-developer-at-bubblynet-4347514675?position=20&pageNum=0&refId=Bgp%2BtmHYD1x78b2TZ2omXA%3D%3D&trackingId=8Nmw%2B57LTOm1T8KmWu7ZQQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424191",
    "description": "We are worldwide one of the top 3 companies in the Bluetooth Mesh for lighting controls space and we intend to become the best at it www.bubblynet.comJob SummaryOur Web Developer (Frontend) is responsible for maintaining and improving our company’s websites, ensuring they remain fast, secure, and reliable. This role involves managing the full technical lifecycle of our web properties — from backend performance and scalability to frontend usability and accessibility.We’re looking for a developer who combines strong technical expertise with an eye for design. You should feel comfortable working across modern web technologies, collaborating with designers and marketing teams to bring creative concepts to life.Success in this role requires curiosity and adaptability. You must enjoy staying current with web standards, emerging frameworks, and best practices to continuously improve our digital presence.We’re looking for someone who understands the full web development lifecycle — from version control and CI/CD pipelines to SEO optimization, analytics integration, and accessibility compliance. A successful candidate will stay current with evolving frameworks, security best practices, and DevOps workflows to ensure our web platforms remain robust and future-ready.This position reports to the Cloud team and works closely with the development department to implement new features, campaigns, and site optimizations that support business goals.Duties & ResponsibilitiesDevelop, maintain, and deploy web client applications using web technologies such as HTML, CSS, TypeScript, Bootstrap, and ReactDevelop using Django, Flask, FastAPI to create small python based web appsDeploy and scale applications across managed and unmanaged cloud environments, using best practices for reliability and cost efficiencyImplement and maintain CI/CD pipelines with tools like Docker, Google Cloud Run, and Google Cloud Build, ensuring smooth version control and automated deployment workflowsCollaborate with other developers to ensure website content, product data, and specifications are accurate and visually consistent with brand standardsMonitor and analyze site performance through analytics and email tracking tools such as Google Analytics and SendGrid, providing actionable insights and reportsWork in Linux-based environments, utilizing SSH and SFTP for secure server access, configuration, and file managementPerform light digital asset optimization, such as image compression, resizing, and cropping, to improve load times and user experienceTechnical RequirementsProficiency in HTML and CSS for building responsive, accessible front-end interfacesStrong understanding of JavaScript, TypeScript, and Node.js for developing dynamic, full-stack applicationsExperience with React for building modular and maintainable UI componentsCompetency in PHP and Python for backend development and system integrationNice to HaveExperience developing or maintaining applications in DjangoFamiliarity with Raspberry Pi’s, Arduino, etcFamiliarity with IoT control systems like Apple Home, Home Assistant, Hubitat, etcDrug Free Workplace:We are a Florida Drug Free Workplace. The company requires all employees to complete a pre-employment 10 panel drug screen; employment status will be dependent on ability to pass this screening and partake on a quarterly random screen.Hours, compensation & benefits:This is a full-time, salaried role. Salary begins at $70,000 and is negotiable based on skillset and experience. This position is on-site on a standard office schedule between the hours of 8am to 5pm, with some flexibility when needed, offering 2 days of remote work once reached “autonomously without supervision” work.After a 30-day waiting period full-time employees become eligible for Medical, Dental and Vision insurance, paid holidays and paid time off that increases with longevity and after 90-days employees may participate in the company-sponsored 401(k) plan.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Sales, General Business, and Education",
      "Industries": "Wireless Services, Telecommunications, and Communications Equipment Manufacturing"
    },
    "skills": [
      "HTML",
      "CSS",
      "JavaScript",
      "TypeScript",
      "React",
      "Node.js",
      "Django",
      "Flask",
      "Bootstrap",
      "Google Cloud Platform",
      "Cloud Run",
      "Cloud Build",
      "Docker",
      "CI/CD",
      "Linux",
      "SendGrid",
      "Google Analytics",
      "SFTP",
      "SSH"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251127_013"
  },
  {
    "job_id": "software-engineer-at-pearson-4324801180",
    "title": "Software Engineer",
    "company": "Pearson",
    "location": "Sri Lanka",
    "posted_date": "2025-11-26",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-at-pearson-4324801180?position=15&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=aOY5mzwIDhKNPA3Y0JNGlA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424193",
    "description": "Synopsis: Designs and develops internet scale applications and supports throughout their lifecycleResponsibilitiesDeveloping and maintaining top-notch software applications built on private & public cloud.Architecting & Designing applications by adapting proven industry best practices alongside the R&D objectives.Raising the bar on application & infrastructure code quality.Strengthening the application and platform Security by adopting security best practices.Ensuring the Compatibility and Accessibility conformity along with various Non-Functional Requirements throughout the application lifecycle.Automating functional & other quality tests at different layers of the application to uncover issues as early as possible.Improving application's ability to continuously integrate & deploy to facilitate frequent and smaller releases with no customer impact.Baking Observability into the applications, actively monitoring and resolving issues promptly.Monitoring various performance indicators of the applications and making continuous improvements and optimizations.RequirementsA bachelor's degree in Software Engineering, Computing or a related field.Minimum of 2 years of experience in Software Engineering.An up-to-date knowledge on industry trends & new developments in programming, application development and lifecycle management.A passion for solving problems with innovative & practical solutions.Strong analytical and reasoning skills with the ability to visualize the outcomes.Thorough knowledge on algorithms & data structures.Proficiency in at least two high level programming languages including Java and the ability to quickly adopt languages & techniques.Previous experience with ReactJS , Node and frameworks such as SpringBoot, Redux would be beneficialPrevious experience in MongoDB would be an added advantagePractical experience in cloud environments, preferably in AWS would be beneficialAbility to craft quality code and automate various types of tests on application components.Proficiency in monitoring applications, troubleshooting and fixing application issues.Thorough knowledge on the Non-Functional requirements of applications such as Security, Accessibility, Compatibility, Observability & Availability.Working knowledge on continuous integration and deployment.Who We AreAt Pearson, our purpose is simple: to help people realize the life they imagine through learning. We believe that every learning opportunity is a chance for a personal breakthrough. We are the world's lifelong learning company. For us, learning isn't just what we do. It's who we are. To learn more: We are Pearson.Pearson is an Equal Opportunity Employer and a member of E-Verify. Employment decisions are based on qualifications, merit and business need. Qualified applicants will receive consideration for employment without regard to race, ethnicity, color, religion, sex, sexual orientation, gender identity, gender expression, age, national origin, protected veteran status, disability status or any other group protected by law. We actively seek qualified candidates who are protected veterans and individuals with disabilities as defined under VEVRAA and Section 503 of the Rehabilitation Act.If you are an individual with a disability and are unable or limited in your ability to use or access our career site as a result of your disability, you may request reasonable accommodations by emailing TalentExperienceGlobalTeam@grp.pearson.com.Job: EngineeringJob Family: TECHNOLOGYOrganization: Higher EducationSchedule: FULL_TIMEWorkplace Type: HybridReq ID: 21827",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Education Administration Programs and E-Learning Providers"
    },
    "skills": [
      "Java",
      "ReactJS",
      "Node.js",
      "Spring Boot",
      "Redux",
      "MongoDB",
      "AWS",
      "Continuous Integration"    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_007"
  },
  {
    "job_id": "software-engineer-data-remote-full-time-at-cut%2Bdry-4339254514",
    "title": "Software Engineer - Data (Remote) Full-Time",
    "company": "Cut+Dry",
    "location": "Sri Lanka",
    "posted_date": "2025-11-27",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-data-remote-full-time-at-cut%2Bdry-4339254514?position=16&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=CXewBK2Y9FL9%2Bc%2B%2F1Ncedg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424195",
    "description": "Data Pipeline DevelopmentDesign, develop, and maintain scalable ETL/ELT pipelines using tools like Airbyte, Python, and SQL. Write reliable transformation scripts and implement robust data validation processes.Monitor and improve data quality, latency, and availability across ingestion pipelines.Software Engineering & AutomationWrite clean, maintainable, and well-tested code to support data operations.Build internal tools and automation scripts to streamline data workflows.Work closely with backend teams to integrate application data into the warehouse.Warehouse Management & OptimizationContribute to data modeling and Snowflake schema design that supports analytics, reporting, and self-service BI.Optimize Snowflake queries and storage to improve performance and cost-efficiency.Collaboration & Stakeholder SupportCollaborate with analysts, product managers, and business users to understand data needs and design appropriate solutions. Support reporting, dashboards, and analytics projects by making data assets easily consumable.Infrastructure & DevOpsWork with AWS services (e.g., S3, Lambda, RDS) as part of the data ingestion and processing workflows.Contribute to CI/CD practices, infrastructure-as-code, and monitoring for data pipelines.Qualifications2+ years of experience as a Software Engineer, Data Engineer, or Full-Stack Developer working with data-intensive systems.Strong proficiency in Python and SQL (or similar scripting languages) for data processing and transformation.Experience with modern data warehouses, ideally Snowflake.Familiarity with ELT/ETL tools such as Airbyte or similar platforms.Hands-on experience with AWS services and basic infrastructure automation (IaC).Solid software engineering fundamentals including version control, testing, and modular code design.Strong analytical and problem-solving skills, especially when dealing with complex or inconsistent datasets.Effective communicator with the ability to collaborate across technical and non-technical teams.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "SQL",
      "Snowflake",
      "Airbyte",
      "AWS",
      "S3",
      "Lambda",
      "RDS",
      "CI/CD",
      "IaC",
      "ETL",
      "ELT",
      "Data Pipeline",
      "Data Modeling",
      "Data Validation"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_008"
  },
  {
    "job_id": "associate-software-engineer-python-at-ilabs-4321207367",
    "title": "Associate Software Engineer - Python",
    "company": "iLabs",
    "location": "Battaramulla, Western Province, Sri Lanka",
    "posted_date": "2025-11-07",
    "job_url": "https://lk.linkedin.com/jobs/view/associate-software-engineer-python-at-ilabs-4321207367?position=25&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=ZzQnBS7JBWk%2FBpyVXCxmNQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424197",
    "description": "iLabs is a global software product engineering company headquartered in Sri Lanka, with deep roots in the US Silicon Valley. We deliver world-class solutions in Web, eCommerce, Mobile, AI/ML, and Cloud technologies, serving industries such as fintech, edtech, medtech, martech, and hospitality. Guided by our vision “to become a global powerhouse in information technology to push humanity forward” we focus on delivering innovative, impactful solutions that empower businesses and create meaningful change in the world.With a global talent network, we build agile remote teams for leading tech companies worldwide, including Silicon Valley pioneers. Our in-house ventures include Cloud of Goods, a fast-growing eCommerce rental marketplace, and Xenia, a customizable web platform for modern businesses.At iLabs, we’re on a mission to advance lifestyles through technology and empower our partners to scale smarter and faster. Our culture is driven by creativity, innovation, ownership, teamwork, and global impact; giving you the opportunity and freedom to challenge the norm, spark change, and make a real difference.If you’re ready to break boundaries and create your defining moment, we’re here to make it happen. Be part of something bigger. Join iLabsJob RequirementsDesign and implement scalable, reliable distributed data processing frameworks and analytical infrastructure.Be part of a team to define, design, and implement data integration, management, storage, consumption, backup, and recovery solutions that ensure the high performance of the organization's enterprise data. Develop Structured Query Language (SQL), Data Definition Language (DDL), and Python or equivalent programming scripts to support data pipeline development, problem-solving, data validation, and performance tuning. Work with software engineers, devops, ML engineers, and data scientists to achieve the organization’s goals. Shift: 9.00am - 6.00pmLocation: Battaramulla (On-Site)Job RequirementsMinimum 0.6 - 1 years experience in the similar capacity with BS/MS degree in Computer Science, Engineering or a related subject.Strong knowledge of python programming languages is required.Experience with FastAPI, Django, Django REST Framework, and Celery for background task processing.Strong understanding of SOLID principles and ability to write clean, reusable, and maintainable code.Knowledge of MongoDB or AWS DocumentDB, along with caching technologies such as Redis.Experience with data engineering tools and platforms, including Delta Lake and Data Lakehouse architecturesProficiency in ELT/ETL data pipeline orchestration tools, such as Apache Airflow.Understanding about data warehousing solutions, relational database theories and no-sql databases.Good knowledge of new and emerging tools for extracting, ingesting and processing of large datasets (Kafka, Spark, Hadoop, DataBricks or equivalent).Hands-on experience with Amazon Web Services is a big plus and knowledge about other cloud systems (Azure/GCP).Understanding about dockerization and kubernetes, data modeling and design patterns is a big plus.Knowledge of web scraping technologies is a big plus (selenium, beautiful soup etc.).Familiarity with Linux.Excellent interpersonal, communication and organizational skills are required.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Information Technology & Services"
    },
    "skills": [
      "Python",
      "SQL",
      "Django",
      "FastAPI",
      "Django REST Framework",
      "Celery",
      "MongoDB",
      "Redis",
      "Databricks",
      "Delta Lake",
      "AWS",
      "Azure",
      "GCP",
      "Kubernetes",
      "Linux",
      "Hadoop",
      "Kafka",
      "Airflow",
      "ETL",
      "ELT",
      "Data Pipeline",
      "Data Warehousing",
      "Data Integration",
      "Selenium",
      "Beautiful Soup",
      "Web Scraping",
      "Caching"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_012"
  },
  {
    "job_id": "software-engineer-associate-react-native-at-ilabs-4322995059",
    "title": "Software Engineer / Associate - React Native",
    "company": "iLabs",
    "location": "Battaramulla, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-associate-react-native-at-ilabs-4322995059?position=26&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=LQvpPLFc8LoLMQbeVpK%2BIQ%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424199",
    "description": "iLabs is a global software product engineering company headquartered in Sri Lanka, with deep roots in the US Silicon Valley. We deliver world-class solutions in Web, eCommerce, Mobile, AI/ML, and Cloud technologies, serving industries such as fintech, edtech, medtech, martech, and hospitality. Guided by our vision “to become a global powerhouse in information technology to push humanity forward” we focus on delivering innovative, impactful solutions that empower businesses and create meaningful change in the world.With a global talent network, we build agile remote teams for leading tech companies worldwide, including Silicon Valley pioneers. Our in-house ventures include Cloud of Goods, a fast-growing eCommerce rental marketplace, and Xenia, a customizable web platform for modern businesses.At iLabs, we’re on a mission to advance lifestyles through technology and empower our partners to scale smarter and faster. Our culture is driven by creativity, innovation, ownership, teamwork, and global impact; giving you the opportunity and freedom to challenge the norm, spark change, and make a real difference.If you’re ready to break boundaries and create your defining moment, we’re here to make it happen. Be part of something bigger. Join iLabsJob ResponsibilitiesAssist in designing, developing, and maintaining mobile applications using React Native and Expo for both iOS and Android.Work closely with UI/UX designers, backend engineers, QA, and product teams to build and deliver new features.Contribute to the full feature lifecycle including planning, development, testing, and deployment.Support app releases, including handling basic tasks related to push notifications, version updates, and App Store / Play Store submissions.Integrate RESTful APIs and external data sources to ensure smooth communication between the mobile app and backend systems.Optimize app performance by identifying and fixing performance issues across devices and platforms.Participate in debugging, unit testing, and performance tuning to ensure app quality and stability.Write clean, reusable, and maintainable code following best practices and Git-based workflows.Assist in updating or refactoring existing React Native codebases under guidance.Stay up to date with new tools, libraries, and trends in the React Native ecosystem.Explore modern frameworks or AI SDKs when relevant, to support feature enhancements.Shift: 9.00am - 6.00pmLocation: Battaramulla (On-Site)Job Requirements1 to 2+ years of hands-on experience in React Native development, with strong JavaScript/TypeScript fundamentals.Hands-on experience contributing to at least one mobile app feature or module in a production environment.Familiarity with Expo, EAS, React Hooks, React Navigation, and TypeScript.Basic understanding of CI/CD processes, app release workflows, and push notifications.Knowledge of mobile app architecture fundamentals, navigation patterns, and performance best practices.Experience working with RESTful APIs, JSON data handling, and asynchronous workflows.Working knowledge of state management tools such as Redux, Zustand, or Context API.Ability to debug and troubleshoot using tools like Flipper or React Native Debugger.Practical experience using Git for version control and team collaboration.Bonus: Exposure to AI SDKs, native modules, or bridging concepts.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Information Technology & Services"
    },
    "skills": [
      "JavaScript",
      "TypeScript",
      "React Native",
      "Expo",
      "EAS",
      "React Hooks",
      "React Navigation",
      "Redux",
      "CI/CD",
      "Git",
      "Unit Testing",
      "iOS",
      "Android",
      "REST API",
      "Flipper"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_013"
  },
  {
    "job_id": "senior-software-engineer-remote-full-time-at-cut%2Bdry-4336908285",
    "title": "Senior Software Engineer (Remote) Full-Time",
    "company": "Cut+Dry",
    "location": "Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-software-engineer-remote-full-time-at-cut%2Bdry-4336908285?position=28&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=JwH5Ue3MkMWSybdGgjs5xw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424202",
    "description": "Our ideal candidate is a fast mover with a hunger for developing high-quality applications who will be responsible for implementing testable and scalable code. As an early-stage start-up, you must be able to thrive in a fast-moving, rapidly evolving work setting.Design and develop software components adhering to both functional and non-functional requirements.Work with a team of A-players while coaching, mentoring, and shaping junior engineers and our development efforts.Assure excellent quality of software development with a high level of unit, component, and end-to-end testing.Bachelor’s degree in computer science/engineering or equivalent technical field.Have at least 3+ year of experience in developing enterprise grade applications.Strong object-oriented programming skills in at least 1 programming language i.e.: Java, PHP.Experience with multiple languages will be an added advantage. Must be willing to work with Java and Spring boot related codebases.Experience with relational databases is a must. Having experience with NoSQL databases is a plus.Experience with multiple languages will be an added advantage.Experience with continuous integration and continuous delivery (CI/CD) tools and practices.Must be a high-quality coder who consistently applies best coding practices and design patterns to deliver clean, efficient, and scalable code.Possess excellent verbal and written communication skills.Have hands on experience in cloud platforms.Be passionate about solving problems.Why Work at Cut+Dry?Results-driven company culture that encourages a balanced lifestyle.Flexible remote working environment.Above market remuneration, based on experience and skill-level paid in USD.Work with cutting edge technologies in a collaborative and innovating setting.At Cut+Dry you will be part of a team that transforms an entire industry through technology, compensated above prevailing market rates and have access to an unparalleled employee benefits plan.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Java",
      "PHP",
      "Spring Boot",
      "NoSQL",
      "CI/CD",
      "Continuous Integration",
      "Continuous Delivery",
      "Design Patterns"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_014"
  },
  {
    "job_id": "software-engineer-igt1-lanka-sitecore-at-igt1-4340956996",
    "title": "Software Engineer (IGT1 Lanka: Sitecore)",
    "company": "IGT1",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-igt1-lanka-sitecore-at-igt1-4340956996?position=30&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=Xlzux4qQHClJ01x96HwUMA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424203",
    "description": "About IGT1 LankaIGT1 Lanka is a rapidly growing offshore technology and talent solutions company based in Port City Colombo. We are a fully owned subsidiary of IGT I Holdings Sweden AB, funded by the three of world’s leading private equity firms; EQT Group, Hg, and TA Associates. We’re also proud to be a sister company of IFS, Sri Lanka’s largest and most established technology company.At IGT1 Lanka, we partner with global businesses to scale operations, accelerate innovation, and build world-class SaaS platforms through high-quality offshore delivery. Our people-first culture champions diversity, teamwork, and continuous learning, creating an environment where talent thrives.With a team of over 400 professionals and counting, we are always looking for passionate, skilled individuals who want to make a global impact while being part of something extraordinary.Through our offshore collaboration model, you'll be embedded within the team of one of our esteemed international clients, contributing directly to high-impact, enterprise-level initiatives.About the client: Sitecore At Sitecore, their mission is to simplify how brands reach, engage, and serve people by delivering intelligent, personalized digital experiences that connect the world. They empower the world’s most iconic brands to build lifelong relationships with their customers seamlessly, smartly, and at scale.As the leading provider of agentic digital experience software, Sitecore brings together content, commerce, and data into one composable platform that enables brands to deliver millions of meaningful, adaptive experiences every day. Trusted by global leaders such as American Express, Porsche, Starbucks, and L’Oréal, Sitecore helps brands transform engagement through experiences that are not only personalized but predictive and dynamic.Job DescriptionAbout the role:The Software Engineer for Deployment team is a technically proficient, customer-centric role focused on supporting Sitecore Search customers. This individual will implement customer features, address issues/escalation from customers ensuring timely resolution and seamless implementation. The specialist will collaborate with internal teams—including Engineering, Product, and Customer Success—to escalate and resolve complex issues.Key ResponsibilitiesWe are seeking a driven and experienced professional with 2 to 3 years of relevant experience who will:Monitor customer site implementations and proactively address potential issues before they impact the customer. Assist customers in deploying search features, resolving technical problems, and configuring environments. Log and manage support tickets, track issue progress, and communicate updates to customers and the Customer Success (CS) team. Ensure helpdesk tickets are resolved within agreed service level agreements (SLAs). Participate in daily syncs with the US-based CS team to report issue status, stay informed on-site updates, and receive task assignments. Monitor system performance dashboards and alerts to identify and troubleshoot issues. QualificationsPreferred Skills and ExperienceStrong programming skills in Python or Golang and Shell ScriptingDeep understanding of API integrations and customer deployment workflows. Proven ability to take ownership of issues, conduct thorough investigations, and drive resolution while keeping all stakeholders informed. Excellent verbal and written communication skills in English. Understanding of web development frameworks such as React or Angular, along with HTML, CSS, and JavaScript. Hands-on experience with tools such as JIRA, ServiceNow, Opsgenie, and providing support via email and phone. Nice to haveSolid understanding of UX/UI design across web, mobile, and tablet platforms. Experience with AWS services including EC2, S3, and RDS. Proficiency in SQL and experience with RDS and NoSQL databases such as MongoDB. Familiarity with batch scheduling frameworks like Jenkins or Airflow is preferred. Additional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Executive",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development and IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Golang",
      "Shell Scripting",
      "API Integration",
      "React",
      "Angular",
      "HTML",
      "CSS",
      "JavaScript",
      "JIRA",
      "ServiceNow",
      "Opsgenie",
      "AWS EC2",
      "AWS S3",
      "AWS RDS",
      "MongoDB",
      "NoSQL",
      "Jenkins",
      "Airflow",
      "SQL"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_015"
  },
  {
    "job_id": "software-engineer-net-at-virtusa-4340005128",
    "title": "Software Engineer-.NET",
    "company": "Virtusa",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-net-at-virtusa-4340005128?position=33&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=e9SZTTiNN0GxztoA1Zv1oA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424205",
    "description": "1-2 years of development expertise in ASP.NET technology including MVC & Web APIExpertise in DB concepts & SQL (DB: SQL server)Ability to understand Design documents (UML Design)Basic knowledge in Design patternsExpertise / Knowledge in Agile methodologiesExpertise on Source code control usage or managementGood in resolving problems and efficiently learn advance technologiesGood communication skillsNice To HaveExperience in Azure OR React technologies",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "ASP.NET",
        "MVC",
        "Web API",
        "SQL",
        "SQL Server",
        "UML",
        "Design Patterns",
        "Source Control",
        "Azure",
        "React"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_017"
  },
  {
    "job_id": "intern-software-engineer-at-zebra-technologies-4341857722",
    "title": "Intern Software Engineer",
    "company": "Zebra Technologies",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-25",
    "job_url": "https://lk.linkedin.com/jobs/view/intern-software-engineer-at-zebra-technologies-4341857722?position=35&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=pHiGLbrvp80AI57zjuiiZg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424207",
    "description": "Remote Work: NoOverview:At Zebra, we are a community of innovators who come together to create new ways of working. United by curiosity and a culture of caring, we develop smart solutions that anticipate our customer’s and partner’s needs and solve their challenges.Being a part of Zebra Nation means you are seen, heard, valued, and respected. Drawing from our unique perspectives, we collaborate to deliver on our purpose. Here you are a part of a team pushing boundaries today to redefine the work of tomorrow for organizations, their employees, and those they serve.You'll have opportunities to learn and lead in a forward-thinking environment, defining your path to a fulfilling career while channeling your skills toward causes you care about – locally and globally.Come make an impact every day at Zebra.The purpose of this internship is to prepare students for entry into the business world by providing a thorough understanding of the various functions of the Zebra Technologies organization. The program is designed to provide students with experiences that provide insights into a career with Zebra. Students will be positioned for success with training and hands-on experiences, invited to social and development activities, and provided a professional mentor relationship.Responsibilities: Develop planning, organizational and leadership skills. Increase technology knowledge and skills, especially as it relates to Zebra’s product portfolio. Manage team-based work assignments. Practice interpersonal skills to connect with day-to-day business contacts through follow-upactivities.Qualifications:Minimum Education/Qualifications: Concurrent enrollment in a degree-seeking post secondary educational institution Work authorization and no requirement of sponsorship now or in the futureMinimum Work Experience (years):0 yearsKey Skills and Competencies: Communication Skills – Clear and effective verbal andwritten communication Adaptability and Learning Agility – Willingness to learnquickly, embrace new tools or methods, and thrive in adynamic, fast-paced environment. Technical Skills – Proficiency in Microsoft Office tools(e.g., Excel, Word, PowerPoint) and basic familiaritywith technology solutions. Integrity – Commitment to ethical behavior andconfidentiality.Position Specific Information:Travel Requirements: 0-10%Able to Telework? NoPersonal Protective Equipment (PPE) Required: NoSafety Sensitive Role? NoTo protect candidates from falling victim to online fraudulent activity involving fake job postings and employment offers, please be aware our recruiters will always connect with you via @zebra.com email accounts. Applications are only accepted through our applicant tracking system and only accept personal identifying information through that system. Our Talent Acquisition team will not ask for you to provide personal identifying information via e-mail or outside of the system. If you are a victim of identity theft contact your local police department.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Excel",
        "Word",
        "PowerPoint"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_018"
  },
  {
    "job_id": "software-engineer-backend-at-saltside-4322783150",
    "title": "Software Engineer (Backend)",
    "company": "Saltside",
    "location": "Sri Lanka",
    "posted_date": "2025-11-16",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-backend-at-saltside-4322783150?position=39&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=gFxPWZzpwml6rK5BrJVTuw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424209",
    "description": "Hey there!!It is good to see you interested in our open position for the role of Senior Software Engineer.Time is valuable, so we will not jibber jabber about ourselves. Rather you can read about us at your own leisure at Saltside.Nerd factsPeople come in many different shapes, and we are open to everyone.At Saltside, who you are is important - but never limiting. Our team represents people of different origin, sex, religion and beliefs.Our mission is simple;Our job is to build the easiest listing platform for buying, selling and recruiting.We sell increased exposure on our platform, with minimal manual involvement from usWe want to offer our employees a fantastic place to workWhether you have an academic background or just a lot of experience is less important to us, what we are interested in is someone with learning mindset ready for new challenges.Since we are a fully remote company, all the interviews for this role will be over a video call.Wearing the hat of a Software EngineerResponsibilitiesIn this role, you will be expected to:Design high quality components in Golang/Ruby with clean, tested code.Integrate AWS technologies to achieve high scale and reliability.Lead architecture, design, and develop features and solutions with high quality.Review and contribute to the team specifications and implementations.Design and implement Backend Services for front-end consumption.Take ownership of code base and contribute to its improvement.Practice continuous delivery & improvements at all levels.Necessary Skills & ExperienceThe following are necessary to be successful in this role:You must have 3+ years of backend development experience (Ruby/Go preferred but other backgrounds are acceptable).A solid foundation in computer science (data structures, algorithms, design patterns).Experience building large-scale server applications/services (RESTful APIs, SOA principles).Experience with SQL and NoSQL preferably MongoDB & DynamoDB.Experience with Test Driven Development/Unit Testing.Experience with any cloud service provider.Excellent communication skills and the ability to work effectively with others in a remote environment.Experience working in an Agile Team is a plus.Will be added advantage if you have:Experience with Elastic Search.Experience with Kafka.Experience with gRPC.Experience with ELK stack.Experience with CI/CD pipeline (e.g. Buildkite) and Kubernetes.Familiarity with one or more of the following might help, but even if you do not, do apply if you think you’re right for the job!Why join us:100% remote work and flexible hours.Inclusive, diverse, and supportive team culture.Opportunities for professional growth and learning.Competitive compensation and benefits.Interview Rounds:Round 1: HR screening call (15 mins)Round 2: Technical Video call (1 hour)Round 3: Technical Video call (1 hour)Round 4: Managerial Video call (1 hour)Round 5: HR Round (45 mins)",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "Technology, Information and Internet"
    },
      "skills": [
        "Golang",
        "Ruby",
        "AWS",
        "SQL",
        "MongoDB",
        "DynamoDB",
        "NoSQL",
        "RESTful APIs",
        "SOA",
        "Test Driven Development",
        "Unit Testing",
        "Elastic Search",
        "Kafka",
        "gRPC",
        "ELK Stack",
        "CI/CD",
        "Kubernetes"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_020"
  },
   {
    "job_id": "healthcare-data-analyst-at-infosys-4320258622",
    "title": "Healthcare Data Analyst",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "posted_date": "2025-11-24",
    "job_url": "https://in.linkedin.com/jobs/view/healthcare-data-analyst-at-infosys-4320258622?position=9&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=cnkSd4c690ANfUGwDtM4Fg%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424078",
    "description": "Healthcare Data analyst ,PL/SQL, SQL, Data mapping, STTM creation, Data profiling, ReportsA day in the life of an Infoscion As part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction. You will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain. You will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews. You will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes. You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "SQL"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_023"
  },
   {
    "job_id": "data-analyst-1-at-jar-4339350249",
    "title": "Data Analyst - 1",
    "company": "Jar",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-26",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-1-at-jar-4339350249?position=7&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=gnQRaJ7t1hEFlM3d8pcsHw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424074",
    "description": "About UsJar is India’s leading Daily Saving app that helps people build strong saving habits—one small step at a time. Our goal is to make saving simple, rewarding, and truly life-changing. Founded in 2021 by Misbah Ashraf and Nishchay AG, Jar is a Bengaluru-based startup with one simple belief: saving a little every day in 24K Digital Gold can truly transform your future.Today, 20 million+ Indians trust Jar as their saving partner. With flexible saving options—Daily, Weekly, Monthly, and Instant Saving—we have made it easy for everyone to save in their own way and withdraw anytime. We are one of the leaders in UPI autopay transactions, crossing more than 1 million transactions per day. In 2023, we expanded our vision with Nek, our jewelry brand crafted to bring together luxury and affordability, it has since surpassed ₹100 crore in revenue.We have a big dream of bringing “Har Ghar Sona”. Small, consistent savings are just the start. We’re here to walk alongside our users, helping Indians secure their financial future every step of the way.Backed by Tiger Global Management, Arkam Ventures, and WEH Ventures, among others, we have raised $50 million+ in funding. In January 2025, we hit a huge milestone of becoming profitable. Now, we’re charging ahead, focused on sustainable growth and scaling impact.And this is just the beginning!What’s the role?As a Data Analyst - 1, you will be responsible for analyzing data to generate insights, building dashboards, and supporting decision-making across acquisition, retention and product performance. You will work closely with senior analysts, product managers, and business stakeholders to ensure accurate tracking, reporting, and data-driven recommendations.What will be your responsibilities?Perform data analysis and reporting on customer acquisition, retention, churn, and transactionsBuild, maintain, and automate dashboards and reports for business stakeholdersConduct deep dives into structured and unstructured data to identify trends, anomalies, and actionable insightsSupport Root Cause Analysis (RCA) for business metric changes and provide recommendationsPartner with product and business teams to define, track, and measure key performance indicators (KPIs)Assist in A/B experiments, feature evaluations, and campaign analysisEnsure data accuracy, consistency, and completeness across reporting pipelinesCollaborate with engineers and analysts to improve data quality and infrastructureWhat’s required from you?Bachelor’s degree in Engineering, Statistics, Mathematics, Economics, Computer Science, or related field1–3 years of experience in a data analytics role, preferably in fintech, e-commerce, or consumer techStrong proficiency in Python & MongoDb for data analysis, including Pandas, NumPy, Scikit-learn, Matplotlib/Seaborn, Dask, Statsmodels, Re(regular expressions for text cleaning), textblob (sentiment analysis & text processing) & Automations. Object oriented programming is a plusSQL: Expertise in writing complex sql (postgres) queries for data extraction, transformation, and reportingProcess, clean, and wrangle large datasets using Python to ensure data quality and readiness for analysisStrong understanding of Excel/Google Sheets for quick ad-hoc analysisExperience working with large, structured/unstructured datasetsVisualization Tools: Data Exploration and Visualisation with tools like Amplitude, Clevertap, MS Excel, Tableau, Power BI, etcFamiliarity with A/B testing frameworks and statistical conceptsStrong analytical thinking, problem-solving skills, and attention to detailGood communication skills to explain insights to non-technical stakeholdersWhat makes us different? We’re not just building a product—we’re shaping the future of savings in India. We seek people who bring passion, energy, and fresh ideas to help us make that happen. Experience matters, but we are a potential first organisation. We move fast, learn from our mistakes, and take bold risks to solve problems that haven’t been attempted before. If you’re excited about working in an environment where people inspire and truly support each other, you’ve found the right fit.What do we stand for? The five values that we live by :Passion: At Jar, we strive to create an environment where people love what they do, are motivated and equipped to do their best work.Equality: We bring diverse skills, ideas, and experiences to the table, supporting and challenging each other across teams to create something bigger than ourselves.Growth: When our people grow, Jar grows. We create opportunities for learning, development, and meaningful impact.Accountability: The core of our work ethic is taking ownership of our work, showing initiative, and having the freedom to ask questions.Consistency: We believe in doing the right things consistently. Big change doesn’t happen overnight, it’s built one step at a time.Join us and let’s build something amazing together!What employee benefits do we have?Glad you asked! Among other things, we haveMedical Insurance for employees and their familiesESOPs allocationPluxee meal cardSwish club card for exclusive employee discounts Advance salary plansRelocation assistanceL&D programmesPowered by JazzHRyFnGcnOHMq",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Internet Publishing"
    },
    "skills": [
      "Python",
      "SQL",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "Data Analysis",
      "Statistics",
      "A/B Testing",
      "Matplotlib",
      "Seaborn",
      "MongoDB",
      "Data Quality",
      "Tableau",
      "Power BI",
      "Excel"
    
     
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_021"
  },
   {
    "job_id": "data-analyst-at-wipro-4337253357",
    "title": "Data Analyst",
    "company": "Wipro",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-20",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-wipro-4337253357?position=11&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=7OtzwHtds%2FwjUq0DfWN7Zw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424080",
    "description": "Job description:Job Description Role PurposeThe purpose of this role is to interpret data and turn into information (reports, dashboards, interactive visualizations etc) which can offer ways to improve a business, thus affecting business decisions.͏ Do1. Managing the technical scope of the project in line with the requirements at all stagesa. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trendsb. Develop record management process and policiesc. Build and maintain relationships at all levels within the client base and understand their requirements.d. Providing sales data, proposals, data insights and account reviews to the client basee. Identify areas to increase efficiency and automation of processesf. Set up and maintain automated data processesg. Identify, evaluate and implement external services and tools to support data validation and cleansing.h. Produce and track key performance indicators 2. Analyze the data sets and provide adequate informationa. Liaise with internal and external clients to fully understand data contentb. Design and carry out surveys and analyze survey data as per the customer requirementc. Analyze and interpret complex data sets relating to customer’s business and prepare reports for internal and external audiences using business analytics reporting toolsd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarkinge. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting toolf. Develop predictive models and share insights with the clients as per their requirement͏ Deliver NoPerformance ParameterMeasure1.Analyses data sets and provide relevant information to the clientNo. Of automation done, On-Time Delivery, CSAT score, Zero customer escalation, data accuracy ͏ ͏",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Data Integration",
      "Reporting",
      "Analytics"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_024"
  },
  {
    "job_id": "software-engineer-%E2%80%93-backend-at-levein-group-4324476715",
    "title": "Software Engineer – Backend",
    "company": "Levein Group",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-25",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-%E2%80%93-backend-at-levein-group-4324476715?position=41&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=kxvver653k518QNN8pW1Ig%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424211",
    "description": "Summary of The RoleWe are seeking a skilled and motivated Backend Engineer to join our cloud team. The role focuses on ensuring that data flows seamlessly from sensors to machine learning services and applications with reliability and low latency. The ideal candidate will have a strong understanding of cloud-native systems, Infrastructure as Code, and backend development, with a passion for scalability, performance, and automation.Role ResponsibilitiesDesign, develop, and maintain backend services that power our data and ML-driven applications.Manage and optimize cloud infrastructure for scalability, security, and reliability using Terraform.Contribute to services built mainly in Go and Clojure, with occasional development in TypeScript and Python.Implement and maintain CI/CD pipelines and automated deployment processes.Participate in code reviews, architecture discussions, and operational best practices.Monitor system performance, troubleshoot issues, and ensure continuous improvement of reliability and resilience.Collaborate with cross-functional teams to integrate data pipelines, APIs, and IoT infrastructure components. Responsibilities Essential Skills, Knowledge & ExperienceTechnical ExpertiseProven experience writing Infrastructure as Code (IaC) using Terraform.Strong experience with AWS services, particularly Lambda, ECS, SNS, SQS, and Kinesis.Proficiency in at least one modern statically typed language (e.g. Go, Java, C#).Experience working with Docker and containerized environments.Familiarity with event-driven systems and distributed architectures.Development & OperationsSolid understanding of CI/CD and deployment automation.Experience with relational and document-based databases such as PostgreSQL and DynamoDB.Exposure to observability tools (e.g. Prometheus, Grafana) for monitoring and alerting.Ability to troubleshoot complex system issues and optimize performance.Problem-Solving and LearningStrong analytical and problem-solving skills in cloud-native environments.Willingness to learn new languages, frameworks, and tools as required.Experience with legacy system modernization or migration is an advantage.Nice to HaveFamiliarity with IoT systems and MQTT-based data pipelines.Experience in designing or maintaining public APIs. Personal Attributes Detail-oriented with a structured, analytical approach to problem-solving.Demonstrates ownership, accountability, and a strong sense of responsibility.Self-motivated and capable of working both independently and collaboratively.Open-minded and adaptable to learning emerging technologies.Clear communicator with the ability to explain technical concepts effectively.Benefits Work Environment General Work Hours: 1.30PM – 10.30PM (WFH) Sri Lanka Time – 45hrs/week.Location: Remote WFH + Occasional Meets at our Colombo 5 office – Sri Lanka.Benefits: Paid leave, career upskilling opportunities, eLearning courses.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Outsourcing and Offshoring Consulting"
    },
      "skills": [
        "Go",
        "Clojure",
        "TypeScript",
        "Python",
        "Terraform",
        "AWS",
        "Lambda",
        "ECS",
        "SNS",
        "SQS",
        "Kinesis",
        "Docker",
        "CI/CD",
        "PostgreSQL",
        "DynamoDB",
        "Prometheus",
        "Grafana",
        "MQTT"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_022"
  },
  {
    "job_id": "software-engineer-at-2xdev-4322952805",
    "title": "Software Engineer",
    "company": "2xDev",
    "location": "Sri Lanka",
    "posted_date": "2025-11-16",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-at-2xdev-4322952805?position=49&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=u4VrzPl0NDxBsAOATGiIkw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424212",
    "description": "We’re Hiring: Software Engineer (5+ Years Experience)Join us at 2xDev, where we build fast, ship bold, and push the boundaries of modern web engineering. If you love solving real problems with clean, scalable code you’ll fit right in.Must-have experience with:Next.jsReactTypeScriptNode.jsPostgreSQLSupabaseBonus points for:NoSQL databasesReact NativeWebSocket implementation experienceBring your curiosity, your craft, and your ability to turn ideas into beautifully engineered products.Ready for the Challenge?Show us what you’ve got: 👉 https://2xdev.com/challenge-01/Once you complete it, make your repository public and email the link to hi@2xdev.com.Why you'll love working with us? Flexible working hoursFully remote after your first 3 monthsCompetitive compensation paid in USDAt 2xDev, you’ll collaborate with a team that values high-quality engineering, rapid iteration, and a culture built on trust and creativity. If modern web technology excites you and you enjoy taking ownership, the adventure starts now!",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
      "skills": [
        "Next.js",
        "React",
        "TypeScript",
        "Node.js",
        "PostgreSQL",
        "Supabase",
        "NoSQL",
        "React Native",
        "WebSocket"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_024"
  },
  {
    "job_id": "associate-software-engineer-at-riskonnect-inc-4334444073",
    "title": "Associate Software Engineer",
    "company": "Riskonnect, Inc.",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-06",
    "job_url": "https://lk.linkedin.com/jobs/view/associate-software-engineer-at-riskonnect-inc-4334444073?position=53&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=qAhD1GVx81mN9hvXUi25Hw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424214",
    "description": "ResponsibilitiesParticipate in requirements analysis.Collaborate with internal teams to produce software design and architecture.Write clean, scalable code using C#/Typescript programming languages.Test and deploy application and systems.Revise, update, refactor and debug code.Improve existing software.Develop documentation throughout the software development life cycle (SDLC).Assist in integrating AI/ML services (e.g., OpenAI, Azure Cognitive Services) into applications.Support the development of AI-driven features by preparing data, testing APIs, and validating outputs.Collaborate with senior engineers and architects to explore the use of AI in enhancing user experience and business workflows.Stay updated with emerging AI tools and frameworks relevant to the product roadmap.RequirementsDegree from a recognized university, preferably in Computer Science, Engineering, or IT.1+ year of experience in .NET Core and Angular development.Proficiency in C#, ASP.NET Core, and Entity Framework Core.Strong front-end skills in Angular 16+, TypeScript, HTML5, CSS3, and JSON.Experience working with RESTful APIs and integrating front-end applications with back-end services.Sound knowledge of software design patterns and OOP concepts.Experience with MS SQL Server technologies.Familiarity with Git and version control workflows.Experience with third-party libraries and APIs.Familiarity with Agile methodologies (e.g., SCRUM).Strong problem-solving, analytical, and troubleshooting skills.Excellent communication and teamwork abilities.Knowledge of Microservices architectureExperience in ASP.NET Web APIs.Experience in CSS/SCSS.Experience in ASP.NET Web Pages and JavaScript.Experience configuring CI/CD pipelines.Experience with Azure or other cloud platforms.Exposure to AI/ML concepts such as natural language processing (NLP), embeddings, or predictive modelling.Familiarity with integrating AI services (e.g., Azure Cognitive Services, OpenAI API, or similar) into web applications.Understanding of how to design prompts, handle AI responses, and apply them in business workflows.Basic knowledge of data processing for AI (JSON, vector databases, text preprocessing).Interest in learning and applying AI/ML technologies to enhance product features.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
      "skills": [
        "C#",
        "TypeScript",
        "ASP.NET Core",
        "Entity Framework Core",
        "Angular",
        "HTML5",
        "CSS3",
        "JSON",
        "RESTful APIs",
        "MS SQL Server"
        ],
     
      "role_tag": "DA",
      "role_key": "data_analyst",
      "job_role_id": "DA_20251127_023"
    },
  {
    "job_id": "python-software-engineer-at-virtusa-4324324008",
    "title": "Python Software Engineer",
    "company": "Virtusa",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-25",
    "job_url": "https://lk.linkedin.com/jobs/view/python-software-engineer-at-virtusa-4324324008?position=58&pageNum=0&refId=MpfaacS8txk5yil2gBl1MQ%3D%3D&trackingId=0tYo2alIIMhJoj5tFMh8dw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424216",
    "description": "Lead Software Engineer Key responsibilities & Accountabilities:Lead and oversee a team of engineers to ensure successful project delivery, from inception to deployment.Define technical requirements and ensure alignment with business objectives.Contribute to architectural decisions and technical designs.Coordinate with product owners and stakeholders to prioritize tasks and allocate resources.Provide technical guidance and mentorship to team members.Facilitate communication and collaboration within the team.Ensure adherence to coding standards, best practices performing code reviews and providing constructive feedback to peers.Identify and address technical debt and architectural weaknesses.Evaluate and mitigate technical risks associated with projects, ensuring smooth progress and timely delivery.Champion quality-focused software development, enforcing quality assurance standards, processes, testing methodologies, and driving initiatives to improve the development team efficiency (like automation, CI/CD).You are able to grasp, articulate, and advocate for technological solutions in both technical and non-technical settings and intelligently apply agile principles as you do so.You are able to interrogate and present data and data analysis and have a willingness to present results of analysis undertaken as a part of your team's work.You have demonstrable experience as a technical lead developer or engineer with a focus on Python.You love SQL (Postgres, SQL Server, Databricks)You are comfortable working without an ORM.You are familiar with the challenges of working with data *at scale*.You prefer the command line use of git, bash/zsh, and (optionally) vim.An undergraduate degree or demonstrable knowledge and experience of concepts in Computer Science, Software Engineering, Logic, Applied Statistics, Actuarial Science, Data Science, or any related discipline would be advantageous.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Python",
        "SQL",
        "PostgreSQL",
        "SQL Server",
        "Databricks",
        "Bash",
        "Git",
        "CI/CD"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_029"
  },
  {
    "job_id": "software-engineer-fullstack-early-career-at-notion-4334367155",
    "title": "Software Engineer, Fullstack, Early Career",
    "company": "Notion",
    "location": "New York, NY",
    "posted_date": "2025-11-27",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-fullstack-early-career-at-notion-4334367155?position=1&pageNum=0&refId=03HiXmBHiyax5ywXnEZyZw%3D%3D&trackingId=g6uZ6PEeDnq3zkU0jPdU%2BA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424217",
    "description": "About UsNotion helps you build beautiful tools for your life’s work. In today's world of endless apps and tabs, Notion provides one place for teams to get everything done, seamlessly connecting docs, notes, projects, calendar, and email—with AI built in to find answers and automate work. Millions of users, from individuals to large organizations like Toyota, Figma, and OpenAI, love Notion for its flexibility and choose it because it helps them save time and money.In-person collaboration is essential to Notion's culture. We require all team members to work from our offices on Mondays and Thursdays, our designated Anchor Days. Certain teams or positions may require additional in-office workdays.About The RoleAs an Early Career Software Engineer at Notion, you’ll help shape core user experiences and accelerate how people discover value in Notion. You'll tackle meaningful challenges with increasing autonomy, crafting code that millions of users will experience. You'll take ownership of projects that matter, make critical technical decisions, and contribute your unique perspective to our product vision. Working alongside passionate experts across design, product, and data, you'll help shape the future of how people work.We’re hiring early career engineers to join us across several teams at Notion. Your recruiter will partner with you to find the team that best aligns with your interests and where you can make the highest impact.What You’ll AchievePlan, build, and ship product features from conception to launch, then iterate based on insights and user feedback.Improve performance, reliability, and quality of key experiences used by millions of users and thousands of organizations.Run experiments that drive activation, retention, collaboration, and revenue, partnering with design, data science, and research.Build internal tools and platform improvements that help all engineers ship quickly and safely.Contribute to team norms, code quality, and a culture of learning and thoughtful tradeoffs.Areas you might work onCore Notion product features: Help develop, improve, and maintain features for our flagship product, focusing on the editor, databases, sharing, or other key areas that power millions of workflows.AI and automation: Help develop and integrate intelligent features that make Notion more powerful, contextual, and efficient for our users.Growth and activation: Work on features that help new users discover Notion's value, improve onboarding experiences, and increase user engagement.Platform and infrastructure: Contribute to the systems that power Notion's backend services, ensuring reliability, scalability, and performance as our user base grows.Skills You’ll BringProven track record of execution: You have a minimum of 1 year (and up to 3 years) of full-time professional engineering experience, including building world-class product experiences as part of an engineering team. You have solid fundamentals in data structures, algorithms, and distributed systems, with a product-minded, pragmatic approach to solving problems.Thoughtful problem-solving: You approach problems holistically, starting with a clear and accurate understanding of the context. You think about the implications of what you're building and how it will impact real people's lives. You can navigate ambiguity successfully, decompose complex problems into clean solutions, while also balancing the business impact of what you’re building.Impact-driven approach to technology: You see technologies as tools to achieve user impact rather than ends in themselves. You care more about building successful systems that solve real problems than about using specific tech stacks or following trends. You stay current with the latest tools like Cursor, Claude Code, and other AI-assisted development environments, you're pragmatic about choosing the right tool for the job, focusing on what delivers the most value to users and the business.Proactive communication and high agency: You own your work, communicating clearly about progress and blockers. You don't wait for instructions for every step but rather show initiative in identifying what needs to be done and driving projects forward. You ask questions when needed while independently finding solutions to problems.Nice to HaveExperience with parts of our stack like React, TypeScript, Node.js, Postgres, or with experimentation and analytics tooling.Exposure to distributed systems, observability, CI/CD, or infrastructure fundamentals.An interest in product quality and craft, and in helping others stay in flow.You've heard of computing pioneers like Ada Lovelace, Douglas Engelbart, Alan Kay, and others—and understand why we're big fans of their work.We hire talented and passionate people from a variety of backgrounds because we want our global employee base to represent the wide diversity of our customers. If you’re excited about a role but your past experience doesn’t align perfectly with every bullet point listed in the job description, we still encourage you to apply. If you’re a builder at heart, share our company values, and enthusiastic about making software toolmaking ubiquitous, we want to hear from you.Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please let your recruiter know.Notion is committed to providing highly competitive cash compensation, equity, and benefits. The compensation offered for this role will be based on multiple factors such as location, the role’s scope and complexity, and the candidate’s experience and expertise, and may vary from the range provided below. For roles based in San Francisco or New York City, the estimated base salary range for this role is $126,000 - $180,000 per year.By clicking “Submit Application”, I understand and agree that Notion and its affiliates and subsidiaries will collect and process my information in accordance with Notion’s Global Recruiting Privacy Policy and NYLL 144.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
      "skills": [
        "React",
        "TypeScript",
        "Node.js",
        "PostgreSQL",
        "CI/CD"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_031"
  },
  {
    "job_id": "software-engineer-new-grad-web-at-clear-4339211205",
    "title": "Software Engineer, New Grad, Web",
    "company": "CLEAR",
    "location": "New York, NY",
    "posted_date": "2025-11-26",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-new-grad-web-at-clear-4339211205?position=7&pageNum=0&refId=03HiXmBHiyax5ywXnEZyZw%3D%3D&trackingId=hTOwB5jZpJZXGhF7R1cm4g%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424225",
    "description": "Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 30+ million passionate members and hundreds of partners around the world, CLEAR’s identity platform is transforming the way people live, work, and travel. Whether it’s at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.Level and specific team/role matching will happen at the end of our interview process.A brief highlight of our tech stack:Javascript / React / Typescript / NodeAWS cloud What you'll do:Advance our capabilities across a wide array of industries and domains, and gain hands-on experience with privacy, security, data modeling, and architecture Develop and deliver code, driving engineering excellence by defining best practices in testing, documentation, and observabilityPartner with product and other stakeholders to uncover requirements, to innovate, and to solve complex problemsHave a strong sense of ownership, be responsible for architectural decision-making, and strive for continuous improvement in technology and processes at CLEARWhat you're great at:0-2 years of front-end focused, software development experience in JavaScript and related technologies (React, TypeScript, Node)Working with cloud-based application development, and being fluent in at least a few of: Cloud service providers like AWSContainerization technologies like Docker and KubernetesCollaboration, integration, and deployment tools like GitHub, Argo, and Jenkins Articulating technical concepts to a mixed audience of technical and non-technical stakeholdersCollaborating and mentoring less experienced members of the teamComfort with ambiguityCuriosity about technology, belief in constant learning, and the ability to be autonomous to figure out what's importantHow You’ll be Rewarded:At CLEAR we help YOU move forward - because when you’re at your best, we’re at our best. You’ll work with talented team members who are motivated by our mission of making experiences safer and easier. In our offices, you’ll enjoy benefits like meals and snacks. We invest in your well-being and learning & development with our stipend and reimbursement programs. We offer holistic total rewards, including comprehensive healthcare plans, family building benefits (fertility and adoption/surrogacy support), flexible time off, free OneMedical memberships for you and your dependents, and a 401(k) retirement plan with employer match. The base salary range for this role is $115,000-130,000 depending on levels of skills and experience.The base salary range represents the low and high end of CLEAR’s salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR’s total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock UnitsCLEAR provides reasonable accommodation to qualified individuals with disabilities or protected needs. Please let us know if you require a reasonable accommodation to apply for a job or perform your job. Examples of reasonable accommodation include, but are not limited to, time off, extra breaks, making a change to the application process or work procedures, policy exceptions, providing documents in an alternative format, live captioning or using a sign language interpreter, or using specialized equipment.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Consumer Services"
    },
      "skills": [
        "JavaScript",
        "React",
        "TypeScript",
        "Node.js",
        "AWS",
        "Docker",
        "Kubernetes",
        "GitHub",
        "Jenkins"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_037"
  },
  {
    "job_id": "software-engineer-new-grad-backend-at-clear-4339390809",
    "title": "Software Engineer, New Grad, Backend",
    "company": "CLEAR",
    "location": "New York, NY",
    "posted_date": "2025-11-26",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-new-grad-backend-at-clear-4339390809?position=11&pageNum=0&refId=03HiXmBHiyax5ywXnEZyZw%3D%3D&trackingId=jrvzLmeT0mRO7fjUasUHsA%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424226",
    "description": "Have you ever had that green-light feeling? When you hit every green light and the day just feels like magic. CLEAR's mission is to create frictionless experiences where every day has that feeling. With more than 30+ million passionate members and hundreds of partners around the world, CLEAR’s identity platform is transforming the way people live, work, and travel. Whether it’s at the airport, stadium, or right on your phone, CLEAR connects you to the things that make you, you - unlocking easier, more secure, and more seamless experiences - making them all feel like magic.Level and specific team/role matching will happen at the end of our interview process.A brief highlight of our tech stack:Python / Kafka / Postgres AWS cloud What you’ll do:Advance our capabilities across a wide array of industries and domains and gain hands-on experience with privacy, security, data modeling and architecture Develop and deliver code, driving engineering excellence by defining best practices in testing, documentation and observabilityPartner with product and other stakeholders to uncover requirements, to innovate, and to solve complex problemsHave a strong sense of ownership, responsible for architectural decision-making and strive for continuous improvement in technology and processes at CLEARWhat you’re great at:0-3 years of back-end focused, professional software development experience in PythonWorking with cloud-based application development, and be fluent in at least a few of: Cloud service providers like AWSContainerization technologies like Docker and KubernetesCollaboration, integration, and deployment tools like GitHub and ArgoArticulating technical concepts to a mixed audience of technical and non-technical stakeholdersCollaborating heavily with members of the teamComfort with ambiguity Curiosity about technology, belief in constant learning, and ability to be autonomous to figure out what's importantHow You’ll be Rewarded:At CLEAR we help YOU move forward - because when you’re at your best, we’re at our best. You’ll work with talented team members who are motivated by our mission of making experiences safer and easier. In our offices, you’ll enjoy benefits like meals and snacks. We invest in your well-being and learning & development with our stipend and reimbursement programs. We offer holistic total rewards, including comprehensive healthcare plans, family building benefits (fertility and adoption/surrogacy support), flexible time off, free OneMedical memberships for you and your dependents, and a 401(k) retirement plan with employer match. The base salary range for this role is $115,000-130,000 depending on levels of skills and experience.The base salary range represents the low and high end of CLEAR’s salary range for this position. Salaries will vary depending on various factors which include, but are not limited to location, education, skills, experience and performance. The range listed is just one component of CLEAR’s total compensation package for employees and other rewards may include annual bonuses, commission, Restricted Stock UnitsCLEAR provides reasonable accommodation to qualified individuals with disabilities or protected needs. Please let us know if you require a reasonable accommodation to apply for a job or perform your job. Examples of reasonable accommodation include, but are not limited to, time off, extra breaks, making a change to the application process or work procedures, policy exceptions, providing documents in an alternative format, live captioning or using a sign language interpreter, or using specialized equipment.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Consumer Services"
    },
      "skills": [
        "Python",
        "Kafka",
        "PostgreSQL",
        "AWS",
        "Docker",
        "Kubernetes",
        "GitHub"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_040"
  },
  {
    "job_id": "software-engineer-at-microsoft-4341828947",
    "title": "Software Engineer",
    "company": "Microsoft",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-21",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4341828947?position=3&pageNum=0&refId=jQwPgWVfEQql%2B4WhRKomiw%3D%3D&trackingId=YQPY%2BeSnBPHvrRrGrVyN4Q%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424229",
    "description": "OverviewCome build community, explore your passions and do your best work at Microsoft. This opportunity will allow you to bring your aspirations, talent, potential and excitement for the journey ahead.As a Software Engineer, you will help plan, design, develop and test software systems or applications for software enhancements and new products which may be used in local, networked, cloud-based, or Internet-related computer programs. This opportunity will allow you to develop software, tools and code to be used in support of design, infrastructure and technology platforms as well as commercial or end-user applications. You will use current programming language and technologies to write code, perform testing and debug any issues with robust documentation, procedures for deployment and processes for maintenance.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesYou will contribute in partnership with appropriate stakeholder to determine user requirements for a feature and consider a variety of feedback channels to incorporate insights into future designs or solution fixes.You will learn and contribute to processes for the architecture of a product/solution feature and learns to create proposals by testing design hypotheses and helping to refine code plans under the technical leadership of others as well as help produce code to test hypotheses for technical solutions and assists with technical validation efforts.With guidance, you will learn to create and implement code that is extensible and maintainable and apply diagnosability, reliability and maintainabilit, and understand when the code is ready to be shared and delivered for a product, service, or feature reusing code as applicableYou will learn to review work items to gain knowledge of product features in partnership with appropriate stakeholders and assist and learn about breaking down work items into tasks and provides estimation as well as escalate any issues that would cause a delay.You will learn about and contribute to operations of live service as issues arise on a rotational, on-call basis and identify solutions and mitigations to simple issues impacting performance or functionality of Live Site services and escalates as necessary.You will help develop and contribute to automation within production and deployment of a product feature and run code in simulated or other non-production environments to confirm functionality and error-free runtime for products with oversight.You will embody our culture and values.QualificationsBachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonThis position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
      "skills": [
        "C",
        "C++",
        "C#",
        "Java",
        "JavaScript",
        "Python"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251127_041"
  },
  {
    "job_id": "ai-engineer-at-ifs-4285393282",
    "title": "AI Engineer",
    "company": "IFS",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-10",
    "job_url": "https://lk.linkedin.com/jobs/view/ai-engineer-at-ifs-4285393282?position=7&pageNum=0&refId=ljjfJbaT2EFFm5Uz7mEt%2FA%3D%3D&trackingId=09n7N%2BziZ649mkoCPFzm5g%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793209",
    "description": "IFS is a billion-dollar revenue company with 7000+ employees on all continents. Our leading AI technology is the backbone of our award-winning enterprise software solutions, enabling our customers to be their best when it really matters–at the Moment of Service™. Our commitment to internal AI adoption has allowed us to stay at the forefront of technological advancements, ensuring our colleagues can unlock their creativity and productivity, and our solutions are always cutting-edge.At IFS, we’re flexible, we’re innovative, and we’re focused not only on how we can engage with our customers but on how we can make a real change and have a worldwide impact. We help solve some of society’s greatest challenges, fostering a better future through our agility, collaboration, and trust.We celebrate diversity and understand our responsibility to reflect the diverse world we work in. We are committed to promoting an inclusive workforce that fully represents the many different cultures, backgrounds, and viewpoints of our customers, our partners, and our communities. As a truly international company serving people from around the globe, we realize that our success is tantamount to the respect we have for those different points of view.By joining our team, you will have the opportunity to be part of a global, diverse environment; you will be joining a winning team with a commitment to sustainability; and a company where we get things done so that you can make a positive impact on the world.We’re looking for innovative and original thinkers to work in an environment where you can #MakeYourMoment so that we can help others make theirs. With the power of our AI-driven solutions, we empower our team to change the status quo and make a real difference.If you want to change the status quo, we’ll help you make your moment. Join Team Purple. Join IFS.Job DescriptionThe AI Engineer works closely with stakeholders to translate business requirements into secure, scalable, and maintainable AI‑driven solutions. With deep expertise in software engineering and applied artificial intelligence, you will design, build, and operate applications, services, and automations that leverage Azure AI Services and other cutting‑edge technologies to maximize internal productivity at IFS. You will validate solution architectures with the IT Solution Architect (AI) throughout design and implementation cycles, ensuring alignment with IFS IT architecture standards, governance, and security best practices. Key Responsibilities Analyze business requirements and translate them into AI-driven technical specifications and solution designs. Design, develop, test, and deploy AI-enabled applications, APIs, and workflows using Azure AI Foundry, Azure OpenAI, Azure Cognitive Search, and related Azure AI Service capabilities. Configure, fine-tune, and optimize vector search, embeddings, and retrieval-augmented generation (RAG) pipelines, leveraging vector databases. Build and maintain secure RESTful endpoints that expose AI capabilities to internal products and services, adhering to web development security best practices. Implement MLOps practices for versioning, deployment, monitoring, and continuous improvement of models and prompts using Azure DevOps/GitHub Actions, Azure Pipelines. Leverage Azure Compute services (Azure App Service, Azure Functions) deploy and scale AI applications. Create and maintain data pipelines and data sources in Azure. Document designs, implementations, processes, and procedures; keep knowledge bases up to date. Monitor cloud costs and analyze service choices to ensure cost-efficient use of Azure resources. Provide advanced technical support and problem resolution for AI platforms and integrations, including proactive monitoring and incident response. Stay informed of IFS IT standards, security requirements, and architecture frameworks to ensure compliant and robust AI service delivery. Contribute to IT service delivery improvements by actively participating in agile ceremonies and assigned projects. Skills & Competencies Deep understanding of large-language models (LLMs), NLP concepts, embeddings, vector databases, and prompt engineering. Hands-on expertise with Azure AI Services (Azure OpenAI, Cognitive Search, Azure AI Foundry) and related SDKs. Strong software-engineering skills in languages such as Python, JavaScript/TypeScript (Node.js), or C#/.NET, with experience building production APIs and services. Familiarity with frameworks such as LangChain, Semantic Kernel, or Azure OpenAI SDK for orchestrating conversational and RAG workflows. Solid knowledge of cloud-native and service-oriented architectures, including security and authentication standards (OAuth 2.0, Managed Identities, token-based auth). Experience with Azure Compute, Azure Storage for cloud app development. Familiarity with modern web development frameworks and libraries (React, ExpessJS, FastAPI etc) to build lightweight web interfaces when needed. Strong data-engineering and analysis skills; proficiency with SQL (Azure SQL) and NoSQL (Cosmos DB) and experience with vector-capable databases. Experience with DevOps and MLOps pipelines (Azure DevOps, GitHub Actions, Azure Pipelines, Docker) for continuous integration, delivery, and monitoring. Proficiency in scripting and automation (PowerShell, Bash, Azure CLI) to enhance developer productivity. Knowledge of CI/CD best practices with Git, branching strategies, and release management. Experience building interactive dashboards or reports using tools like Power BI or similar platforms is a plus. Excellent verbal and written communication skills in English; able to convey complex AI concepts to technical and non-technical audiences. Analytical, problem-solving mindset, with the ability to work effectively in distributed and cross-functional teams. Energy, curiosity, and a passion for continuous learning in the rapidly evolving AI landscape. QualificationsEducation: Bachelor’s degree in Computer Science, Artificial Intelligence, Data Science, Information Technology, or a related field (or equivalent experience). Certifications (preferred): - Microsoft Certified: Azure AI Engineer Associate (AI‑102) - Microsoft Certified: Azure Developer Associate (AZ‑204) - ITIL Foundation certification Experiences : 3 - 5 years of professional software-engineering experience, with 2+ years focused on architecting and delivering AI/ML solutions on Azure Cloud. Proven track record integrating generative-AI capabilities (LLM APIs, RAG pipelines, vector search solutions) into enterprise applications and workflows. Hands-on experience with Azure AI services (Azure OpenAI, Cognitive Search, AI Foundry), vector databases and building data pipelines. Demonstrated ability to design and maintain secure, scalable APIs and microservices using Python, Node.js, or C#/.NET, following web security best practices. Experience applying MLOps/DevOps practices—including automated testing, CI/CD (Azure DevOps/GitHub Actions), containerization (Docker). Familiarity with front-end frameworks (React) for building lightweight user interfaces and integrating seamlessly with AI back-ends. Experience monitoring and optimizing Azure resource costs using Azure Cost Management and performance profiling tools. Evidence of strong technical leadership, mentoring, and collaboration in distributed, cross-functional teams. Additional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Python",
        "JavaScript",
        "TypeScript",
        "Node.js",
        "C#",
        "Azure AI Services",
        "Azure OpenAI",
        "Cognitive Search",
        "Azure AI Foundry",
        "Vector Databases",
        "RESTful APIs",
        "Azure DevOps",
        "GitHub Actions",
        "Azure Pipelines",
        "Azure App Service",
        "Azure Functions",
        "Azure Storage",
        "SQL",
        "Cosmos DB",
        "Docker",
        "PowerShell",
        "Bash",
        "React",
        "ExpessJS",
        "FastAPI",
        "Power BI",
        "OAuth",
        "MLOps",
        "DevOps",
        "Microservices",
        "Containerization"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_005"
  },
  {
    "job_id": "ai-research-engineer-agentic-ai-intelligent-automation-at-robotic-assistance-devices-4320474225",
    "title": "AI Research Engineer - Agentic AI & Intelligent Automation",
    "company": "Robotic Assistance Devices",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-03",
    "job_url": "https://lk.linkedin.com/jobs/view/ai-research-engineer-agentic-ai-intelligent-automation-at-robotic-assistance-devices-4320474225?position=8&pageNum=0&refId=ljjfJbaT2EFFm5Uz7mEt%2FA%3D%3D&trackingId=B4mQfg92pP31rXVeh44z3g%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793215",
    "description": "We are seeking a talented and driven AI Engineer to join our innovative team. This role is central to designing and developing agentic AI systems, RAG-based applications, and intelligent automation pipelines that enhance the intelligence and efficiency of our surveillance solutions.You will work on building multi-agent frameworks and integrating LLMs with structured knowledge bases. The ideal candidate combines strong deep learning expertise (PyTorch or TensorFlow) with hands-on experience in LangChain, LangGraph, or similar frameworks to create context-aware, autonomous AI systems ensuring reliability and scalability. You’ll also contribute to QA automation and RPA workflows to ensure smooth operations, focusing on automating repetitive human tasks using computer science technologies.This position offers the opportunity to work at the intersection of AI research, real-time analytics, and intelligent automation.Key ResponsibilitiesDesign Agentic AI Applications: Design and implement agentic AI applications Architect AI agent frameworks capable of autonomously analyzing visual and operational data, making decisions, and coordinating actions (like alerts or diagnostics) within the surveillance ecosystem.Design RAG Applications: Build Retrieval-Augmented Generation (RAG) systems that combine large language models with structured knowledge bases (logs, system data, documentation) to enable context-aware analytics, troubleshooting, and operational insights.Intelligent Robotic Process Automation (RPA) : Design AI based software tools to automate repetitive or rule-based digital tasks normally performed by humans to reduce manual workload and improve system efficiency. Develop and implement intelligent automation pipelines to streamline surveillance operations, such as video data handling and device monitoring by integrating RPA with AI models.QA Automation: Automate QA based applications and integrate AI into QA automation. Design and maintain automated testing frameworks for device software to ensure consistent performance, reliability, and accuracy across camera analytics, detection modules, and cloud-based services.Research on Cutting Edge Technologies: Continuously explore advancements in AI, computer vision, edge computing, and automation to identify innovative solutions that enhance the intelligence and adaptability of surveillance products. Deployment and Integration: Manage the end-to-end deployment, scaling, and integration of AI and automation modules across on-premise devices and cloud environments, ensuring smooth interoperability within the company’s surveillance infrastructure.Required QualificationsBachelor's or Master's degree in Computer Science, Electrical Engineering, Artificial Intelligence, or a related technical field.Strong programming skills in Python.Proven experience with modern deep learning frameworks such as PyTorch (preferred) or TensorFlow.Hands-on experience in working with Agentic AI systems, Multi-Agent workflows (LangGraph or other Agentic AI system design frameworks).Solid understanding of LLMs and experience in developing Retrieval-Augmented Generation (RAG) applications or LLM-based conversational systems (using Vector Databases and frameworks such as LangChain or similar RAG development tools).Prior contributions to research papers or projects.Preferable Skills And Experience(Preferred) Prior research contributions, such as technical papers, open-source projects, or academic collaborations.Familiarity with MLOps principles and tools (e.g., Docker, MLflow) for managing the machine learning lifecycle.Familiarity with Robotic Process Automation (RPA) tools (UiPath, Power Automate, PyAutoGUI).Familiarity with QA automation frameworks (e.g., Selenium, Playwright) is a plus.A portfolio of relevant projects, a GitHub profile showcasing your work, or contributions to open-source projects.Soft Skills:Strong problem-solving abilities and attention to detail.Excellent communication skills for documentation and collaboration.Ability to work effectively in a team-oriented environment.We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Public Safety"
    },
      "skills": [
        "Python",
        "PyTorch",
        "TensorFlow",
        "LangChain",
        "LangGraph",
        "Vector Databases",
        "RAG",
        "MLflow",
        "Docker",
        "UiPath",
        "Power Automate",
        "PyAutoGUI",
        "Selenium",
        "Playwright",
        "Edge Computing"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_006"
  },
  {
    "job_id": "ai-research-engineer-computer-vision-analytics-at-robotic-assistance-devices-4320434287",
    "title": "AI Research Engineer Computer Vision & Analytics",
    "company": "Robotic Assistance Devices",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-03",
    "job_url": "https://lk.linkedin.com/jobs/view/ai-research-engineer-computer-vision-analytics-at-robotic-assistance-devices-4320434287?position=10&pageNum=0&refId=ljjfJbaT2EFFm5Uz7mEt%2FA%3D%3D&trackingId=8l6UReD%2B8uhfKIU2P2UnPg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793219",
    "description": "We are seeking a talented and driven AI Engineer to join our innovative team. This role is central to our computer vision and analytics product development, focusing on the end-to-end lifecycle. The successful candidate will be responsible for training, fine-tuning, and rigorously optimizing custom models, like YOLO, to achieve superior accuracy and real-time performance on resource-constrained NVIDIA Jetson edge devices and cloud deployment.Key ResponsibilitiesModel Training and Development: Lead the complete training pipeline for computer vision based analytical models, including data preparation, augmentation, and implementing custom training and fine-tuning routines to meet specific project goals.Custom Model Adaptation: Develop and customize model architectures to accurately identify unique and specific needs required by our applications.Accuracy and Performance Enhancement: Continuously iterate on and experiment with models to systematically improve key metrics such as precision, recall, and mAP (mean Average Precision).Performance & Cost Optimization: Continuously analyze and optimize cloud resource consumption (e.g., CPU, GPU, memory, and storage) to ensure cost-effective, high-throughput operations and meet budget targets.Accelerator Implementation: Identify, benchmark, and leverage the most appropriate cloud hardware and software accelerators (e.g., specific GPU/TPU instances, inference compilers like NVIDIA TensorRT, AWS Inferentia) to enhance processing speed and reduce latency.Deployment and Integration: Work closely with software and hardware engineering teams to ensure the seamless integration and deployment of optimized models into our final products.Performance Benchmarking: Establish and execute robust testing protocols to measure and report on key performance indicators (KPIs), including inference latency, throughput, accuracy, and cost-per-inference/cost-per-query.Algorithm Development: Develop analytical algorithms for a variety of use cases, with an emphasis on deep mathematical and theoretical principles.Required QualificationsBachelor's or Master's degree in Computer Science, Electrical Engineering, Artificial Intelligence, or a related technical field.Strong programming skills in Python.Proven experience with modern deep learning frameworks such as PyTorch (preferred) or TensorFlow.Solid foundation in computer vision principles and deep learning concepts.Hands-on experience with training and fine-tuning machine learning models.Prior contributions to research papers or projects.Preferable Skills And Experience - Machine LearningDirect, hands-on experience with the NVIDIA Jetson family of devices (e.g., Orin, Xavier, Nano) and its development environment.Demonstrated expertise in model optimization and acceleration using NVIDIA TensorRT.In-depth knowledge of the YOLO architecture (e.g., YOLOv5, YOLOv8, YOLO-NAS) and experience in custom training it.Proven experience with model pruning tools and techniques.Familiarity with MLOps principles and tools (e.g., Docker, MLflow) for managing the machine learning lifecycle.Experience with video pipeline tools like GStreamer or NVIDIA DeepStream.A portfolio of relevant projects, a GitHub profile showcasing your work, or contributions to open-source projects.Preferable Skills And Experience - MathematicalStrong foundation in calculus, including:Differentiation (e.g., gradients, Jacobians, Hessians) for optimization in machine learning.Integration (e.g., continuous probability distributions, loss functions).Linear algebra (e.g., matrix operations, eigenvalues, singular value decomposition).Probability and statistics (e.g., Bayesian inference, statistical modeling).Optimization techniques (e.g., gradient descent, convex optimization).Soft SkillsStrong problem-solving abilities and attention to detail.Excellent communication skills for documentation and collaboration.Ability to work effectively in a team-oriented environment.What We OfferExceptional Peer Environment: The opportunity to work directly with and learn from experts in the field of AI.Impactful Work: Contribute to fundamental research and have a lasting impact on the industry.State-of-the-Art Resources: Access to datasets and extensive computational resources to bring your most ambitious ideas to life.Culture of Growth: A dynamic and intellectually stimulating environment that encourages continuous learning and professional development.We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Public Safety"
    },
      "skills": [
        "Python",
        "PyTorch",
        "TensorFlow",
        "YOLO",
        "NVIDIA Jetson",
        "TensorRT",
        "Docker",
        "MLflow",
        "GStreamer",
        "NVIDIA DeepStream",
        "AWS Inferentia",
        "Computer Vision",
        "Model Pruning",
        "Cloud Deployment"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_007"
  },
  {
    "job_id": "ai-ml-engineer-at-rsc-solutions-4323135079",
    "title": "AI/ML Engineer",
    "company": "RSC Solutions",
    "location": "New York, NY",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/ai-ml-engineer-at-rsc-solutions-4323135079?position=8&pageNum=0&refId=GNe%2FvuGPQ%2Bo4owXpzQ052A%3D%3D&trackingId=w3lfQSfLBFrH6snWdozA%2BA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793229",
    "description": "Long Term ContractRemoteWe are seeking a highly experienced and technically proficient Applied AI/ML Engineer with a strong background in capital markets surveillance to enhance and tune Behavox AI models. This role requires deep domain knowledge, hands-on experience with advanced AI/ML techniques, and the ability to work with large, complex datasets to improve model accuracy, reduce false positives, and ensure regulatory compliance.Key responsibilities• Model Enhancement and Tuning: Work directly on Behavox's proprietary LLM 2.0 and other AI risk policies to refine and improve their performance.• Performance Optimization: Use advanced statistical analysis and machine learning techniques to further reduce alert volumes while dramatically increasing the true positive detection rate for market abuse and misconduct cases.• Data Analysis: Work with terabytes of communications, voice, and transaction data to uncover patterns and train new features for risk detection.• Regulatory Compliance and Auditability: Ensure all model enhancements align with regulatory requirements (e.g., Client, SEC) and maintain the high level of explainability and transparency required by regulatory bodies and client governance teams.• Model Validation and Governance: Partner with internal teams to conduct rigorous model risk and governance testing, including using the Scenario Testing Lab to validate and refine new policy configurations.• Collaboration: Work closely with the Product Management, Data Science, and Engineering teams to translate market needs and emerging threats into robust, scalable AI solutions.• Technical Leadership: Serve as a subject matter expert on AI model behavior and tuning, providing guidance and mentorship to other engineers and data scientists.Required skills and qualificationsExperience:5+ years of hands-on experience as an Applied AI/ML Engineer or Data Scientist, with a focus on model tuning and enhancement in a production environment.• Domain Expertise: Strong, demonstrable knowledge of capital markets, financial trading activities, and compliance surveillance regulations (e.g., market abuse, insider trading, information barriers).Technical Skills:o Proficiency in machine learning frameworks such as PyTorch or TensorFlow, with deep experience in training, tuning, and deploying complex models.o Expertise in Natural Language Processing (NLP) and Large Language Models (LLMs). Experience with transformer architectures and fine-tuning models on domain-specific data is a must.o Experience with big data technologies (e.g., Spark, Kafka) and cloud platforms (GCP, AWS).o Strong programming skills in Python and SQL.• Analytical Abilities: Exceptional problem-solving skills, with a proven ability to perform root cause analysis on model performance and translate findings into actionable improvements.• Communication: Excellent communication skills, capable of explaining complex technical concepts to non-technical stakeholders, including compliance officers and executives.• Education: Bachelor's or Master's degree in Computer Science, Data Science, Quantitative Finance, or a related technical field.Preferred qualifications• Experience in the RegTech or FinTech space.• Experience with GPU-accelerated model training and inference.• A track record of contributing to or leading AI/ML projects that have demonstrably impacted a business's bottom line or operational efficiency.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Contract",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting, Software Development, and Financial Services"
    },
      "skills": [
        "Python",
        "SQL",
        "PyTorch",
        "TensorFlow",
        "NLP",
        "Transformer",
        "Spark",
        "Kafka",
        "GCP",
        "AWS",
        "LLM",
        "Big Data"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_011"
  },
  {
    "job_id": "machine-learning-engineer-at-aaa-global-4336568645",
    "title": "Machine Learning Engineer",
    "company": "AAA Global",
    "location": "New York City Metropolitan Area",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-at-aaa-global-4336568645?position=15&pageNum=0&refId=N3Frt4WR6JkKtQyP3Dkrnw%3D%3D&trackingId=7snk4egucknLTg1jZDCIOg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793242",
    "description": "Machine Learning Engineer – Elite Systematic Trading Team (NYC) 🚀A world-class, technology-driven trading team in New York City is looking for a Machine Learning Engineer to help build the next generation of AI-powered research and production systems. This is a rare opportunity to work at the intersection of cutting-edge deep learning and high-performance trading, collaborating directly with top researchers, PMs, and technologists.If you’re passionate about pushing the limits of AI in real-world, high-stakes environments — this team wants to hear from you.💼 What You’ll DoBuild AI-driven agents to support production, monitor trading systems, and automate operational workflows.Collaborate with AI researchers on projects like synthetic data generation, representation learning, and intelligent research workflow agents.Research, design, and implement advanced deep learning models for sequential modeling, time-series forecasting, and representation learning.Translate complex mathematical ideas into performant, production-ready code.Work in a high-impact, data-driven environment with immense ownership and visibility.🔍 We’re Looking ForPhD or PhD-track candidate in ML, Computer Science, or a related AI field.Deep experience in sequential modeling, time-series forecasting, and neural networks.Proficiency in Python (and ideally R) with strong experience in PyTorch or TensorFlow.Background in research environments, algorithmic modeling, or applied ML.Experience with LLMs, agent frameworks, context engineering, or NLP is a strong plus.Strong analytical skills, independent research ability, and high attention to detail.Clear communication and a commitment to excellence.🌎 Location📍 New York City – Onsite / Hybrid depending on candidate🔥 Why This Role is ExceptionalYou will be joining an elite technology team inside a highly successful systematic trading organization — working directly with leaders who are shaping the future of AI-driven trading. The impact is immediate, the projects are cutting-edge, and the growth potential is massive.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Research",
      "Industries": "Financial Services and Investment Management"
    },
      "skills": [
        "Python",
        "R",
        "PyTorch",
        "TensorFlow",
        "Machine Learning",
        "Deep Learning",
        "NLP",
        "Neural Networks",
        "Sequential Modeling",
        "Time-Series Forecasting",
        "LLM"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_022"
  },
  {
    "job_id": "avp-vp-ai-ml-engineer-at-caspian-one-4341138446",
    "title": "AVP/VP - AI/ML Engineer",
    "company": "Caspian One",
    "location": "New York, United States",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/avp-vp-ai-ml-engineer-at-caspian-one-4341138446?position=18&pageNum=0&refId=xi4Tj7oHHsJ%2BbP%2Bu5O9JEg%3D%3D&trackingId=dW6tGKXM1NE3pv2wnLI2ow%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793252",
    "description": "AVP/VP - AI Engineer - Hybrid - New York Join a mission-critical team within the firm’s cutting-edge platform engineering function, supporting platform for front-office developers.This is a unique opportunity for technically strong hands-on engineering SME to join a cutting-edge platform engineering function, which provides cloud and on-prem infrastructure to front-office developers (quantitative and strat teams). You’ll be at the forefront of cloud-native engineering, working with modern technologies across AWS, On-premise Kubernetes, Python, and data pipelines. If you are passionate about solving hard technical problems, staying current with trends like AI Engineering, and want to make a difference in a globally respected financial institution, this role is for you.Key ResponsibilitiesArchitect and develop platform services.Collaborate with internal infra/platform teams to align capabilitiesDesign and implement cost-aware, secure, scalable systems using AWS services and Kubernetes.Mentor junior engineers and set best practices.Work across organisational boundaries and influence without authority when needed.Keep abreast of modern engineering trends, especially in AI/ML infrastructure and cloud-native tooling.Key Requirements 8-12 years of experience in software/data engineering; ideally in platform or infra roles.Strong understanding of Generative AI concepts, along with hands-on experience in developing and deploying AI applications in real-world environments.Experience with Agentic Solutions and technologies (Langchain, Langraft, Rag-Patterns)Deep experience with AWS services (S3, Glue, Kinesis, Lambda, ECS, IAM, KMS, Api Gateway, Step Functions, MSK, Cloudformation etc.)Experience with On-Prem Hadoop and Kubernetes.Strong programming skills in Python; familiarity with Java is a plus.Knowledge of how quantitative or front-office developers operate is a strong plusIf you or someone you know is interested in this position, apply below or reach out to matthew.dobreecarey@caspianone.co.uk",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology and Finance",
      "Industries": "Information Services, Computer and Network Security, and Financial Services"
    },
      "skills": [
        "Python",
        "Java",
        "AWS",
        "S3",
        "Glue",
        "Kinesis",
        "Lambda",
        "ECS",
        "IAM",
        "KMS",
        "API Gateway",
        "Step Functions",
        "MSK",
        "CloudFormation",
        "Kubernetes",
        "Hadoop",
        "Langchain",
        "Langraft",
        "RAG"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_024"
  },
  {
    "job_id": "ai-engineer-new-grad-at-traversal-4336826567",
    "title": "AI Engineer - New Grad",
    "company": "Traversal",
    "location": "New York, NY",
    "posted_date": "2025-11-19",
    "job_url": "https://www.linkedin.com/jobs/view/ai-engineer-new-grad-at-traversal-4336826567?position=20&pageNum=0&refId=xi4Tj7oHHsJ%2BbP%2Bu5O9JEg%3D%3D&trackingId=r6uuRUm5YG3ItJq7TgSWDg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793256",
    "description": "About TraversalTraversal is the AI Site Reliability Engineer (SRE) for the enterprise—already trusted by some of the largest companies in the world to troubleshoot, remediate, and even prevent the most complex production incidents. Our mission is to free engineers from endless firefighting and enable them to focus on creative, high-impact work.Our roots remain deeply embedded in AI research, and we're channeling that scientific rigor and creativity into building the premier AI agent lab for the enterprise. Hence, what we're proudest of is assembling the most talented yet nicest group of individuals, including researchers from MIT, Harvard, and Berkeley, to world-class engineers from industry: Citadel Securities, Cockroach Labs, Datadog, DE Shaw, ServiceNow, Glean, Perplexity, Pinecone, and more, to take on one of the hardest problems for AI to solve. Without the entire team, none of this would be possible.The RoleAs a New Grad Software Engineer at Traversal, you'll help build the core product and AI systems that power our observability platform. Depending on your interests and the team's needs, you might work on:Backend services and APIsFrontend product experiencesAI agents and LLM-powered workflowsData and infrastructure that keep everything fast and reliableYou'll work closely with experienced engineers across AI, backend, infra, and product to ship real features that help engineers understand and debug complex systems.What you'll doShip product features: Contribute to end-to-end features across the stack—from backend logic to frontend UI.Build and integrate APIs: Help design, implement, and maintain APIs and services that power user workflows and AI integrations.Work with AI & agents: Collaborate with AI engineers to plug LLMs and agent workflows into real product experiences.Handle real data: Work with logs, metrics, traces, or other system data to make insights understandable and actionable.Experiment & iterate: Prototype ideas, run experiments, and use data and feedback to decide what to ship.Debug & improve reliability: Help monitor, debug, and improve performance and reliability of the systems you work on.You might be a good fit if You're graduating with a BS/MS in Computer Science or a related field (or have equivalent experience), or you're currently a student looking for an internship.You have strong coding skills in Python, TypeScript/JavaScript, Go, Rust, or similar, and you've built real projects (internships, research, hackathons, side projects).You're interested in one or more of:Full-stack development (backend + frontend)AI/LLMs and agentsInfrastructure, distributed systems, or data-heavy applicationsYou enjoy debugging, learning new systems, and working through ambiguous problems.You're excited by startups: high ownership, fast iteration, and working closely with a small, senior team.Nice to Have (not required)Experience with React, TypeScript, Next.js, or other modern frontend frameworks.Exposure to backend frameworks (e.g., FastAPI, Flask) or databases like Postgres.Projects involving LLMs, prompt engineering, fine-tuning, or agentic workflows.Familiarity with observability data (logs, metrics, traces) or incident response tools.Exposure to cloud infrastructure (AWS/GCP), Docker, or Kubernetes.Contributions to open source or personal projects you're proud to show.CompensationWe offer competitive compensation, startup equity, health insurance, and additional benefits. The U.S. base salary range for this full-time, in-person role in New York is $100,000–$130,000, plus equity and benefits. Our salary ranges are based on location, level, and role. Individual compensation is determined by experience, skills, and job-related knowledge.Why You Should Join UsWe'll make sure you're fully supported with health insurance, a great tech setup, flexible time off, and plenty of in-office snacks. We offer competitive salary and equity packages, and take thoughtful consideration with every hire on our small, high-impact team.Traversal is fully in-office, 5 days a week, based in New York near Madison Square Park. We have a collaborative, hard-working culture and are energized by building the future of AI-powered software maintenance.Working here means owning meaningful parts of the product, having the flexibility to move fast, and learning constantly. This is a place to grow your career, make a real impact, and help define a new category of infrastructure software.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
      "skills": [
        "Python",
        "JavaScript",
        "TypeScript",
        "Go",
        "Rust",
        "React",
        "Flask",
        "Next.js",
        "FastAPI",
        "PostgreSQL",
        "AWS",
        "GCP",
        "Docker",
        "Kubernetes",
        "Datadog"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_025"
  },
  {
    "job_id": "ai-ml-engineer-at-oracle-4337407644",
    "title": "AI/ML Engineer",
    "company": "Oracle",
    "location": "Pune, Maharashtra, India",
    "posted_date": "2025-11-04",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-oracle-4337407644?position=1&pageNum=0&refId=ucCEnmasjPrSVo%2BuOMBP0Q%3D%3D&trackingId=WHFL8MxDfqHxdtxdxKlBkw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793261",
    "description": "AI Applications Engineer Interview Location- PuneJob Location- Hyderabad/Bangalore/Pune/Noida Join Oracle Applications Labs, where we design, build, and operate Oracle’s mission-critical AI-based enterprise applications—including systems that automate our AI cloud data centers. Our mission is to showcase Oracle’s AI-driven products and technologies, deploying them internally to support Oracle’s growth as a global AI leader. As part of our global team of data scientists, AI engineers, program managers, and scrum masters, you’ll contribute to transforming Oracle into an industry leader in AI. Essential Skills Proficiency in programming languages relevant to AI (e.g., Python, Java).Familiarity with modern AI/ML frameworks and platforms (e.g., TensorFlow, PyTorch, Oracle Cloud AI services).Practical experience with enterprise software development, including REST APIs, microservices, and cloud-native architectures.Strong problem-solving skills, particularly in translating business needs into scalable AI solutions.Excellent written and verbal communication skills.Ability to work effectively in a collaborative, multi-disciplinary, and global team environment. Required: Bachelor’s degree or equivalent experience in Computer Science, Engineering, Mathematics, or a related technical field.At least 1 year of experience in AI, software engineering, or closely related fields (exceptional candidates with less experience will be considered).Hands-on knowledge of common AI techniques, including machine learning methods and statistical modeling.Preferred: Masters degree or higher in Computer Science, Data Science, Artificial Intelligence, or related discipline.Experience with Large Language Models, Retrieval Augmented Generation, or other advanced modern AI tooling.Prior work with cloud platforms (preferably Oracle Cloud Infrastructure) a major plus.Experience in developing and deploying enterprise-grade AI solutions.Familiarity with DevOps practices and tools for CI/CD.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Python",
        "Java",
        "TensorFlow",
        "PyTorch",
        "Oracle Cloud",
        "Oracle Cloud AI",
        "REST API",
        "Microservices",
        "CI/CD",
        "DevOps",
        "Machine Learning",
        "Statistical Modeling",
        "LLM",
        "RAG"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_029"
  },
  {
    "job_id": "ai-ml-engineer-at-emerson-4295163204",
    "title": "AI/ML Engineer",
    "company": "Emerson",
    "location": "Noida, Uttar Pradesh, India",
    "posted_date": "2025-11-14",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-emerson-4295163204?position=5&pageNum=0&refId=ucCEnmasjPrSVo%2BuOMBP0Q%3D%3D&trackingId=LUR1hEsxP6Gzke5xwWrikg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793273",
    "description": "Job DescriptionJob Summary:Looking for an AI Developer with proficiency in AI, artificial intelligence, deep learning, NLP, generative AI, and optimization approaches. Proficient in developing, implementing, and launching AI models for functions like predictive analytics, anomaly detection, intelligent process improvement, and conversational AI. Proficient in applying reinforcement learning, fuzzy logic methodologies, and decision-making strategies. Having expertise in reinforcement learning, fuzzy logic systems, and decision-making using innovative technology is beneficial.This role involves designing, implementing, and optimizing AI-powered solutions to enhance the performance, efficiency, and reliability of digital platforms, industrial processes, and enterprise systems. The candidate will work on integrating AI models into production environments, automating workflows, and bringing to bear generative AI to drive innovation across business applications.If you think this role suits you, join our team and apply now!In this Role, Your Responsibilities Will Be:AI/ML Model Development & Automation – Develop AI/ML models that assist Ovation engineers by automating tasks such as control logic generation, graphics template suggestions, report/documentation automation, and workflow optimization.Data-Driven Insights & Predictive Tooling – Analyze Ovation system engineering data (configuration files, tag databases, and control schemes) to identify patterns, build predictive tools, and enable data-driven decision-making.Generative AI & NLP Applications – Integrate large language models (LLMs) and natural language processing (NLP) techniques to translate natural language descriptions into Ovation configuration elements and intelligent engineering support tools.Productivity & Operator Assistance – Create AI-powered operator-assistive tools such as SOP recommendations, automated report generation, intelligent dashboards, and alarm prioritization to enhance plant performance.Predictive Maintenance & Anomaly Detection – Design AI-based modules for predictive maintenance, control loop performance monitoring, anomaly detection, and root-cause analysis using Ovation historian and time-series process data.MLOps & Lifecycle Management – Implement and maintain AI model pipelines for training, validation, deployment, monitoring, and continuous improvement in the Ovation engineering environment.Collaboration & Co-Creation – Work closely with control engineers, software developers, and UX designers to deliver user-friendly AI-enabled features; collaborate with plant engineers and operators to validate models and ensure seamless integration with DCS HMI.Compliance & Security – Ensure all AI solutions align with Emerson’s Plantweb ecosystem standards, cybersecurity guidelines, and operational safety procedures.Clear Communication – Proficiently explain technical concepts to non-technical colleagues and support a culture of innovation, collaboration, and Agile delivery.Who You AreWe are looking for a proactive professional who excels in dynamic, fast-paced environments. You demonstrate exceptional initiative, confidently tackling complex challenges in power plant control and optimization. With a strong commitment to innovation and excellence, you set ambitious goals and uphold the highest standards in every project.For This Role, You Will Need:A Bachelor’s degree (or equivalent experience) in Engineering, Artificial Intelligence, Data Science, Electrical/Computer Engineering, or a related field.2–5 years of hands-on experience in AI/ML model development, deployment, and optimization, with a track record of driving innovation and efficiency in real-world applications.Preferred Qualifications That Make You Stand Out:Deep expertise in machine learning, deep learning, and generative AI techniques (LLMs, diffusion models, reinforcement learning), enabling automation, optimization, and decision support in engineering workflows.Proven proficiency in Python, TensorFlow/PyTorch, and MLOps frameworks, with hands-on experience in deploying AI in production and industrial environments.Knowledge of power plant processes (boiler, turbine, steam temperature, combustion, unit load optimization, drum level/feedwater control) and ability to apply AI/ML solutions to optimize these operations.Strong understanding of control theory and advanced control strategies (PID, MPC, fuzzy logic, multivariable control) and how AI can enhance traditional approaches.Experience working with Emerson Ovation DCS or similar control/automation systems, integrating AI-based modules into control engineering workflows.Proficiency in predicting maintenance issues, detecting irregularities, and enhancing processes with time-series data from historians/DCS systems.Familiarity with responsible AI practices (explain ability, bias detection, compliance) to ensure safe and trustworthy adoption in critical infrastructure.Excellent communication and collaboration skills, with the ability to bridge AI/ML techniques with domain experts in power generation and automation.Our Culture & Commitment to You:At Emerson, we prioritize a workplace where every employee is valued, respected, and empowered to grow. We foster an environment that encourages innovation, collaboration, and diverse perspectives—because we know that great ideas come from great teams. Our commitment to ongoing career development and growing an inclusive culture ensures you have the support to thrive. Whether through mentorship, training, or leadership opportunities, we invest in your success so you can make a lasting impact. We believe diverse teams, working together are key to driving growth and delivering business results.We recognize the importance of employee wellbeing. We prioritize providing flexible, competitive benefits plans to meet you and your family’s physical, mental, financial, and social needs. We provide a variety of medical insurance plans, with dental and vision coverage, Employee Assistance Program, 401(k), tuition reimbursement, employee resource groups, recognition, and much more. Our culture offers flexible time off plans, including paid parental leave (maternal and paternal), vacation and holiday leave.Learn more about our Culture and Values.About UsWHY EMERSONOur Commitment to Our PeopleAt Emerson, we are motivated by a spirit of collaboration that helps our diverse, multicultural teams across the world drive innovation that makes the world healthier, safer, smarter, and more sustainable. And we want you to join us in our bold aspiration.We have built an engaged community of inquisitive, dedicated people who thrive knowing they are welcomed, trusted, celebrated, and empowered to solve the world’s most complex problems — for our customers, our communities, and the planet. You’ll contribute to this vital work while further developing your skills through our award-winning employee development programs. We are a proud corporate citizen in every city where we operate and are committed to our people, our communities, and the world at large. We take this responsibility seriously and strive to make a positive impact through every endeavor.At Emerson, you’ll see firsthand that our people are at the center of everything we do. So, let’s go. Let’s think differently. Learn, collaborate, and grow. Seek opportunity. Push boundaries. Be empowered to make things better. Speed up to break through. Let’s go, together.Accessibility Assistance or AccommodationIf you have a disability and are having difficulty accessing or using this website to apply for a position, please contact: idisability.administrator@emerson.com .About EmersonEmerson is a global leader in automation technology and software. Through our deep domain expertise and legacy of flawless execution, Emerson helps customers in critical industries like life sciences, energy, power and renewables, chemical and advanced factory automation operate more sustainably while improving productivity, energy security and reliability.With global operations and a comprehensive portfolio of software and technology, we are helping companies implement digital transformation to measurably improve their operations, conserve valuable resources and enhance their safety.We offer equitable opportunities, celebrate diversity, and embrace challenges with confidence that, together, we can make an impact across a broad spectrum of countries and industries. Whether you’re an established professional looking for a career change, an undergraduate student exploring possibilities, or a recent graduate with an advanced degree, you’ll find your chance to make a difference with Emerson. Join our team – let’s go!No calls or agencies please.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Automation Machinery Manufacturing"
    },
      "skills": [
        "Python",
        "Go",
        "TensorFlow",
        "PyTorch",
        "NLP",
        "Reinforcement Learning",
        "Machine Learning",
        "Deep Learning",
        "Generative AI",
        "MLOps",
        "Ovation DCS",
        "Control Theory",
        "PID",
        "MPC",
        "Fuzzy Logic",
        "Multivariable Control",
        "Time-Series Data",
        "Predictive Maintenance"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_032"
  },
  {
    "job_id": "ai-ml-engineer-at-aivar-innovations-4340978167",
    "title": "AI/ML Engineer",
    "company": "Aivar Innovations",
    "location": "Coimbatore, Tamil Nadu, India",
    "posted_date": "2025-11-18",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-aivar-innovations-4340978167?position=8&pageNum=0&refId=ucCEnmasjPrSVo%2BuOMBP0Q%3D%3D&trackingId=rboKlz3wZjmUsxOETxoCNA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793277",
    "description": "Are you a motivated individual eager to launch your career in generative AI and learn advanced technologies? Are you a hands-on learner with an interest in large language models and emerging AI technologies? Do you possess the ability to collaborate effectively within a team environment to implement and learn technical solutions?At Aivar, we're looking for entry-level architects and engineers to learn generative AI techniques and contribute to building innovative solutions under the guidance of experienced professionals.As an Generative AI/ML Engineer, you'll learn from technology and business teams while developing solutions. You will gain hands-on experience in a fast-paced environment that contributes to innovative AI projects.Key Job ResponsibilitiesLearn to implement large language model solutions using Amazon Web Services (AWS)Learn Generative AI frameworks (LangChain, LangSmith, HuggingFace)Support prompt engineering implementationAssist in fine-tuning pipelines for specific use casesLearn to build basic generative AI solutions for text and imagesHelp implement RAG architecturesSupport MLOps/LLMOps practicesDocument implementations and learningsAssist in testing generative AI solutionsSkills:- Problem solving, Domain management, Artificial Intelligence (AI) and Generative AI",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "AWS",
        "LangChain",
        "LangSmith",
        "HuggingFace",
        "LLMOps",
        "MLOps",
        "RAG",
        "Large Language Models"
      ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251120_034"
  },
  {
    "job_id": "data-analyst-at-syra-health-4340986838",
    "title": "Data Analyst",
    "company": "Syra Health",
    "location": "United States",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-syra-health-4340986838?position=5&pageNum=0&refId=bjCjz1j7PE84Mey0wlKetA%3D%3D&trackingId=%2FucrEt9oVYHrK%2FArq3yM3A%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793302",
    "description": "SH-744 Data Analyst, Indianapolis, INAbout Syra HealthSyra Health is a healthcare consulting company with a mission to improve healthcare by providing innovative services and technology solutions. Syra Health aims to achieve its goal by becoming a valuable partner to government, payers, providers, life sciences organizations, and academic institutions. Syra Health offers products and services in digital health, behavioural and mental health, population health management, health education, and healthcare workforce.For more information, please visit www.syrahealth.com.Job SummaryWe are seeking a highly skilled Data Analyst to join our team and play a critical role in supporting our healthcare initiatives. The ideal candidate will have a strong background in data analysis, statistical modeling, and data visualization. This role will involve analyzing complex datasets, generating insightful reports, and supporting key decision-making processes.Key ResponsibilitiesData Analysis and Reporting: Conduct in-depth analysis of large datasets to identify trends, patterns, and anomalies. Develop and maintain data reports and dashboards to monitor key performance indicators.Statistical Modeling: Utilize statistical techniques to model data, forecast trends, and make data-driven decisions.Data Visualization: Create clear and compelling data visualizations using tools like Power BI, Tableau, or other relevant software.Compliance and Quality Monitoring: Support compliance efforts by analyzing data to identify potential issues and track key performance metrics.Provider Network Analysis: Analyze provider network data to assess adequacy and identify opportunities for improvement.Geographic Access Reporting: Generate reports on geographic access to healthcare services, utilizing tools like GIS.Ad-hoc Analysis: Respond to ad-hoc data requests and provide timely analysis.Required Skills And ExperienceStrong proficiency in SQL for data extraction, transformation, and analysis.Experience with data visualization tools (Power BI, Tableau).Knowledge of statistical analysis techniques (regression, hypothesis testing, ANOVA).Familiarity with healthcare data and regulatory requirements.Excellent analytical and problem-solving skills.Strong attention to detail and accuracy.Excellent communication and presentation skills.Preferred QualificationsExperience with Python or R for data analysis and modeling.Knowledge of GIS tools (ArcGIS, QGIS).Experience with data warehousing and ETL processes.Certification in data analysis or business intelligence.Healthcare data and knowledge of the healthcare industry is a plus",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Hospitals and Health Care"
    },
      "skills": [
        "Python",
        "R",
        "SQL",
        "Tableau",
        "Power BI",
        "ETL",
        "Data Warehousing",
        "ArcGIS",
        "QGIS",
        "Statistical Modeling",
        "Data Visualization",
        "Business Intelligence"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_007"
  },
  {
    "job_id": "data-analyst-at-exxonmobil-4337073004",
    "title": "Data Analyst",
    "company": "ExxonMobil",
    "location": "Houston, TX",
    "posted_date": "2025-11-19",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-exxonmobil-4337073004?position=7&pageNum=0&refId=bjCjz1j7PE84Mey0wlKetA%3D%3D&trackingId=43dXy7VD4K1gy%2F0MgRpVDw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793306",
    "description": "About UsAt ExxonMobil, our vision is to lead in energy innovations that advance modern living and a net-zero future. As one of the world’s largest publicly traded energy and chemical companies, we are powered by a unique and diverse workforce fueled by the pride in what we do and what we stand for.The success of our Upstream, Product Solutions and Low Carbon Solutions businesses is the result of the talent, curiosity and drive of our people. They bring solutions every day to optimize our strategy in energy, chemicals, lubricants and lower-emissions technologies.We invite you to bring your ideas to ExxonMobil to help create sustainable solutions that improve quality of life and meet society’s evolving needs. Learn more about our What and our Why and how we can work together.About HoustonExxonMobil's state-of-the-art campus north of Houston serves as home to its Upstream, Product Solutions and Low Carbon Solutions businesses and their associated service groups. The facility opened in 2014 and accommodates more than 10,000 employees and visitors.By bringing many global functional groups together, the campus provides employees with the tools and capabilities needed today, and in the future, to achieve business objectives and accelerate the discovery of new resources, technologies and products. It was designed to foster improved collaboration, creativity and innovation and enhance the company’s ability to attract, develop and retain the top talent in the industry.The campus is located in Spring, Texas, on 385 wooded acres immediately to the west of Interstate Highway 45 (I-45), at the intersection of I-45 and the Hardy Toll Road, approximately 25 miles from the cultural vibrancy of downtown Houston.The campus was constructed to the highest standards of energy efficiency and environmental stewardship. Its design incorporates extensive research into best practices in building and workplace design through extensive benchmarking of the world’s top academic, research, and corporate facilities.AboutLearn more about what we do in Houston here. What role you will play in our teamA Data Analyst will leverage data engineering and BI development techniques to pipeline, automate, analyze, and visualize dataThis role reports to the Continuous Improvement team and supports strategic decision-making for safety, production, and cost optimization by applying data-driven insightsThis job will be located in Houston, TXWhat You Will DoDevelop automated reports, conduct analyses, and provide visibility into KPIs and performance drivers and trends help create final displays of the results, often for formal presentationsBuild and manage data pipelines integrating structured and unstructured data sourcesDesign, develop, and institute automated workflows utilizing various technologies (SQL, Python, Databricks, Alteryx, Spotfire, MS Power Platform and more) to minimize human error, standardize data, and apply data management best practices with a focus on data integrity and governanceDevelop ETL processes and maintain application integrations across multiple systems and data sourcesCoordinate with Field and Engineering to perform analysis on drivers impacting LOE, Capital, and ProductionDevelop, maintain, and distribute recurring reports for Permian Operations timely and accuratelyAssist in compiling data for regulatory, financial, and accounting reportingMaintain up-to-date and accurate data analysis and tool documentation for reference purposesEvaluate current processes around data entry, data QC, report distribution and provide recommendations and solutions on optimizing existing processesIdentify redundancies, automation opportunities, process inefficiencies and provide solutionsCommunicate, collaborate, and report with multiple departments – field operations, IT, accounting, data support groups, etcDevelop, maintain, distribute, and provide training on standardized tools for analyzing LOE, Capital, Production, and SSHE events/observationsStay updated on advancements in data automation, analysis, AI, machine learning, and digital oilfield technologiesMentor engineers/analysts within the team on data engineering and BI development techniquesAbout YouBachelor's degree required in Data/Computer Science, Engineering, Mathematics or related fieldEducation should include mathematical and computer training5+ years experience in a technical roleAdvanced level of data handling skills to include data integration and creating reportsProficient working with relational databases and generating complex data visualizationsCan modify established workflows and evaluate and assess errors as they ariseCan interpret, understand, and explain workflows and data processesPerforms complex analytics, generates insightful dashboards and or can write code to automate basic redundant workflows/processesWorks under limited supervisionWorks with technical staff and professionalsExperience with data visualization including Spotfire and PowerBI applications is requiredExperience with ETL processes and Workflow automation (Ex: Databricks, Alteryx) is requiredAdvanced proficiency in MS Office suitePreferred Qualifications/ ExperienceUnderstanding of programming languages such as Python, R, Matlab or similar is highly preferredSubject Matter Expert within select functions applicable to Data Analyst roleYour BenefitsAn ExxonMobil career is one designed to last. Our commitment to you runs deep: our employees grow personally and professionally, with benefits built on our core categories of health, security, finance, and life.We offer you: Pension Plan: Enrollment is automatic and at no cost to you. The basic benefit is a monthly annuity to be paid to you in retirement for the rest of your life. Savings Plan: You can contribute between 6% and 20% of your pay and are encouraged to enroll right away. If you contribute at least 6% to your savings plan, the Company will contribute a 7% matchComprehensive medical, dental, and vision plans. Culture of Health: Programs and resources to support your wellbeing. Employee Health Advisory Program: Provides confidential professional counseling for you and your family, including tools and resources promoting mental health and resiliency at no additional cost to you. Disability Plan: Income replacement for when you cannot work due to illness or injury occurring on or off the job. Enrollment is automatic and at no cost to you. More information on our Company’s benefits can be found at www.exxonmobilfamily.comPlease note benefits may be changed from time to time without notice, subject to applicable law.Stay connected with usLearn more at our websiteFollow us on LinkedIN and Instagram Like us on Facebook Subscribe our channel at YouTubeEmployer equal opportunityExxonMobil is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, citizenship status, protected veteran status, genetic information, or physical or mental disability.Nothing herein is intended to override the corporate separateness of local entities. Working relationships discussed herein do not necessarily represent a reporting connection, but may reflect a functional guidance, stewardship, or service relationship.Exxon Mobil Corporation has numerous affiliates, many with names that include ExxonMobil, Exxon, Esso and Mobil. For convenience and simplicity, those terms and terms like corporation, company, our, we and its are sometimes used as abbreviated references to specific affiliates or affiliate groups. Abbreviated references describing global or regional operational organizations and global or regional business lines are also sometimes used for convenience and simplicity. Similarly, ExxonMobil has business relationships with thousands of customers, suppliers, governments, and others. For convenience and simplicity, words like venture, joint venture, partnership, co-venturer, and partner are used to indicate business relationships involving common activities and interests, and those words may not indicate precise legal relationships.Job Id: 82322",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Oil and Gas"
    },
      "skills": [
        "Python",
        "R",
        "MATLAB",
        "SQL",
        "Databricks",
        "Alteryx",
        "Spotfire",
        "ETL",
        "Data Integration",
        "Data Visualization",
        "Reporting",
        "Machine Learning"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_009"
  },
  {
    "job_id": "data-analyst-at-allied-consultants-inc-4323015156",
    "title": "Data Analyst",
    "company": "Allied Consultants, Inc.",
    "location": "Austin, Texas Metropolitan Area",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-allied-consultants-inc-4323015156?position=8&pageNum=0&refId=bjCjz1j7PE84Mey0wlKetA%3D%3D&trackingId=vVtbvM7jIehFaIZyQ722ZQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793311",
    "description": "Allied Consultants, Inc is a proudly Austin based firm with over 33 years of experience delivering top-tier technical and business professionals within Texas State Agencies. We are currently seeking an experience Data Analyst to play a key role within a high-impact technical services team.**Location of job: Onsite. Candidates must be local to Austin, TX, within a 50 mile radius.**ResponsibilitiesThe client seeks highly qualified candidates to fill the Data Analyst position within the client's Environmental Epidemiology and Disease Registries Section. This position will perform senior level consultative services and technical assistance work in the area of client's analysis for program related activities. Work involves analyzing client's priority initiatives and special projects utilizing business analysis best practices in coordination with agency business and technical units. Duties include: assessing, analyzing, researching, documenting data requirements, assuring the use of data best practices and standards, assisting in the coordination and optimization of client's operations and program functions and providing recommendations.Data reporting analysts transform data into information that can be utilized to make business decisions and actions. Their work involves acquiring data from other sources, creating reports on a regular basis, correcting any code issues, and ensuring that databases remain error-free and organized. This position is responsible for assisting with the analysis across numerous related initiatives and leading special projects as assigned by agency leadership. These responsibilities include: developing data analysis tools; defining data requirements; providing recommendations to project leadership. This position will also work with staff to initiate, facilitate or participate in projects to maximize the success of multiple and diverse projects. Works under limited direction with extensive latitude for the use of initiative and independent judgment. QualificationsMinimum Requirements:8 years of:Ability to research, gather, assemble, correlate and analyze facts; to devise solutions to problems; and to prepare concise reports and/or to analyze and solve complex and difficult problems and prioritize information and issues.Required Ability to transform data into information that can be utilized to make business decisions and develop and present reports identifying gaps in technology and operational effectiveness to executive stakeholders.Develops or contributes in the development of as-is / to-be data models to identify opportunities for greater operational efficiencies.Skilled in effectively mapping data and identifying improvements. Establishes benchmarks and develops framework for operational trend analysis and performance measurementRequired Experience with the analysis of data policies and procedures to determine their effect on automated systems and system functional areas.Acquires data from various sources, creates reports on a regular basis, and performs deep analysis of underlying trends and correlations. Develops metadata, tables and user interfaces to define clear reports for business usersRequired Uses creativity and specialty reporting tools to define and develop data reports, dashboards, and data visualizations.Preferred:5 years of:Uses creativity and specialty reporting tools to define and develop data reports, dashboards, and data visualizations.Experience developing strategic and project SDLC materials, including gap analysis, recommendations, roadmaps, requirements, design documents, system and data flow diagrams, test cases, and use cases.1 year of:State or Federal Public Sector experienceOverviewAt Allied Consultants, we value our consultants and are committed to providing an exceptional experience including:Highly competitive pay ratesLocal support staff for responsive, personal serviceComprehensive benefits package, including:Medical insurance (with employer cost sharing)Life insuranceA 401(K) plan with company matchFlexible spending through a cafeteria planCandidates selected for interviews will be subject to a criminal background check and may be required to pass a drug screening, in compliance with federal and state regulations. All offers of employment are contingent upon successful completion of these checks. Allied Consultants is a proud to be an Equal Opportunity Employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Contract",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Data Analysis",
        "Reporting",
        "Data Visualization",
        "Data Modeling"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_010"
  },
  {
    "job_id": "data-analyst-at-emids-4323115520",
    "title": "Data Analyst",
    "company": "Emids",
    "location": "United States",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-emids-4323115520?position=10&pageNum=0&refId=bjCjz1j7PE84Mey0wlKetA%3D%3D&trackingId=qVAbUkjx2BTd7Ndgym3Hdg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793315",
    "description": "Emids is a leading provider of digital transformation solutions to the healthcare industry, serving payers, providers, life sciences, and technology firms. Headquartered in Nashville, Emids helps bridge critical gaps in providing accessible, affordable, and high-quality healthcare by providing digital transformation services, custom application development, data engineering, business intelligence solutions, and specialized consulting services to all parts of the healthcare ecosystem. With nearly 3,500 professionals globally, Emids leverages strong domain expertise in healthcare-specific platforms, regulations, and standards to provide tailored, cutting-edge solutions and services to its clientsResponsibilities: Responsible for designing, developing, and optimizing semantic data model using Looker Modeling Language (LookML) to transform raw data into a reliable, consistent, and user-friendly source of truth.Design and Implement LookML Models: Translate complex business requirements and raw data warehouse schemas (e.g., in BigQuery, Snowflake, Redshift) into robust, scalable, and highly performant LookML models, Views, and Explores.Define Metrics and Business Logic: Enforce a \"single source of truth\" by defining and centralizing all core business metrics, dimensions, and calculations (measures) within LookML.Develop Derived Tables: Create Persistent Derived Tables (PDTs) and Native Derived Tables (NDTs) to pre-calculate complex or common logic, significantly improving query performance and user experienceRequired skills: Experience: 3+ years of professional experience in Business Intelligence development, with at least 2+ years of hands-on, deep expertise with Looker and LookML.SQL Mastery: Advanced proficiency in writing and optimizing complex SQL queries across cloud data warehouses (e.g., BigQuery, Snowflake, etc.).Data Modeling: Solid understanding of data warehousing concepts, including star/snowflake schemas and normalization/denormalization techniques.Emids is an Equal Opportunity Employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, alienage or national origin, ancestry, citizenship status, age, disability or handicap, sex, marital status, veteran status, sexual orientation, or any other characteristic protected by applicable federal, state or local laws. Our management team is dedicated to this policy with respect to recruitment, hiring, placement, promotion, transfer, training, compensation, benefits, employee activities and general treatment during employment.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Public Health, Insurance Agencies and Brokerages, and Insurance"
    },
      "skills": [
        "SQL",
        "Snowflake",
        "BigQuery",
        "Redshift",
        "LookML",
        "Looker",
        "Data Modeling",
        "Data Warehousing",
        "Business Intelligence"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_012"
  },
  {
    "job_id": "data-analyst-t500-20905-at-delta-air-lines-4315163413",
    "title": "Data Analyst [T500-20905]",
    "company": "Delta Air Lines",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-14",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-t500-20905-at-delta-air-lines-4315163413?position=2&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=J2EdeYx%2BKZR6z6B6%2BKoJvQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793328",
    "description": "About Delta Tech Hub:Delta Air Lines (NYSE: DAL) is the U.S. global airline leader in safety, innovation, reliability and customer experience. Powered by our employees around the world, Delta has for a decade led the airline industry in operational excellence while maintaining our reputation for award-winning customer service. With our mission of connecting the people and cultures of the globe, Delta strives to foster understanding across a diverse world and serve as a force for social good. Delta has fast emerged as a customer-oriented, innovation-led, technology-driven business. The Delta Technology Hub will contribute directly to these objectives. It will sustain our long-term aspirations of delivering niche, IP-intensive, high-value, and innovative solutions. It supports various teams and functions across Delta and is an integral part of our transformation agenda, working seamlessly with a global team to create memorable experiences for customers.Responsibilities: Data Integration and Harmonization:Aggregate and normalize HR data from multiple platforms Implement data transformation and enrichment processes to support analytics and reporting needs.Data Quality and Monitoring:Develop and implement data validation and monitoring frameworks to ensure data accuracy and consistency.Troubleshoot and resolve issues related to data quality, latency, or performance.Collaboration with Stakeholders:Partner with teams, analysts, and data scientists to understand data requirements and translate them into technical solutions.Provide technical support and guidance on data-related issues or projects.Tooling and Automation:Leverage cloud-based solutions and frameworks (e.g., AWS) to streamline processes and enhance automation.Maintain and optimize existing workflows while continuously identifying opportunities for improvement.Continuous Learning and Innovation:Stay current with industry trends, tools, and technologies in data engineering and marketing analytics.Recommend and implement innovative solutions to improve the scalability and efficiency of data systems.What you need to succeed (minimum qualifications):Bachelor’s or master’s in data science, Business Analytics, Information Science, Computer Science, Statistics, or a related field.2+ yrs of Experience as Data Analyst with experience in Python (NumPy & Pandas) including (Matplotlib / Seaborn) & EDA & SQL & Scikitlearn library.Experience with AWS DB - (S3 Bucket or Redshift) is required.Basic understanding of ETL / Glue data pipelines.What will give you a competitive edge (preferred qualifications): Hands on Experience with Dashboarding e.g QuicksightDesired experience working with HR DataExperience working with Glue/Lambda to develop data pipelinesExperience working with DBT",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology and Engineering",
      "Industries": "Airlines and Aviation"
    },
      "skills": [
        "Python",
        "SQL",
        "Pandas",
        "NumPy",
        "Matplotlib",
        "Seaborn",
        "Redshift",
        "AWS",
        "S3",
        "Lambda",
        "dbt",
        "ETL",
        "Data Integration",
        "Data Transformation",
        "Data Quality",
        "Quicksight",
        "Dashboarding",
        "Scikit-learn"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_015"
  },
  {
    "job_id": "am-data-analyst-at-medanta-4335443971",
    "title": "AM-Data Analyst",
    "company": "Medanta",
    "location": "Gurugram, Haryana, India",
    "posted_date": "2025-11-11",
    "job_url": "https://in.linkedin.com/jobs/view/am-data-analyst-at-medanta-4335443971?position=5&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=g3%2B11yMOB%2FRDuAeViAU98w%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793336",
    "description": "Job Summary:We are looking for a highly skilled Data Analyst with 2+ years of experience in data analysis, statistical modelling, and AI-driven insights. The ideal candidate will have expertise in handling large datasets, building analytical models, and leveraging AI/ML techniques to drive business decisions.Key Responsibilities:Collect, clean, and analyse large datasets to generate actionable insights.Develop and maintain dashboards, reports, and data visualizations.Utilize AI and machine learning algorithms to enhance data analysis and predictive modelling.Collaborate with cross-functional teams to understand business requirements and implement data-driven solutions.Perform statistical analysis and hypothesis testing to support strategic decisions.Automate data collection, pre-processing, and reporting processes.Ensure data accuracy, integrity, and security in all analytics processes.Stay up to date with the latest trends and advancements in AI and data analytics.Required Skills & Qualifications:Bachelor’s or Master’s degree in Data Science, Statistics, Computer Science, or a related field (research/Stats/Maths/Hospital management).3-5 years of experience in data analysis or hospital management, business intelligence, or related roles.Proficiency in SQL, Python, or R for data manipulation and analysis.Strong experience in visualization tools such as Tableau, Power BI, or similar.Strong problem-solving and analytical thinking abilities.Excellent communication and stakeholder management skills.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Analyst",
      "Industries": "Hospitals and Health Care"
    },
      "skills": [
        "Python",
        "R",
        "SQL",
        "Machine Learning",
        "Statistics",
        "Tableau",
        "Power BI",
        "Business Intelligence",
        "Reporting",
        "Data Analysis"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_017"
  },
  {
    "job_id": "data-analyst-at-persistent-systems-4341161525",
    "title": "Data Analyst",
    "company": "Persistent Systems",
    "location": "Mumbai, Maharashtra, India",
    "posted_date": "2025-11-17",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-persistent-systems-4341161525?position=7&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=i47h%2FzXrjbZGxpbTQ1a1AA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793339",
    "description": "About Position: As a Data Analyst – Reporting & Data Analytics, you will drive insights by analyzing and rationalizing enterprise reports. You'll collaborate with cross-functional teams to understand reporting needs and translate them into technical solutions. Leveraging tools like SQL, PySpark, Power BI, and Databricks, you'll ensure data accuracy and impactful visualizations. Your role bridges business requirements with data engineering to enable informed decision-making.Role: Data AnalystLocation: MumbaiExperience: 4 to 7 YearsJob Type: Full Time EmploymentWhat You'll Do: Develop and optimize SQL and PySpark queries to extract, transform, and analyze data from Databricks and other data platforms.Leverage Unity Catalog for data governance and access control. Participate in Report bursting and Distribution monitoring.Work closely with data engineering teams to validate data accuracy, completeness, and transformation logic.Ensure data integrity and consistency across reporting layers.Perform functional-to-technical mapping of legacy reports to new systems and platforms.Support the transition from legacy reporting tools to modern data platforms.Collaborate with cross-functional teams including Operations, Finance, Audit, MIS, and Compliance to gather and understand reporting requirements.Translate business needs into clear, actionable technical specifications.Expertise You'll Bring: Proficiency in SQL and PySpark for data querying and transformation.Hands-on experience with Databricks, Unity Catalog, and Power BI.Strong analytical and problem-solving skills with attention to detail.Excellent communication and stakeholder management abilities.Experience in report rationalization and system migration is a plus.Benefits:Competitive salary and benefits packageCulture focused on talent development with quarterly growth opportunities and company-sponsored higher education and certificationsOpportunity to work with cutting-edge technologiesEmployee engagement initiatives such as project parties, flexible work hours, and Long Service awardsAnnual health check-upsInsurance coverage: group term life, personal accident, and Mediclaim hospitalization for self, spouse, two children, and parentsValues-Driven, People-Centric & Inclusive Work Environment:Persistent Ltd. is dedicated to fostering diversity and inclusion in the workplace. We invite applications from all qualified individuals, including those with disabilities, and regardless of gender or gender preference. We welcome diverse candidates from all backgrounds.We support hybrid work and flexible hours to fit diverse lifestyles.Our office is accessibility-friendly, with ergonomic setups and assistive technologies to support employees with physical disabilities.If you are a person with disabilities and have specific requirements, please inform us during the application process or at any time during your employmentLet’s unleash your full potential at Persistent - persistent.com/careers\"Persistent is an Equal Opportunity Employer and prohibits discrimination and harassment of any kind.'",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "SQL",
        "Databricks",
        "PySpark",
        "Unity Catalog",
        "Power BI",
        "Reporting",
        "Data Governance"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_018"
  },
  {
    "job_id": "data-analyst-at-sparknovatechsolutions-4323143326",
    "title": "Data Analyst",
    "company": "SparkNovaTechSolutions",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-17",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-sparknovatechsolutions-4323143326?position=8&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=FOMT4EZg9gn5D5oY%2FS4AHg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793343",
    "description": "Job Overview We are looking for a highly motivated and detail-oriented Data Analyst to join our analytics team. The ideal candidate will be responsible for gathering, analyzing, and interpreting data to provide meaningful insights that support business strategies and performance optimization.Key Responsibilities Collect, clean, and analyze large datasets from various sources. Develop dashboards, reports, and visualizations using tools like Power BI, Tableau, or Google Data Studio. Identify patterns, trends, and insights to support strategic and operational decisions. Collaborate with cross-functional teams to understand data requirements and deliver actionable insights. Prepare clear presentations and reports for both technical and non-technical stakeholders. Ensure accuracy, consistency, and security of data throughout reporting processes. Assist in the development of predictive models and performance forecasting.Required Skills & Qualifications Bachelor’s degree in Data Science, Statistics, Mathematics, Computer Science, or a related field. 0–2 years of experience in data analysis or business intelligence roles. Strong knowledge of Excel, SQL, and at least one data visualization tool. Basic understanding of Python or R is a plus. Good problem-solving and analytical thinking skills. Excellent communication skills and attention to detail. Willingness to learn in a fast-paced, evolving environment.What We Offer Competitive salary and growth-based performance bonuses. Hands-on experience with real-world analytics projects. Mentorship from experienced professionals in the data and tech space. A collaborative, learning-oriented work culture. Office located in a vibrant and tech-forward business hub.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Python",
        "R",
        "SQL",
        "Tableau",
        "Power BI",
        "Google Data Studio",
        "Business Intelligence",
        "Data Visualization",
        "Statistics",
        "Excel"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_019"
  },
  {
    "job_id": "data-analyst-at-capgemini-4323265940",
    "title": "Data Analyst",
    "company": "Capgemini",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-19",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-capgemini-4323265940?position=10&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=WvXujRkQ2E5yhnv%2BkqyoAg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793349",
    "description": "Job DescriptionThe ESM Consultant focuses on all of the Service Integration and Service Management lifecycle stages and associated processes. They are a recognized subject matter expert in one or more of the lifecycle stages or processes. They are an expert in related areas such as governance, industry standards or regulatory compliance.Job Description - Grade SpecificThe ESM Consultant focuses on all of the Service Integration and Service Management lifecycle stages and associated processes. They are a recognized subject matter expert in one or more of the lifecycle stages or processes. They are an expert in related areas such as governance, industry standards or regulatory compliance. This role provides SME in one or more areas of Service Integration, undertakes consulting work and participates in governance reviews, service audits, benchmarking, and trend analysis. Assists sales teams in pre-qualification and due diligence and builds customer relationships and delivers specific process to support the overall engagement.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Governance",
        "Service Management"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_020"
  },
  {
    "job_id": "data-analytics-analyst-t500-20967-at-inspire-4317817468",
    "title": "Data Analytics Analyst [T500-20967]",
    "company": "Inspire",
    "location": "Hyderabad, Telangana, India",
    "posted_date": "2025-11-17",
    "job_url": "https://in.linkedin.com/jobs/view/data-analytics-analyst-t500-20967-at-inspire-4317817468?position=12&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=Qa54EEEmVUZ7uX3yUBm5mA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793351",
    "description": "About Inspire Brands:Inspire Brands is disrupting the restaurant industry through digital transformation and operational efficiencies. The company’s technology hub, Inspire Brands Hyderabad Support Center, India, will lead technology innovation and product development for the organization and its portfolio of distinct brands. The Inspire Brands Hyderabad Support Center will focus on developing new capabilities in data science, data analytics, eCommerce, automation, cloud computing, and information security to accelerate the company’s business strategy. Inspire Brands Hyderabad Support Center will also host an innovation lab and collaborate with start-ups to develop solutions for productivity optimization, workforce management, loyalty management, payments systems, and more.RESPONSIBILITIES: Build and maintain HR dashboards, and metrics to track and measure key HR performance indicators.Collaborate with HR business partners, talent acquisition, compensation and benefits, and other stakeholders to understand their analytical needs and provide customized dashboards and insights.Stay updated with the latest HR analytics trends, tools, and technologies and recommend innovative solutions to enhance HR data Analyst capabilities.Provide training and guidance to HR team members on data techniques and tools.Ensure data accuracy, integrity, and security in all HR analytics processes and systems.Present findings, insights, and recommendations to senior management and key stakeholders in a clear and concise manner.Collect, analyze, and interpret HR data from multiple sources, including HRIS systems, employee surveys, performance reviews, and other relevant data sets.Identify trends, patterns, and correlations in HR data to provide insights and recommendations for HR initiatives and strategies.EXPERIENCE QUALIFICATION:Required Minimum:2-4 years of relevant experience.Bachelor’s degree in human resources, statistics, business administration, or a related field experience preferred. Proven previous Workday experience. Proficiency in statistical analysis, data mining, and data visualization tools (e.g., Workday, Excel, Tableau, Power BI, etc.).Excellent analytical and problem-solving skills, with the ability to translate complex data into actionable insights.Effective communication and presentation skills to effectively convey complex findings to non-technical stakeholders.Ability to work independently, manage multiple projects simultaneously, and meet tight deadlines.Attention to detail and a high level of data accuracy and integrity.Self-starter with the ability to effectively influence and communicate, build strong relationships, and become a trusted advisor and change agent.REQUIRED KNOWLEDGE, SKILLS, OR ABILITIES:Experienced Workday superuser with deep understanding of people analytics and PRISM modules. Ability to move quickly from big picture thinking and manage relevant detail. Demonstrated desire to challenge the status quo and “how it is always been done” to drive the team to new ways of thinking and processes. Has passion for the restaurant industry and excitement for learning about restaurant operations.Strong communicator can work collaboratively across the enterprise and effectively manage expectations across distributed stakeholders.Maintains flexibility and influences others to do the same.Equal Employment Opportunity Policy:It is the policy of Inspire Brands Inc.™ (“IRB” or the “Company”) to treat all employees and applicants for employment fairly and to provide equal employment opportunities without regard to race, color, sex, religion, national original or ancestry, ethnicity, sexual orientation, gender identity, age, disability, genetic information, citizenship, military service or veteran status, marital status or any other characteristic protected under applicable federal, state, or local law. This policy applies to all employment practices including recruiting, hiring, placement, pay, promotions, transfers, training, leaves of absence, and termination. Inspire Brands, Inc. expressly prohibits any form of unlawful employment harassment based on race, color, sex, religion, national original or ancestry, ethnicity, sexual orientation, gender identity, age, disability, genetic information, citizenship, military service or veteran status, marital status or any other characteristic protected under applicable federal, state, or local law. Improper interference with the ability of IRB’s employees to perform their expected job duties will not be tolerated.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology and Engineering",
      "Industries": "Restaurants"
    },
      "skills": [
        "Statistics",
        "Tableau",
        "Power BI",
        "Data Visualization",
        "Metrics",
        "Analytics",
        "Workday",
        "PRISM",
        "Excel",
        "Data Mining"
      ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_021"
  },
  {
    "job_id": "data-analyst-at-tata-consultancy-services-4322750798",
    "title": "Data Analyst",
    "company": "Tata Consultancy Services",
    "location": "Hyderabad, Telangana, India",
    "posted_date": "2025-11-15",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-tata-consultancy-services-4322750798?position=13&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=hAKYPSctBp1qL0l%2FasAW8Q%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793355",
    "description": "🚀 TCS Hyderabad is Hiring! Looking for experienced professionals to join our IT Infrastructure team and shape the future with us.📍 Location: Tata Consultancy Services Limited, 2S2 Zone, Deccan Park Office,Plot No 1, Deccan Park, Software Units Layout, Hitech City, Madhapur-500081. Software Units Layout, Hitech City, Hyderabad📅 Drive Date: Saturday,22nd November 2025⏰ Time: 09:30 AM – 12:30 PM🎓 Eligibility: Graduate / Post-Graduate 15+ years of regular full-time education Excellent communication skills📌 Please carry: Updated Resume Government ID + photocopy 1 Passport size photograph🔗 Apply Here: https://ibegin.tcs.com/candidate/jobs/searchAzure Fullstack Dotnet: – Job ID: 381058| Exp: 4–12 Years1) Build, monitor, schedule ADF pipelines2) Develop PowerBI reports/metrics with good workexp of developing DAX queries3) Proficient in SQL queries, filter, joins, group bys, sub queries, indexing, optimization etc.4)Design, develop, and maintain data pipelines and ML models using Azure services like Azure Data Factory, Databricks, Synapse Analytics and Azure Machine Learning.5)Build and optimize data models for analytics and reporting, ensuring high data quality and performance.6)Collaborate with business stakeholders to gather requirements, create dashboards, and deliver actionable insights using Power BI or similar tools.7)Ensure security, governance, and automation of data processes while troubleshooting and optimizing cloud-based solutions",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "SQL",
      "Azure Data Factory",
      "Power BI",
      "DAX",
      "Databricks",
      "Synapse Analytics",
      "Azure Machine Learning",
      "Data Modeling",
      "Data Pipeline",
      "Azure"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_022"
  },
  {
    "job_id": "data-analyst-data-management-and-analytics-data-ops-data-analyst-at-exl-4332002302",
    "title": "Data Analyst-Data Management and Analytics-Data Ops/Data Analyst",
    "company": "EXL",
    "location": "Pune, Maharashtra, India",
    "posted_date": "2025-11-17",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-data-management-and-analytics-data-ops-data-analyst-at-exl-4332002302?position=15&pageNum=0&refId=zja1MRJyR%2B7UxUczOUoYCA%3D%3D&trackingId=ctNViIvqTTEWvNlaVoxBUQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793357",
    "description": "5 - 9 years of professional experience as a Data Analyst with good decision-making, analytical and problem-solving skills. Working knowledge / experience of Big Data frameworks like Hadoop, Hive and Spark. Hands-on experience in query languages like HQL or SQL (Spark SQL) for Data exploration. Data mapping: Determine the data mapping required to join multiple data sets together across multiple sources. Documentation - Data Mapping, Subsystem Design, Technical Design, Business Requirements. Exposure to Logical to Physical Mapping, Data Processing Flow to measure the consistency, etc. Data Asset design / build: Working with the data model / asset generation team to identify critical data elements and determine the mapping for reusable data assets. Understanding of ER Diagram and Data Modeling concepts Exposure to Data quality validation Exposure to Data Management, Data Cleaning and Data Preparation Exposure to Data Schema analysis. Exposure to working in Agile framework. SQL, Pyspark, Python with Wholesale Banking Domain knowledge / Credit & Lending domain knowledge. Knowledge of Credit Risk Frameworks such as Basel II, III, IFRS 9 and Stress Testing and understanding their drivers - advantageous Retail Credit / Traded Credit knowledge - applications will be considered.Good To Have BFSI Domain knowledge Data Visualization - Tableau or Qlik Sense Exposure to Hadoop, Hive and ETL. Working knowledge of any cloud services like AWS or GCP or Azure. Any relevant certifications would be a plus.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Business Consulting and Services"
    },
    "skills": [
      "Python",
      "SQL",
      "PySpark",
      "Spark SQL",
      "Hadoop",
      "Hive",
      "ETL",
      "AWS",
      "Azure",
      "GCP",
      "Data Modeling",
      "Tableau",
      "Qlik Sense",
      "Data Visualization"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_023"
  },
  {
    "job_id": "data-analyst-at-dgh-recruitment-4323055410",
    "title": "Data Analyst",
    "company": "DGH Recruitment",
    "location": "London Area, United Kingdom",
    "posted_date": "2025-11-18",
    "job_url": "https://uk.linkedin.com/jobs/view/data-analyst-at-dgh-recruitment-4323055410?position=1&pageNum=0&refId=509c4aH4OfRZZDbPpoxn2w%3D%3D&trackingId=kV5wrHNYVdBlHnEIT1QN0A%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793361",
    "description": "Data Analyst (12-month FTC)Responsible for delivering accurate, insightful reporting and dashboards for L&D and People Teams. The role involves translating complex data into actionable insights, ensuring data quality, and supporting strategic decision-making.Key Responsibilities:Develop and maintain reports, dashboards, and presentations using tools like Power BI and Excel.Collaborate with stakeholders to understand reporting needs and deliver scalable solutions.Ensure data accuracy and compliance with governance standards (e.g., GDPR).Provide BAU and ad hoc analytics for initiatives, audits, and surveys.Act as a subject matter expert on people data and proactively resolve data quality issues.Skills & Experience:Minimum 1 year in L&D / people data analytics.Advanced Excel and Power BI skills; familiarity with Cornerstone, Workday, SQL, and Power Automate desirable.Strong analytical, organisational, and communication skills.Ability to manage multiple priorities and present data effectively.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Contract",
      "Job function": "Information Technology and Human Resources",
      "Industries": "Information Services, Technology, Information and Media, and Data Infrastructure and Analytics"
    },
    "skills": [
      "SQL",
      "Power BI",
      "Excel",
      "Workday"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_024"
  },
  {
    "job_id": "data-analyst-at-haystack-4323115216",
    "title": "Data Analyst",
    "company": "Haystack",
    "location": "United Kingdom",
    "posted_date": "2025-11-18",
    "job_url": "https://uk.linkedin.com/jobs/view/data-analyst-at-haystack-4323115216?position=2&pageNum=0&refId=509c4aH4OfRZZDbPpoxn2w%3D%3D&trackingId=4yVwOJqk2Mf0qNUjmNhYmQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793365",
    "description": "🔬 Data Scientist, United Kingdom - BCG X (Partnered with Haystack)Haystack is partnering with Boston Consulting Group (BCG) to find a high-impact Data Scientist for their innovative tech-build and design unit, BCG X.Location: London (Remote or Hybrid Options Available)Role Type: Permanent (Full-Time)Career Level: Mid-Senior LevelAbout BCG XBCG X is the tech build and design unit of Boston Consulting Group. We are a global team of experts combining industry expertise with cutting-edge technology to build game-changing products and services. Join us to apply data science to solve complex challenges, including climate change and digital transformation.The OpportunityAs a Data Scientist, you will own the full analytics value-chain end-to-end, driving measurable business impact across diverse industries.Design & Deployment: Design, implement, and deploy innovative algorithms and machine learning solutions.Client Engagement: Act as a subject matter expert in a client-facing role, effectively translating complex data science into clear business strategies for leadership.End-to-End Ownership: Frame business challenges, implement scalable solutions, and ensure client adoption of AI technologies.Contribution: Contribute to thought leadership and technical community engagement on behalf of BCG X.Candidate ProfileWe seek intellectually curious builders who are biased toward action and possess a strong foundation in advanced analytics.Essential Qualifications:Education: Master’s degree or PhD in a relevant field (e.g., Data Science, Statistics, Operations Research).Programming: Professional proficiency in Python.Technical Depth: Deep understanding of modern machine learning techniques and their mathematical foundations.Experience: Significant experience applying advanced analytics to complex business problems in a professional setting.Communication: Strong ability to synthesize complex data, visualize results simply, and communicate technical concepts clearly.Why Join BCG X?Impact-driven work on mission-critical projects globally.Flexible working options (Remote or Hybrid, based in London).Be part of an innovative and collaborative global firm.BCG is an Equal Opportunity Employer.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Machine Learning",
      "Statistics"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251120_025"
  },
  {
    "job_id": "senior-data-engineer-at-cube-4320435637",
    "title": "Senior Data Engineer",
    "company": "CUBE",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-03",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-data-engineer-at-cube-4320435637?position=18&pageNum=0&refId=Fi4jCelatrIqjKj83VAVpQ%3D%3D&trackingId=75KBBIyt%2BDf46LVbbarJXQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793380",
    "description": "CUBE are a global RegTech business defining and implementing the gold standard of regulatory intelligence for the financial services industry. We deliver our services through intuitive SaaS solutions, powered by AI, to simplify the complex and everchanging world of compliance for our clients.Why us?🌍 CUBE is a globally recognized brand at the forefront of Regulatory Technology. Our industry-leading SaaS solutions are trusted by the world’s top financial institutions globally.🚀 In 2024, we achieved over 50% growth, both organically and through two strategic acquisitions. We’re a fast-paced, high-performing team that thrives on pushing boundaries—continuously evolving our products, services, and operations. At CUBE, we don’t just keep up we stay ahead.🌱 We believe our future is built by bold, ambitious individuals who are driven to make a real difference. Our “make it happen” culture empowers you to take ownership of your career and accelerate your personal and professional development from day one.🌐 With over 700 CUBERs across 19 countries spanning EMEA, the Americas, and APAC, we operate as one team with a shared mission to transform regulatory compliance. Diversity, collaboration, and purpose are the heartbeat of our success.💡 We were among the first to harness the power of AI in regulatory intelligence, and we continue to lead with our cutting-edge technology. At CUBE, You will work alongside some of the brightest minds in AI research and engineering in developing impactful solutions that are reshaping the world of regulatory compliance.Role MissionAs a Senior Data Engineer, your mission is to architect, build, and optimize scalable and secure data pipelines and infrastructure to support advanced analytics, business intelligence, and data science initiatives. Leveraging technologies like Microsoft Fabric, Apache Spark, Python, and SSIS, you will be instrumental in transforming raw data into actionable insights that drive business performance.Key ResponsibilitiesDesign & Development: Build robust ETL pipelines and scalable data solutions using Microsoft Fabric (Data Engineering, Data Factory, OneLake), Python, Apache Spark, and SSIS.Data Integration: Develop reliable data integration frameworks that consolidate structured and unstructured data from various sources, ensuring high-quality and consistent datasets.Data Processing & Transformation: Create and optimize data transformation logic using Python, Spark SQL, and PySpark to support complex analytical workloads.Infrastructure Optimization: Monitor, troubleshoot, and enhance the performance, scalability, and resilience of data pipelines and infrastructure.Collaboration: Work closely with data scientists, analysts, and business stakeholders to gather data requirements and deliver efficient and secure data solutions.Data Modeling: Design data models (relational and dimensional) that support operational processes and business reporting needs.Governance & Compliance: Implement and uphold data governance, quality, and security standards across all systems and processes.Documentation & Mentoring: Maintain thorough documentation of data architecture, pipelines, and workflows. Mentor junior data engineers and contribute to knowledge-sharing across the team.Required Skills & QualificationsEducation: Bachelor’s degree in Computer Science, Engineering, or a related discipline (Master’s degree preferred).Experience: 5-8 years in data engineering or related roles.Core Technologies:Expertise in Microsoft Fabric ecosystem (Data Factory, OneLake, Azure Synapse).Strong programming experience with Python for data manipulation and scripting.Proven experience in developing and maintaining ETL workflows using SSIS.Solid experience with Apache Spark (Spark SQL, PySpark).Database Proficiency:Strong SQL skills with hands-on experience in SQL Server.Exposure to both SQL and NoSQL databases.DevOps & Version Control: Experience with Git and CI/CD tools and practices.Data Modeling: Proficiency in designing relational and dimensional data models.Governance: Understanding of data governance, privacy, and security principles.Soft Skills: Strong analytical thinking, problem-solving ability, and effective communication in cross-functional teams.Preferred QualificationsExperience with real-time streaming technologies (e.g., Kafka).Familiarity with data visualization tools such as Power BI.Hands-on experience with containerization (Docker, Kubernetes).Cloud platform experience, especially with Azure.Microsoft/Azure certifications in data engineering or analytics.Experience working on ML data pipelines or in support of data science teams.Interested?If you are passionate about leveraging technology to transform regulatory compliance and meet the qualifications outlined above, we invite you to apply. Please submit your resume detailing your relevant experience and interest in CUBE.CUBE is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "SQL",
      "SQL Server",
      "NoSQL",
      "Data Modeling",
      "Azure Synapse",
      "Azure Data Factory",
      "Microsoft Fabric",
      "OneLake",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "Git",
      "Apache Spark",
      "PySpark",
      "Spark SQL",
      "Kafka",
      "SSIS",
      "ETL",
      "Data Integration",
      "Data Transformation",
      "Power BI",
      "Containerization"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_006"
  },
  {
    "job_id": "data-engineer-solution-architect-at-therighttalent-4322125938",
    "title": "Data Engineer & Solution Architect",
    "company": "Therighttalent",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-13",
    "job_url": "https://lk.linkedin.com/jobs/view/data-engineer-solution-architect-at-therighttalent-4322125938?position=44&pageNum=0&refId=Fi4jCelatrIqjKj83VAVpQ%3D%3D&trackingId=hvD%2Fdm3lBbpFgEmqGJ5yuQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793394",
    "description": "About Our Client PartnerOur client is a leading, diversified conglomerate with major operations spanning in diverse industries. The organization is undergoing a significant digital and AI transformation, establishing a robust data foundation to power enterprise-wide decision-making and next-generation analytics. This role sits within a centralized Group function, responsible for designing and building the scalable, cloud-native data platforms that connect business data to strategic insights.Role SummaryWe are seeking an experienced Data Engineer & Solution Architect to lead the design, construction, and optimization of the Group's enterprise data platform and ETL/ELT pipelines. This pivotal role will define the technical architecture for the movement and storage of data, ensuring it is readily available, governed, and performant for consumption by the Group AI & Advanced Analytics team and various business applications. The Architect will bridge the gap between business requirements and scalable cloud infrastructure.Key ResponsibilitiesData Architecture and Platform DesignDesign and implement the Group-wide, cloud-native data architecture (e.g., Data Lake, Data Warehouse, Data Mesh principles) to support analytics, reporting, and Machine Learning workloads.Define technical standards and best practices for data storage, security, quality, and governance across all data assets.Select and evaluate technologies for the data stack, ensuring compatibility with major cloud platforms (e.g., Azure/AWS/GCP).Data Pipeline Development (ETL/ELT)Build, manage, and optimize scalable ETL/ELT pipelines to ingest data from diverse source systems (e.g., SAP ERP, CRM, operational databases) into the centralized data platform.Implement robust data quality checks, monitoring, and error handling within data pipelines.Utilize modern data processing frameworks (e.g., Spark, Databricks) and orchestration tools (e.g., Airflow) for automation and efficiency.Solution Architecture and IntegrationAct as the technical Solution Architect for analytics projects, translating data science models (from the AI team) and business requirements into concrete data flow designs and production-ready deployments.Ensure seamless integration between the core data platform and consumption layers, including BI tools (Power BI), internal APIs, and front-end applications.Partner with IT and Security teams to ensure all data solutions meet enterprise-level security and compliance standards.Mentorship and DocumentationProvide technical leadership and mentorship to junior data engineers, fostering skills in cloud data services and modern data modeling techniques.Develop and maintain comprehensive technical documentation, including data dictionaries, platform diagrams, and ETL/ELT process flows.RequirementsExperience: Typically 5-8 years of experience in Data Engineering, Data Architecture, or a related role, with proven experience designing and deploying end-to-end data solutions in a cloud environment.Technical Expertise:Programming: Advanced proficiency in SQL and Python is mandatory.Cloud: Hands-on experience designing and operating services in at least one major cloud platform (Azure preferred, AWS, or GCP), specifically involving data services (e.g., Azure Data Factory, Azure Synapse, S3/Redshift).Data Modeling: Strong expertise in relational and non-relational database design and modern data modeling techniques (e.g., dimensional modeling, Data Vault).Systems Knowledge: Familiarity with enterprise systems, particularly SAP ERP data structures, is highly desirable.Education: Bachelor’s or Master’s degree in Computer Science, Engineering, Information Systems, or a related quantitative field.Attributes: Strong analytical and problem-solving skills, excellent communication abilities to clearly articulate technical designs to both technical and business stakeholders.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology, Other, and Project Management",
      "Industries": "Software Development, Information Services, and IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "SQL",
      "Redshift",
      "Databricks",
      "Data Modeling",
      "Database Design",
      "AWS",
      "Azure",
      "GCP",
      "S3",
      "Azure Synapse",
      "Azure Data Factory",
      "Data Lake",
      "Vault",
      "Airflow",
      "ETL",
      "ELT",
      "Data Pipeline",
      "Data Mesh",
      "Power BI",
      "SAP",
      "ERP",
      "CRM"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_010"
  },
  {
    "job_id": "data-network-engineer-walk-in-interview-21th-nov-at-cinnamon-life-offices-level-6-at-hcltech-sri-lanka-4340997427",
    "title": "Data Network Engineer (Walk in Interview 21th Nov at Cinnamon Life Offices, Level 6)",
    "company": "HCLTech Sri Lanka",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/data-network-engineer-walk-in-interview-21th-nov-at-cinnamon-life-offices-level-6-at-hcltech-sri-lanka-4340997427?position=48&pageNum=0&refId=Fi4jCelatrIqjKj83VAVpQ%3D%3D&trackingId=C93MM0z%2BEiXgJ%2BSvtA6vgA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793398",
    "description": "Excited for an IT career opportunity at HCLTech Sri Lanka? Join us for walk-in interviews for Network Data roles !🗓️ Mark Your Calendar: 21st Nov 2025🕙 Time: 10:00 AM – 3:00 PM📍 Where: HCL Tech, Level 06, Cinnamon Life Offices, Colombo 02Why Attend?- Meet HCLTech’s hiring team in person- Accelerate your career growth with a global tech leader- Explore a world of endless possibilities🚀 Step in, make an impression, and secure your spot! Don’t forget to bring your best self, your resume, and your aspirations. We're eager to discover talent like YOU!Please use the below link https://lnkd.in/gahuzCKU",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_011"
  },
  {
    "job_id": "data-engineer-at-lazard-4306156872",
    "title": "Data Engineer",
    "company": "Lazard",
    "location": "New York, United States",
    "posted_date": "2025-11-15",
    "job_url": "https://www.linkedin.com/jobs/view/data-engineer-at-lazard-4306156872?position=2&pageNum=0&refId=BG7%2Ffqujzdc%2FszCMaKlc0Q%3D%3D&trackingId=YRGqEtgJ%2Fc3KaZhkBHoHRg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793403",
    "description": "AmericasCorporateNew YorkLazard is one of the world’s preeminent financial advisory and asset management firms. Our people and culture make the difference. While global in presence and reach, ours is a close, collaborative community of just over 3,000 professionals. Lazard is a place of continuous knowledge sharing, skill development and relationship building, where professionals grow and succeed together. Our entrepreneurial culture, flat structure and embrace of individual differences, allow creative ideas, original concepts, and unique perspectives to drive our business forward — and for careers to take flight.The Lazard Data Analytics Group, composed of data scientists, AI engineers, and software engineers, drives innovation by developing advanced AI and data science solutions that enhance decision-making across our financial advisory and asset management business lines. This team ensures Lazard stays at the forefront of a data-driven world, delivering insights that support client engagements and strengthen key partnerships, while keeping the firm competitive and efficient in an evolving financial landscape.As a Data Engineer, you’ll lead efforts to onboard and model datasets on modern cloud data platforms, delivering reliable pipelines and high-quality data layers that serve analytics, reporting, and ML/AI workloads.We’ll trust you to: Ingest and model data from APIs, files/SFTP, and relational sources; implement layered architectures (raw/clean/serving) using PySpark/SQL and dbt, Python. Design and operate pipelines with Prefect (or Airflow), including scheduling, retries, parameterization, SLAs, and well‑documented runbooks. Build on cloud data platforms, leveraging S3/ADLS/GCS for storage and a Spark platform (e.g., Databricks or equivalent) for compute; manage jobs, secrets, and access. Publish governed data services and manage their lifecycle with Azure API Management (APIM) — authentication/authorization, policies, versioning, quotas, and monitoring. Enforce data quality and governance through data contracts, validations/tests, lineage, observability, and proactive alerting. Optimize performance and cost via partitioning, clustering, query tuning, job sizing, and workload management. Uphold security and compliance (e.g., PII handling, encryption, masking) in line with firm standards. Collaborate with stakeholders (analytics, AI engineering, and business teams) to translate requirements into reliable, production‑ready datasets. Enable AI/LLM use cases by packaging datasets and metadata for downstream consumption, integrating via Model Context Protocol (MCP) where appropriate. Continuously improve platform reliability and developer productivity by automating routine tasks, reducing technical debt, and maintaining clear documentation. You’ll need to have: Bachelor’s or advanced degree in Computer Science, Data Engineering, or a related field. 4–15 years of professional data engineering experience. Strong Python, SQL, and Spark (PySpark) skills, and/or Kafka Hands-on experience building ETL/ELT with Prefect (or Airflow), dbt, Spark, and/or Kafka. Experience onboarding datasets to cloud data platforms (storage, compute, security, governance). Familiarity with Azure/AWS/GCP data services (e.g., S3/ADLS/GCS; Redshift/BigQuery; Glue/ADF). Git-based workflows CI/CD and containerization with Docker (Kubernetes a plus). It is a bonus to have:Snowflake (Snowpipe, Tasks, Streams) as a complementary warehouse. Databricks (Delta formats, workflows, cataloging) or equivalent Spark platforms. Advanced APIM practices (custom policies, OAuth2/JWT, mTLS, private endpoints) and Azure AD integration. Integrating datasets into MCP tools/providers for LLM/agent applications; familiarity with frameworks such as LangChain or LlamaIndex. Data observability/quality tools (e.g., Great Expectations, Monte Carlo, Datafold) and strong lineage practices. Exposure to financial datasets and controls (PII handling, encryption, masking). What we offer:We strive to enhance the total health and well-being of our employees through comprehensive, competitive benefits. Our goal is to offer a highly individualized employee experience that enables you to balance your commitments to career, family, and community. When you work for Lazard, you are working for an organization that cares about your unique talents and passions and will continue to invest in the development of your career.We expect the base salary range for this role to be approximately $140,000 – $180,000 USD. Various factors contribute to determining the actual base compensation offered, including but not limited to the applicant’s years of relevant experience, career tenure, qualifications, level of education attained, certifications or other professional licenses held, relevant skills for the role. Base salary is one component of Lazard’s compensation package, which also includes comprehensive benefits and may include incentive compensation.Does this sound like you?Apply! We'll get in touch and let you know the next steps.Representation at LazardLazard is an intellectual capital business committed to delivering the best advice and solutions to clients. To achieve these objectives, we focus on attracting, developing and retaining the best talent. We believe that a workforce comprised of people who represent a wide array of backgrounds, experiences and perspectives creates a rich variety of thought that empowers us to challenge conventional wisdom, solve problems creatively and make better decisions.Lazard was built on the premise that a multicultural firm can best serve a global clientele. As a global firm that has grown organically from local roots in different countries, we have a deep tradition of respecting and appreciating individual differences. Doing so has been core to our success for over 175 years. We are committed to sustaining an environment where every colleague is supported in their professional pursuits, can maximize their individual potential and contribute to our collective success.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "Python",
      "SQL",
      "Snowflake",
      "BigQuery",
      "Redshift",
      "Databricks",
      "AWS",
      "Azure",
      "GCP",
      "S3",
      "Azure AD",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "Git",
      "PySpark",
      "Kafka",
      "Airflow",
      "Prefect",
      "dbt",
      "ETL",
      "ELT"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_015"
  },
  {
    "job_id": "data-engineer-go-to-market-at-google-4323267394",
    "title": "Data Engineer, Go-To-Market",
    "company": "Google",
    "location": "New York, NY",
    "posted_date": "2025-11-19",
    "job_url": "https://www.linkedin.com/jobs/view/data-engineer-go-to-market-at-google-4323267394?position=4&pageNum=0&refId=BG7%2Ffqujzdc%2FszCMaKlc0Q%3D%3D&trackingId=j1dYb6Y9%2FuIpKHac3vLxfA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793406",
    "description": "The application window will be open until at least November 26, 2025. This opportunity will remain online based on business needs which may be before or after the specified date.This role may also be located in our Playa Vista, CA campus.Applicants in the County of Los Angeles: Qualified applications with arrest or conviction records will be considered for employment in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.Applicants in San Francisco: Qualified applications with arrest or conviction records will be considered for employment in accordance with the San Francisco Fair Chance Ordinance for Employers and the California Fair Chance Act.Note: By applying to this position you will have an opportunity to share your preferred working location from the following: New York, NY, USA; Atlanta, GA, USA; Boulder, CO, USA; Chicago, IL, USA; Mountain View, CA, USA; Los Angeles, CA, USA; San Francisco, CA, USA.Minimum qualifications:Bachelor’s degree in Engineering, Computer Science, a related field, or equivalent practical experience.1 year of experience in designing data pipelines (extract transform and load) and model data, for synch and asynch system integration and implementation.1 year of experience in coding with one or more programming languages (e.g., Python, Java, C/C++).1 year of experience in analyzing data, database querying (e.g., SQL), and creating dashboards/reports.Preferred qualifications:Master’s degree in Engineering, Computer Science, Business, or a related field.1 year of experience partnering with stakeholders (e.g., users, partners, customers).Experience with data visualizations and business intelligence tools.Experience with statistical analysis and modeling.Experience in an ad sales, ad support, finance, data science, or strategy and operations role.About The JobThe Go-To-Market Product Data Warehouse team tracks adoption of ads and measurement products and features. This is used to generate lead lists, analyze the value of various features, set priorities for sales teams, and to help influence the direction of Ads products. Our goal is to organize and produce data that is thoughtful, useful to sales teams, and widely accessible. You will also find our work in sales analytical leads' database scripts, in the weekly executive leadership meetings, and referenced in Ads annual plans.As a Data Engineer, you will monitor the measurement, audience and data products by developing Key Performance Indicators (KPIs), data pipelines, dashboards, and doing ad-hoc analysis to derive insights and opportunities. You will work cross-functionally with global product leads, Go-to-Market, sales, etc.The US base salary range for this full-time position is $102,000-$146,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .ResponsibilitiesDrive Ads and measurement feature adoption by developing scalable, shareable sales tools, dashboards, data, and programs using F1 query engine, and other tools to support key resources like connect sales.Synthesize advertiser data and conduct analyses to deliver insights and actionable recommendations for product and sales leadership.Define and prioritize KPIs to drive key global initiatives that will be used by regions, countries, and sales in all sales channels.Be a strategic thought partner to commercial leaders of products like Marketing Mix Modeling (MMM).Handle special projects as assigned.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Project Management, Consulting, and Engineering",
      "Industries": "Information Services and Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "SQL"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_017"
  },
  {
    "job_id": "data-engineer-iii-t500-19720-at-mcdonald-s-4312072305",
    "title": "Data Engineer III [T500-19720]",
    "company": "McDonald's",
    "location": "Hyderabad, Telangana, India",
    "posted_date": "2025-11-07",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-iii-t500-19720-at-mcdonald-s-4312072305?position=1&pageNum=0&refId=HD3bVeatgcLS4sTJUD5fhw%3D%3D&trackingId=fvgR2UeTcsQXSx27i89aIw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793410",
    "description": "About McDonald’s:One of the world’s largest employers with locations in more than 100 countries, McDonald’s Corporation has corporate opportunities in Hyderabad. Our global offices serve as dynamic innovation and operations hubs, designed to expand McDonald's global talent base and in-house expertise. Our new office in Hyderabad will bring together knowledge across business, technology, analytics, and AI, accelerating our ability to deliver impactful solutions for the business and our customers across the globe.Who we are looking for:Primary Responsibilities:Builds and maintains relevant and reliable data products that support Finance Analytics. Develops and implements new technology solutions as needed to ensure ongoing improvement with data reliability and observability in-view.Participates in new software development and data engineering initiatives supporting Finance Analytics, ensuring timely and accurate delivery of financial data products.Drive and implement best Data Engineering practices for pipeline development, data governance, data security and quality across financial datasets.Implement security and privacy controls in data workflows, ensuring compliance with finance regulatory requirements.Monitor, troubleshoot, and improve performance and reliability of existing finance data pipeline infrastructure.Staying up to date with emerging data engineering technologies, trends, and best practices, and evaluating their applicability to meet evolving financial analytics needs.Documenting data engineering processes, workflows, and solutions for knowledge sharing and future reference. Partner and collaborate with data engineers, particularly in finance-centric data models and processing frameworks.Ability and flexibility to coordinate and work with teams distributed across time zones, as needed.Skill:Applies technical data engineering expertise to develop reliable pipelines and improve data quality in support of finance and analytics initiativesBachelor's or master's degree in computer science or related engineering field and deep experience with Cloud computing3+ years of professional experience in data engineering or related fieldsProficiency in Python, Java, or Scala for data processing and automationHands-on experience with data orchestration tools (e.g., Apache Airflow, Luigi) and big data ecosystems (e.g., Hadoop, Spark, NoSQL)Good working knowledge of Data quality functions like cleansing, standardization, parsing, de-duplication, mapping, hierarchy management, etc.Ability to perform extensive data analysis (comparing multiple datasets) using a variety of toolsEffective communication and stakeholder management skills to drive alignment and adoption of data engineering standardsDemonstrated experience in data management & data governance capabilitiesFamiliarity with data warehousing principles and best practices.Excellent problem solver - use of data and technology to solve problems or answer complex data related questionsExcellent collaboration skills to work effectively in cross-functional teamsWork location: Hyderabad, IndiaWork hours: Work pattern: Full time role.Work mode: Hybrid.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology and Engineering",
      "Industries": "Restaurants"
    },
    "skills": [
      "Python",
      "Java",
      "Scala",
      "NoSQL",
      "Hadoop",
      "Airflow",
      "Luigi",
      "Data Pipeline",
      "Data Warehousing",
      "Big Data",
      "Data Governance",
      "Data Quality",
      "Data Orchestration"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_024"
  },
  {
    "job_id": "data-engineer-at-albert-invent-4341328373",
    "title": "Data Engineer",
    "company": "Albert Invent",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-18",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-at-albert-invent-4341328373?position=3&pageNum=0&refId=HD3bVeatgcLS4sTJUD5fhw%3D%3D&trackingId=bgawPfvqJ4jT8UkuyQHgTg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793420",
    "description": "Responsibilities Develop, and maintain SQL and NoSQL databases, ensuring high performance, scalability, andreliability. Collaborate with the API team and Data Science team to build robust data pipelines andautomations. Work closely with stakeholders to understand database requirements and provide technicalsolutions. Optimize database queries and performance tuning to enhance overall system efficiency. Implement and maintain data security measures, including access controls and encryption. Monitor database systems and troubleshoot issues proactively to ensure uninterruptedservice. Develop and enforce data quality standards and processes to maintain data integrity. Create and maintain documentation for database architecture, processes, and procedures. Stay updated with the latest database technologies and best practices to drive continuousimprovement. Expertise in SQL queries and stored procedures, with the ability to optimize and fine-tunecomplex queries for performance and efficiency. Experience with monitoring and visualization tools such as Grafana to monitor databaseperformance and healthRequirements Bachelor’s degree in Computer Science, Engineering, or equivalent experience 2+ years of experience in data engineering, with a focus on large-scale data systems. Proven experience designing data models and access patterns across SQL and NoSQLecosystems. Hands-on experience with technologies like SQL, DynamoDB, S3, and Lambda services. Proficient in SQL stored procedures with extensive expertise in MySQL schema design, queryoptimization, and resolvers, along with hands-on experience in building and maintaining datawarehouses. Strong programming skills in Python or JavaScript, with the ability to write efficient,maintainable code. Familiarity with observability stacks (Prometheus, Grafana, Open Telemetry) and debuggingproduction bottlenecks. Understanding cloud infrastructure (preferably AWS), including networking, IAM, and costoptimization. Excellent communication and collaboration skills to influence cross-functional technicaldecisions.Skills:- Python, SQL, AWS Lambda, Snow flake schema and Amazon Redshift",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "JavaScript",
      "SQL",
      "MySQL",
      "DynamoDB",
      "Redshift",
      "NoSQL",
      "AWS",
      "S3",
      "Lambda",
      "Prometheus",
      "Grafana",
      "IAM",
      "Encryption",
      "Networking"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_026"
  },
  {
    "job_id": "junior-data%C2%A0engineer-at-uptitude-4323174686",
    "title": "Junior Data Engineer",
    "company": "UPTITUDE",
    "location": "Gurugram, Haryana, India",
    "posted_date": "2025-11-18",
    "job_url": "https://in.linkedin.com/jobs/view/junior-data%C2%A0engineer-at-uptitude-4323174686?position=5&pageNum=0&refId=HD3bVeatgcLS4sTJUD5fhw%3D%3D&trackingId=MmYJauNjM33LRIkiGbGDfw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793427",
    "description": "Job Description: Data EngineerAre you passionate about data engineering and solving real-world problems with clean, scalable pipelines? Do you enjoy working in a fast-paced and dynamic start-up environment? If so, we’re looking for talented Data Engineers across all experience levels to join our team at Uptitude! This is a full-time role based on-site in our energetic and fun office in Gurugram, India.Junior Data Engineer (1–3 years of experience)1-3 years working in a data engineering, analytics, or software development role.Experience designing and maintaining data pipelines using Python, SQL, and either Azure Data Factory, Databricks, Synapse, or other Azure services.Familiarity with data warehousing, data lake architecture, and data integration challenges.Proactive problem-solving skills: ability to diagnose and resolve technical issues independently.Demonstrated ability to learn new tools/frameworks quickly and apply them in projects.Version control familiarity (Git/DevOps practices).Clear communication and documentation skills for technical and business audiences.Strong ownership, willingness to step up on team projects.About UptitudeUptitude is a forward-thinking consultancy that specialises in providing exceptional data, AI, and business intelligence solutions to clients worldwide. Headquartered in London, UK, and powered by teams across India and Europe, we’re committed to empowering businesses with data-driven insights that spark action and growth. At Uptitude, innovation, excellence, and collaboration are at the heart of everything we do.Your RoleAs a Data Engineer at Uptitude, you’ll be responsible for designing, developing, and optimising data pipelines and data infrastructure that empower analytics, machine learning, and operational reporting. You’ll collaborate closely with analysts, BI engineers, data scientists, and business stakeholders to build the backbone of our clients’ data capabilities.Company ValuesAt Uptitude, we embrace a set of core values that guide our work and define our culture.Be Awesome: Strive for excellence in everything you do, continuously improving your skills and delivering exceptional results.Step Up: Take ownership of challenges, be proactive, and seek opportunities to contribute beyond your role.Make a Difference: Embrace innovation, think creatively, and contribute to the success of our clients and the company.Have Fun: Foster a positive and enjoyable work environment, celebrating achievements and building strong relationships.BenefitsUptitude values its employees and offers a competitive benefits package, including:Competitive Salary Commensurate With Experience And Qualifications.Private health insurance coverage.Offsite trips to encourage team building and knowledge sharing.Quarterly team outings to unwind and celebrate achievements.Corporate English Lessons with UK instructorWe are a fast-growing company with a global client base, so this is an excellent opportunity for the right candidate to grow and develop their skills in a dynamic and exciting environment.Apply now to become part of a team that’s transforming data into opportunity.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "SQL",
      "Databricks",
      "Azure",
      "Azure Data Factory",
      "Data Factory",
      "Data Lake",
      "Git",
      "Data Warehousing",
      "Data Integration"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_028"
  },
  {
    "job_id": "data-engineer-python-sql-spark-etl-at-staples-india-4323033705",
    "title": "Data Engineer (Python, SQL, Spark, ETL)",
    "company": "Staples India",
    "location": "Chennai, Tamil Nadu, India",
    "posted_date": "2025-11-18",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-python-sql-spark-etl-at-staples-india-4323033705?position=7&pageNum=0&refId=HD3bVeatgcLS4sTJUD5fhw%3D%3D&trackingId=B2ffDQeaI4b1f2sgOXYtzw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793433",
    "description": "Minimum Years of Experience 3-5 years in Python and SQL programming, ETL 2+ years in Spark, data visualization Duties and Responsibilities: Data processing: data querying, analysis and validation Build, optimize and maintain data flows within data warehouses, storage and cloud environments. Data Modeling: Design scalable data pipeline schemas and architecture. Deploy and monitor data pipelines in production.RequirementsBasic Qualification: Bachelor’s degree in computer science, Information Systems, Engineering, or a related field Proficient in Python, SQL, and Spark/PySpark. Design, develop, and maintain efficient and scalable data pipelines for both batch and real-time processing. Build and manage data integration workflows between internal and external data sources. Implement and optimize data models, schemas, and storage structures for analytics and reporting. Collaborate with data scientists, analysts, and business teams to ensure data availability, quality, and reliability. Develop and enforce data quality, governance, and security best practices. Automate data ingestion, transformation, and validation processes. Deploy and monitor data pipelines in cloud environments (Azure, GCP). Support data infrastructure scalability, performance tuning, and cost optimization. Document data flow processes, architecture, and best practices. Preferred Qualification: Knowledge in Machine Learning and AI engineering. MLOPs in Databricks",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Retail"
    },
    "skills": [
      "Python",
      "SQL",
      "Databricks",
      "PySpark",
      "ETL",
      "Data Pipeline",
      "Data Integration",
      "Azure",
      "GCP",
      "Data Modeling",
      "MLOps"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251120_030"
  },
  {
    "job_id": "senior-devops-engineer-at-qlub-4322000594",
    "title": "Senior DevOps Engineer",
    "company": "qlub",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-10",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-qlub-4322000594?position=4&pageNum=0&refId=cwjO1pdVhjZgV7Z0gf3YlA%3D%3D&trackingId=q6bKWGReSA4QwsS1cqfxTw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793445",
    "description": "Why qlubQlub is revolutionizing the dining experience with ultra-fast, seamless payment solutions. Our technology enables customers to pay in seconds by scanning a QR code – no app download required. From Pay-at-Table QR payments and Digital Menus to Order-and-Pay tech, Payment Links, and SoftPOS terminals, qlub streamlines the entire payment process, making it faster and more convenient for both diners and restaurants. Plus, splitting the bill with friends has never been easier!We help restaurants focus on what they do best: providing exceptional dining experiences. By removing payment hassles, we increase table turnover and improve operational efficiency, boosting profits. Features like analytics, instant tipping and reviews, and automated accounting empower restaurants to thrive in today’s digital-first world.We’re a fast-scaling fintech start up transforming payment solutions that go beyond the normal payment methods. Backed by leading investors including Mubadala, E&, Shorooq & Mastercard we have just secured a $30 million investment to drive our next phase of growth - this makes our total raised capital $72 million! This marks one of the largest start up investment rounds in the Middle East — and this is just the beginning. Over the past year, we’ve nearly doubled in size, expanded globally, and continue to grow our network of clients and partners, with our GMV reaching 3x!This is more than a job, this is a mission to transform qlub and power its growth, we’re building high-performing, diverse teams—and that’s where you come in!The role?We are looking for a Senior DevOps Engineer with deep experience in cloud infrastructure and tooling, who will play a key role in scaling our systems and improving our developer and monitoring experience. You will work closely with cross-functional teams to design, build, and maintain the infrastructure that powers our global platform. As a Senior DevOps Engineer you’ll be responsible for:Owning and managing cloud infrastructure across AWS and/or GCPDeveloping and maintaining CI/CD pipelines using GitHub Actions, ArgoCD, and GitOps practicesDesigning, deploying, and managing Kubernetes clusters and Helm chartsSetting up and maintaining observability stacks, including Prometheus, Thanos, and GrafanaMaintaining and enhancing centralized logging systems (e.g., Loki, ELK, or similar)Collaborating with developers to ensure high system reliability and performanceChampioning Infrastructure as Code (IaC) best practices using Terraform or similar toolsContributing to internal tooling and automation via scripting (Python preferred; Go is a plus)What are we looking for?Relevant IT degree;Fluency in English is a must;3-4+ years previous experience Proven experience as a DevOps Engineer, preferably in a high-growth SaaS or product environmentStrong knowledge of monitoring and observability tools: Prometheus, Thanos, GrafanaExperience building and maintaining logging systems (e.g., Loki)Solid hands-on experience with Kubernetes, Helm, DockerStrong proficiency with Infrastructure as Code (e.g., Terraform)Familiarity with GitOps tools and principles (e.g., ArgoCD)Proficient in Python or Bash scripting; knowledge of Go is a big plusStrong understanding of cloud-native services (e.g., ECS, EC2, ALB, GKE, RDS, Route53)Excellent communication and collaboration skills in English Proactive, accountable, and driven by outcomesA builder mindset with the desire to make a measurable impactWhat We OfferBe part of an exciting, fast-paced environment, where you can grow the business from an early-stage start-up into a global organizationDrive growth and tailoring of fast-evolving new products and featuresWork with highly motivated people, enthusiastic about improving the customer experience at table-service restaurants.Sounds like you? Are you excited by this opportunity? If so, “Apply now”.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "AWS",
      "GCP",
      "EC2",
      "RDS",
      "Kubernetes",
      "CI/CD",
      "Terraform",
      "GitHub",
      "GitHub Actions",
      "ArgoCD",
      "Helm",
      "Prometheus",
      "Grafana",
      "Loki",
      "Infrastructure as Code",
      "IaC",
      "GitOps",
      "Docker"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_002"
  },
  {
    "job_id": "devops-engineer-at-lseg-4338141523",
    "title": "DevOps Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-07",
    "job_url": "https://lk.linkedin.com/jobs/view/devops-engineer-at-lseg-4338141523?position=5&pageNum=0&refId=cwjO1pdVhjZgV7Z0gf3YlA%3D%3D&trackingId=2wbRs75yYdwmEwxKrkd0SA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793450",
    "description": "Position SummaryDevOps Engineer is a technical operations engineer with more than one year of experience having a foundation and experience in DevOps infrastructure and automation. The ideal candidate will work closely with multi-functional teams to implement, test, maintain and deploy different DevOps tools and carryout Non-functional testing such as Fault tolerance and Performance testing.Role ResponsibilitiesHelp configure DevOps tools (Continues Integration and Continues Delivery) for the team and monitor the DevOps infrastructure.Involve in operational cycle design, implementation and automation of the Millennium application.Plan and implement performance, fault tolerance, security and operational testing of the systems by way of automated test suits.Evaluate various tools as guided by the line manager.Required Skills and Experience:Preferred Skills And ExperienceBachelor’s Degree from a recognised university or equivalent.One year or more experience in a similar capacity.Moderate scripting (e.g. Python) and automation skills.Basic skills in at least one object-oriented programming language (Eg: Java).Exposure to Linux based development environments.Experience in DevOps Engineering including automation experience with configuration management tools.Experience in cloud technologies will be an additional advantage.Experience in CI/CD processes and Agile.Ability to communicate efficiently to audiences with differing levels of domain expertise (presentations, reports, justification).Meticulous individual with the ability to rapidly learn new concepts and technologies.Strong problem-solving skills, including providing simple solutions to complex situations.Strong teammate.Strong interpersonal skills and attention to detail with the ability to prioritize efficiently, balance multiple objectives under tight deadlines, identify/ flag/resolve potential issues early on.Takes initiative and demonstrates a high level of passion.Our Purpose and ValuesOur purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth. Underpinning our purpose, our values of Integrity, Partnership, Excellence and Change set the standard for everything we do, every day. They guide the way we interact with each other, the partners we work with and our customers. Delivering on our purpose and living up to our values is a responsibility that we all share.Integrity: We stand by our principles and deliver on our promises. We earn trust by acting responsibly.Partnership: Our open model is integral to how we do business. We forge long-term relationships; we work together to solve evolving needs and deliver strategic outcomes.Excellence: Our breadth of capabilities sets us apart, globally. We achieve industry leading outcomes by combining unique, diverse perspectives and knowledge across markets.Change: We embrace change. We combine human ingenuity, technology, risk management, and insight to create the products and services that lead and shape the industry.Our People:People are at the heart of what we do and drive the success of our business. Our values of Integrity, Partnership, Excellence and Change shape how we think, how we do things and how we help our people fulfil their potential. We embrace diversity and actively seek to attract individuals with unique backgrounds and perspectives. We break down barriers and encourage teamwork, enabling innovation and rapid development of solutions that make a difference. Our workplace generates an enriching and rewarding experience for our people and customers alike. Our vision is to build an inclusive culture in which everyone feels encouraged to fulfil their potential.We know that real personal growth cannot be achieved by simply climbing a career ladder - which is why we encourage and enable a wealth of avenues and interesting opportunities for everyone to broaden and deepen their skills and expertise. As a global organisation spanning 65 countries and one rooted in a culture of growth, opportunity, diversity and innovation, LSEG is a place where everyone can grow, develop and fulfil your potential with meaningful careers.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "CI/CD",
      "Linux"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_003"
  },
  {
    "job_id": "senior-devops-engineer-at-acuity-knowledge-partners-4323394170",
    "title": "Senior DevOps Engineer",
    "company": "Acuity Knowledge Partners",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-acuity-knowledge-partners-4323394170?position=12&pageNum=0&refId=cwjO1pdVhjZgV7Z0gf3YlA%3D%3D&trackingId=LgPBrgaLSuDcFMOV17CKFw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793457",
    "description": "Job ResponsibilitiesManage and maintain the lifecycle of core application suite with establishing, deploying, and maintaining CI/CD pipelines to automate the build, test, and deployment processes of application and infrastructure in cloud environment. Collaborate with development, testing, and operations teams to gather functional requirements and evaluate technologies for research, Proof of Concept and implement solutions that meet these requirements.Desired Skills And ExperienceBachelor’s degree or master’s in computer science or related field5-8 years of experience in a DevOps role preferably in Investment Banking.Experience in managing and working with Kubernetes environments and observability tools.Strong knowledge of containerization and orchestration of microservices.Experience with Docker/Podman, Helm, ArgoCD GitOps tool, Terraform.Experience with Azure Kubernetes Service, Azure Storage, Azure Redis, and other Azure cloud related technologies.Experience with Prometheus, Grafana, Loki, Tempo, Grafana Agent, Azure Monitor logging and observability tools.Bamboo CI/CD tools, Bitbucket, GIT.Automation scripting (Bash, PowerShell, Python).Be able to demonstrate a high level of professionalism, organization, self-motivation, and a desire for self-improvement.Ability to plan, schedule and manage a demanding workload.Key ResponsibilitiesOwn, manage, and maintain Azure Kubernetes Service, Azure Databricks environments hosting Credit & Swaps FO IT microservices and data lake platform.Manage and maintain the lifecycle of core application suite that provide common capabilities such as continuous deployment, observability, and Kafka streaming.Adapt to fast moving FO IT infra, application requirements and deliver innovative systems, solutions with a shorter time to market where possible.Collaborate with infra teams to provision and manage infra resources required by FO IT development teams in Azure cloud.Establish, deploy, and maintain CI/CD pipelines to automate the build, test, and deployment processes. Investigate and resolve issues related to the application infrastructure, continuous integration, and deployment pipelines.Identify areas that benefit from automation and build automated processes wherever possible.Design and develop application health dashboards, alerting and notification delivery systems to help with observability of application stack in Azure cloud.Collaborate with development, testing, and operations teams to gather, understand, and analyse functional requirements. Evaluate technologies for research, Proof of Concept and implement solutions that meet these requirements.Implement backup and disaster recovery strategies and participate in annual DR tests and assist with executing the DR test plan.Develop and utilize cost tracking tools and methodologies to provide transparent and accurate financial reporting for all projects. Identify areas where cloud spend can be optimised to reduce wastage and costs.Create and maintain documentation related to infrastructure, deployment processes, transfer knowledge among team members to remove any key man dependencies.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "Python",
      "Bash",
      "PowerShell",
      "Redis",
      "Databricks",
      "Azure",
      "Azure Storage",
      "Data Lake",
      "Docker",
      "Kubernetes",
      "CI/CD",
      "Terraform",
      "Git",
      "Bitbucket",
      "Bamboo",
      "ArgoCD",
      "Helm",
      "Prometheus",
      "Grafana",
      "GitOps",
      "Kafka",
      "Loki",
      "Tempo",
      "Grafana Agent"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_005"
  },
  {
    "job_id": "senior-devops-engineer-at-coveragex-sri-lanka-4323172766",
    "title": "Senior DevOps Engineer",
    "company": "CoverageX Sri Lanka",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-devops-engineer-at-coveragex-sri-lanka-4323172766?position=19&pageNum=0&refId=cwjO1pdVhjZgV7Z0gf3YlA%3D%3D&trackingId=69QkV3sEB9qbDLAHHuVb0Q%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793466",
    "description": "Job SummaryThe Senior DevOps Engineer will lead the design, implementation, and maintenance of robust, scalable, and secure cloud infrastructure and CI/CD pipelines to support our software development lifecycle. This role requires deep technical expertise in automation, cloud technologies, infrastructure-as-code, and system reliability. The ideal candidate will collaborate closely with development, QA, and security teams to enhance system performance, streamline deployments, and ensure high availability across production environments.Key Responsibilities1. Infrastructure & Cloud Management· Design, deploy, and maintain scalable cloud infrastructure (AWS / Azure / GCP).· Implement Infrastructure-as-Code (IaC) using Terraform, CloudFormation, or similar tools.· Ensure high availability, fault tolerance, and disaster recovery capabilities.· Monitor cloud resource usage and optimise costs where appropriate.2. CI/CD Pipeline Development· Build, maintain, and improve automated CI/CD pipelines for seamless code integration and deployment.· Work with engineering teams to ensure smooth deployment processes and shorter release cycles.· Implement automated rollback and release verification strategies.3. Automation & System Optimization· Automate routine tasks, configuration management, and system provisioning using tools such as Ansible, Chef, or Puppet.· Identify performance bottlenecks and optimise systems for speed, reliability, and scalability.4. Security & Compliance· Integrate security best practices into infrastructure, pipelines, and deployments (DevSecOps).· Manage secrets, access controls, and encryption to ensure data protection.· Conduct regular security audits and vulnerability assessments.5. Monitoring & Incident Management· Implement and manage monitoring, alerting, and logging systems (Prometheus, Grafana, ELK, Datadog).· Lead root-cause analysis for incidents, prioritising long-term preventive solutions.· Participate in on-call rotations and ensure rapid response to production issues.6. Collaboration & Leadership· Work closely with software engineers, QA, and product teams to align DevOps practices with organisational goals.· Mentor junior DevOps engineers and contribute to the development of team best practices and standards.· Provide technical leadership in architectural discussions and roadmap planning.Required Qualifications & Experience· Bachelor’s degree in Computer Science, Engineering, or related field (or equivalent experience).· 5+ years of hands-on experience in DevOps, Site Reliability Engineering, or Cloud Engineering.· Proven experience with AWS, Azure, or Google Cloud Platform.· Strong skills in CI/CD tools such as GitHub Actions, Jenkins, GitLab CI, or Azure DevOps.· Advanced knowledge of containerisation technologies (Docker, Kubernetes).· Proficiency in scripting languages such as Bash, Python, or Go.· Experience with configuration management tools (Ansible, Chef, Puppet).· Deep understanding of network fundamentals, distributed systems, and microservices architecture.Preferred Skills· Experience with service mesh tools (Istio, Linkerd).· Familiarity with observability stacks (ELK, Loki, OpenTelemetry).· Knowledge of zero-downtime deployments and blue–green / canary release strategies.· Exposure to agile development methodologies.· Certification in AWS/Azure/GCP is an added advantage.What We Offer· A dynamic and collaborative work environment· Opportunities for professional growth and development· Competitive compensation package· Flexible work options (if applicable)· A chance to be part of impactful projects with real business valueJoin us in building the future of technology. Apply now with your resume and brief description of your most impactful project.*CoverageX is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.*",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Holding Companies"
    },
    "skills": [
      "Python",
      "Go",
      "Bash",
      "AWS",
      "Azure",
      "Google Cloud Platform",
      "CloudFormation",
      "Azure DevOps",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Ansible",
      "Chef",
      "Puppet",
      "GitHub",
      "GitLab",
      "GitHub Actions",
      "GitLab CI",
      "Istio",
      "Prometheus",
      "Grafana",
      "Datadog",
      "IaC",
      "Service Mesh",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_007"
  },
  {
    "job_id": "lead-devops-engineer-at-lseg-4251776269",
    "title": "Lead Devops Engineer",
    "company": "LSEG",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-16",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-devops-engineer-at-lseg-4251776269?position=29&pageNum=0&refId=cwjO1pdVhjZgV7Z0gf3YlA%3D%3D&trackingId=hAnF40fQUx4yCvpasvbsjQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793483",
    "description": "Company OverviewFTSE Russell, part of the London Stock Exchange Group, is an essential index partner for a changing world, providing category defining indices across asset classes and investment objectives to create new possibilities for the global investment community. FTSE Russell’s expertise and products are used extensively by institutional and retail investors globally.Job SummaryAre you passionate about making developers' lives easier, faster, and more fulfilling ? We're on a mission to supercharge our engineering culture by building a world-class DevOps organization that's the envy of the industry.This is a great opportunity to join a growing company in an innovative and dynamic industry !We are looking for a strong, hands-on Lead DevOps Engineer to build and maintain a brand-new cloud-based Index platform. You will lead a team of Senior and Junior DevOps Engineers to help us build and manage secure, reliable, and cost-effective cloud environments, drive observability and resilience through chaos and disaster recovery testing, and implement FinOps strategies to optimize cloud spending. Your expertise will be crucial in ensuring operational excellence and business continuity in a dynamic cloud-native environment. You will also use your deep experience of DevOps CI/CD practices to design, implement and optimize a best-in-class AWS micro services architecture.We are looking for someone with a strong background in DevOps practices and tools, with a focus on GitLab, Terraform, AWS cloud, Kubernetes/EKS, Ansible. Candidate will play a crucial role in our technology team, contributing to the development, deployment, and maintenance of our infrastructureKey ResponsibilitiesLead and mentor a high-performing, geographically diverse team of DevOps engineers, fostering a culture of collaboration, automation, and continuous improvement.Build and oversee the implementation of secure, resilient, and cost-optimized AWS cloud infrastructure using best-in-class DevOps practices and technologies.Collaborate with software developers across multiple geographies and cross-functional teams to understand project objectives, gather requirements, and deliver systems and software within agreed upon timelines.Oversee the implementation and management of CI/CD pipelines to streamline software development and deployment processes for Java and Python based Microservices-style architectures.Drive infrastructure-as-code maturity through Terraform, enforcing modular, reusable, and version-controlled infrastructure patterns.Oversee Kubernetes (EKS) infrastructure at scale, ensuring robust workload orchestration, service discovery, and container lifecycle management.Lead cloud security posture management by integrating security controls, automated scanning, and continuous compliance into the DevOps lifecycle.Drive observability efforts using tools like Datadog (or equivalent) to monitor infrastructure and application performance.Introduce and lead chaos engineering practices to proactively identify potential points of failure and improve system resilience.Oversee and continuously optimize cloud cost management strategies in line with Cloud FinOps principles.Design, lead, and continuously improve disaster recovery strategies and testing frameworks to support high availability and business continuity.\\Collaborate with executive leadership and cross-functional stakeholders to align infrastructure strategy with long-term business objectives.Ensure code is up-to-date, maintainable, scalable, and secure.Mentor senior DevOps engineers and promote a culture of continuous improvement and cloud operational excellence.Stay updated on industry best practices and emerging technologies in DevOps and Cloud.Stay updated on cloud technologies, security vulnerabilities, and emerging FinOps methodologies.This is not just a People Management role, and requires you to be completely hands-on.Must Have SkillsStrong hands-on experience with AWS cloud services: EC2, S3, RDS, Lambda, VPC, IAM, CloudWatch, EKS, ECSExpertise in Infrastructure as Code (IaC) using Terraform.Deep knowledge and hands-on experience with CI/CD tools (e.g., GitLab CI, Jenkins, etc.) for Java and Python based Microservices-style architectures. Proven experience in a leadership role within a DevOps or Cloud Engineering team.Strong expertise in AWS services and cloud architecture best practices.Strong experience managing Kubernetes clusters (preferably EKS) and containerization using Docker.Solid understanding of cloud security practices and compliance frameworks.Experience with observability platforms such as Datadog, Prometheus, or equivalent.Familiarity with cloud financial management and FinOps principles.Track record of designing and executing disaster recovery plans and drills.Solid knowledge of Cloud security best practices including IAM policies, encryption, vulnerability scanning, and compliance audits.Proven track record in AWS Cloud Networking best practices, focused on building a robust, secure and efficient cloud network architectureStrong scripting skills in Python, Bash, Ansible or similar language. (Bash and Python preferred)Experience with automated testing frameworks and infrastructure testing tools.Excellent problem-solving skills and ability to work collaboratively.Nice To Have SkillsAWS Certifications such as AWS Certified Solutions Architect, Certified DevOps Engineer or equivalent.Practical experience with chaos engineering methodologies and tools.Experience with other cloud platforms (Azure, GCP) for hybrid or multi-cloud environments.Experience working in a regulated or high-availability environment (e.g., fintech, financial services or capital markets).Passion for open-source technologies and contributions to the DevOps community.Bonus SkillsExperience working in areas of Equity or Fixed Income and a working knowledge of Benchmarks and Indices.Preferred QualificationsBachelor’s degree in Computer Science, Engineering, or related field, or equivalent experience.15+ years of experience in engineering roles, with at least 5+ years in senior DevOps leadership positions.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce. You will be part of a collaborative and creative culture where we encourage new ideas and are committed to sustainability across our global business. You will experience the critical role we have in helping to re-engineer the financial ecosystem to support and drive sustainable economic growth. Together, we are aiming to achieve this growth by accelerating the just transition to net zero, enabling growth of the green economy and creating inclusive economic opportunity.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.Join us and be part of a team that values innovation, quality, and continuous improvement. If you're ready to take your career to the next level and make a significant impact, we'd love to hear from you.LSEG is a leading global financial markets infrastructure and data provider. Our purpose is driving financial stability, empowering economies and enabling customers to create sustainable growth.Our purpose is the foundation on which our culture is built. Our values of Integrity, Partnership, Excellence and Change underpin our purpose and set the standard for everything we do, every day. They go to the heart of who we are and guide our decision making and everyday actions.Working with us means that you will be part of a dynamic organisation of 25,000 people across 65 countries. However, we will value your individuality and enable you to bring your true self to work so you can help enrich our diverse workforce.We are proud to be an equal opportunities employer. This means that we do not discriminate on the basis of anyone’s race, religion, colour, national origin, gender, sexual orientation, gender identity, gender expression, age, marital status, veteran status, pregnancy or disability, or any other basis protected under applicable law. Conforming with applicable law, we can reasonably accommodate applicants' and employees' religious practices and beliefs, as well as mental health or physical disability needs.You will be part of a collaborative and creative culture where we encourage new ideas. We are committed to sustainability across our global business and we are proud to partner with our customers to help them meet their sustainability objectives. Our charity, the LSEG Foundation provides charitable grants to community groups that help people access economic opportunities and build a secure future with financial independence. Colleagues can get involved through fundraising and volunteering.LSEG offers a range of tailored benefits and support, including healthcare, retirement planning, paid volunteering days and wellbeing initiatives.Please take a moment to read this privacy notice carefully, as it describes what personal information London Stock Exchange Group (LSEG) (we) may hold about you, what it’s used for, and how it’s obtained, your rights and how to contact us as a data subject.If you are submitting as a Recruitment Agency Partner, it is essential and your responsibility to ensure that candidates applying to LSEG are aware of this privacy notice.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting and Financial Services"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "Bash",
      "AWS",
      "Azure",
      "GCP",
      "EC2",
      "S3",
      "Lambda",
      "RDS",
      "CloudWatch",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "Terraform",
      "Ansible",
      "GitLab",
      "GitLab CI",
      "Prometheus",
      "Datadog",
      "Infrastructure as Code",
      "IaC",
      "IAM",
      "Containerization"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_012"
  },
  {
    "job_id": "devops-engineer-at-paramount-4335876548",
    "title": "DevOps Engineer",
    "company": "Paramount",
    "location": "New York, NY",
    "posted_date": "2025-11-14",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-at-paramount-4335876548?position=6&pageNum=0&refId=iMnSUuHRfTry5LDWhW1laA%3D%3D&trackingId=qGjWQicv1UldaFgrORtVFg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793491",
    "description": "#WeAreParamount on a mission to unleash the power of content… you in?We’ve got the brands, we’ve got the stars, we’ve got the power to achieve our mission to entertain the planet – now all we’re missing is… YOU! Becoming a part of Paramount means joining a team of passionate people who not only recognize the power of content but also enjoy a touch of fun and uniqueness. Together, we co-create moments that matter – both for our audiences and our employees – and aim to leave a positive mark on culture.In This Role You’ll:Paramount Global is hiring a DevOps Engineer! As a DevOps Engineer at Paramount, you will be an integral part of our Data Engineering team, responsible for building and maintaining robust CI/CD pipelines, creating automations, and ensuring the reliability and performance of our systems. You will work closely with Data Engineers, Cloud Administrators, and other partners to support our development and production environments.Responsibilities include: Design, develop, and maintain CI/CD pipelines for various applications. Implement and manage Infrastructure as Code using tools like Terraform. Develop automation scripts and tools to streamline operations and improve efficiency. Collaborate with development teams to ensure smooth code deployments and integrations. Monitor and troubleshoot deployment incidents and resolve technical issues. Implement and manage container orchestration using Kubernetes. Develop and maintain technical documentation for DevOps processes and systems. Stay up to date with the latest industry trends and guidelines in DevOps. Basic Qualifications You Bring: 3+ years of experience with Linux, and a thorough understanding in writing Bash scripts. Good knowledge of Git, Docker, Terraform, and one of the major cloud platforms. Communicating with internal customers to understand their requirements, and writing automations acceptable to them, with tools such as GitHub Actions, GitLab CI/CD, or similar tools. Bonus Skills: Excellent problem-solving skills and attention to detail. Comfortable to work independently with minimal supervision. Experience with monitoring and logging tools (e.g., Prometheus, Grafana, OpenTelemetry, Google Monitoring). Familiarity with Kubernetes. Knowledge of data governance and Information Security protocols. Understanding of API, Firewalls rules, protocols like http Ability to learn new technologies by reading product documentation with little guidanceParamount Skydance Corporation (NASDAQ: PSKY) is a leading global media and entertainment company that creates premium content and experiences for audiences worldwide. Driven by iconic studios, networks and streaming services, Paramount's portfolio of consumer brands includes CBS, Showtime Networks, Paramount Pictures, Nickelodeon, MTV, Comedy Central, BET, Paramount+, and Pluto TV, among others. Paramount delivers the largest share of the U.S. television audience and boasts one of the industry's most important and extensive libraries of TV and film titles. In addition to offering innovative streaming services and digital video products, the company provides powerful capabilities in production, distribution and advertising solutions.Additional InformationHiring Salary Range: $125,000.00 - 140,000.00.The hiring salary range for this position applies to New York City, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.What We Offer:Attractive compensation and comprehensive benefits packages. Check out our full list of benefits here: https://www.paramount.com/careers/benefitsGenerous paid time off. An exciting and fulfilling opportunity to be part of one of Paramount’s most dynamic teams. Opportunities for both on-site and virtual engagement events. Unique opportunities to make meaningful connections and build a vibrant community, both inside and outside the workplace. Explore life at Paramount: https://www.paramount.com/careers/life-at-paramountParamount is an equal opportunity employer (EOE) including disability/vet.At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Bash",
      "Linux",
      "Docker",
      "Kubernetes",
      "Terraform",
      "Git",
      "GitHub",
      "GitLab",
      "GitHub Actions",
      "GitLab CI",
      "Prometheus",
      "Grafana",
      "OpenTelemetry",
      "Google Cloud Platform",
      "Infrastructure as Code",
      "API",
      "Container Orchestration"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_022"
  },
  {
    "job_id": "devops-engineer-at-kiakia-finance-4341890095",
    "title": "DevOps Engineer",
    "company": "KiaKia Finance",
    "location": "United States",
    "posted_date": "2025-11-19",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-at-kiakia-finance-4341890095?position=11&pageNum=0&refId=iMnSUuHRfTry5LDWhW1laA%3D%3D&trackingId=VPRjPPZcG9L0PT26Q2hxLQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793508",
    "description": "About The RoleHelp us scale our infrastructure to serve millions of customers.Key ResponsibilitiesManage and scale cloud infrastructure to ensure uptimeImplement CI/CD pipelines for automated deploymentsMonitor system performance and troubleshoot issuesEnsure the security and integrity of cloud systemsAutomate deployment processes for faster releasesImplement disaster recovery and data backup solutionsDevelop infrastructure as code (IaC) templatesEnsure compliance with industry security standardsDevelop monitoring and alerting systemsConduct regular performance tuning and optimizationsResearch and implement new DevOps tools and practicesPerform security assessments and vulnerability analysisMaintain documentation of infrastructure and processesRequirements4+ years DevOps experienceAWS certificationExperience with Docker and KubernetesStrong scripting skillsSecurity best practices knowledge",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
      "skills": [
        "AWS",
        "Docker",
        "Kubernetes",
        "CI/CD",
        "Infrastructure as Code",
        "IaC",
        "Scripting",
        "Monitoring",
        "Alerting",
        "Disaster Recovery",
        "Data Backup",
        "Security Assessments",
        "Vulnerability Analysis"
      ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_027"
  },
  {
    "job_id": "devops-engineer-at-infosys-4298628792",
    "title": "Devops Engineer",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "posted_date": "2025-11-14",
    "job_url": "https://in.linkedin.com/jobs/view/devops-engineer-at-infosys-4298628792?position=2&pageNum=0&refId=%2B2ZLDZybQWB9clPabNsg5A%3D%3D&trackingId=Yxm%2B2AB2RzGGQVg4YNHb%2Bg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793514",
    "description": "Support incident management and service requests' customer support Design, implement, and maintain CI/CD pipelines to support automated testing and deployment. Collaborate with software development and IT operations teams to deliver high-quality software and services. Implement and manage monitoring and logging systems to ensure system health and performance. Automate repetitive tasks and processes using scripting languages Troubleshoot and resolve issues related to application performance, infrastructure, and security. Ensure security best practices are followed throughout the development and deployment process. Maintain and enhance configuration management tools Participate in on-call (IA) rotations to provide 24/7 support for critical systems. Continuously evaluate and improve DevOps tools, processes, and practices. Document procedures, configurations, and troubleshooting steps. Ability to develop value-creating strategies and models that enable clients to innovate, drive growth and increase their business profitability Good knowledge on software configuration management systems Awareness of latest technologies and Industry trends Logical thinking and problem solving skills along with an ability to collaborate Ability to assess the current processes, identify improvement areas and suggest the technology solutions One or two industry domain knowledge Client Interfacing skills Project and Team management",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "CI/CD",
        "Monitoring",
        "Logging",
        "Scripting",
        "Configuration Management"
      ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_031"
  },
  {
    "job_id": "devops-engineer-at-razorpay-4340066795",
    "title": "DevOps Engineer",
    "company": "Razorpay",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-12",
    "job_url": "https://in.linkedin.com/jobs/view/devops-engineer-at-razorpay-4340066795?position=5&pageNum=0&refId=%2B2ZLDZybQWB9clPabNsg5A%3D%3D&trackingId=Z63hvH4LvcgtUhpiwoCeBA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793526",
    "description": "DevOps engineer is critical to the project’s overall success, right from planning to supporting primary KPI as customer satisfaction and productivity. A DevOps Engineering Expert has an essential role in integrating the project functions and resources across the product life cycle, right from planning, building, testing, and deployment to support.Roles and Responsibilities:Build and maintain the cloud infra environmentsEnsuring availability, performance, security, and scalability of production systems.Collaborate with application teams to apply DevOps practices in the development lifecycleAbility to create solution prototypes and conduct proof of concept of new toolsDesign repeatable, automated, and scalable processes to increase efficiency and improve software quality such as managing Infrastructure as Code & work on internal tooling which simplifies workflows.Automate and streamline our operations and processes.Troubleshoot and diagnose issues / outages and Provide operational supportEngage in incident handling, especially supporting a culture of post-mortem and knowledge sharingMandatory Qualifications:1-3 years of hands-on experience in DevOps/Currently practicing DevOps methodology.Proven experience with cloud infrastructure preferably AWSWorking knowledge of containerization (Docker, Kubernetes) and orchestration technologiesHands-on experience in any Configuration Management like Puppet/Chef/Ansible.Ability to do scripting (any one of Shell, Ruby, Perl, Python, golang, etc.).Troubleshooting and system engineering exposure in Linux production environments.Comfortable working in a fast-paced environment while continuously evaluating emerging technologiesStrong communication and analytical/problem-solving skillsGood to have experience in database technologies (MariaDB/MySQL, etc)Knowledge of CI/CD, Logging, and Monitoring stack.Should be well versed with IaaC specially TerraformShould be well versed with networking at AWSShould be able to manage infrastructure operations at the bank Have a few weekend side projects up on GitHubHave contributed to an open-source projectHave worked at a product companyHave a working knowledge of a backend programming languageLocation: Bangalore",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Internet Marketplace Platforms"
    },
      "skills": [
        "AWS",
        "Docker",
        "Kubernetes",
        "CI/CD",
        "Infrastructure as Code",
        "Terraform",
        "Linux",
        "Scripting",
        "Ansible",
        "Chef",
        "Puppet",
        "MariaDB",
        "MySQL",
        "Monitoring",
        "Logging",
        "Networking",
        "Containerization"
      ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251120_034"
  },
  {
    "job_id": "entry-level-web-developer-at-ibm-4341139193",
    "title": "Entry Level Web Developer",
    "company": "IBM",
    "location": "San Jose, CA",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/entry-level-web-developer-at-ibm-4341139193?position=9&pageNum=0&refId=tjwvSNzUa0Cz8fw5BOyVdA%3D%3D&trackingId=sWBY0FwoniWonEPd4kAuvg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793551",
    "description": "IntroductionWhy Join UsBe part of a mission-driven team shaping the future of AI and open source.Work with cutting-edge technologies and world-class engineers.Grow your career in developer advocacy and technical communication.Enjoy a collaborative, inclusive, and innovative work environment.Your Role And ResponsibilitiesYou will be a core contributor to developing a modern web platform that will help our users: Learn how our products work and fit into their current workflowsManage their deployments including problem solving, implementing new features, and scaling their current implementationBuild on to our products to discover new use cases and integrationsThis isn't just a documentation site—it's a complete learning ecosystem built on a modern web stack.What You Will DoWrite clean, maintainable code for both front-end interfaces and back-end servicesBuild and integrate features across the full stack—from user-facing components to APIs and databasesCollaborate daily with designers to implement polished, accessible user experiencesParticipate in code reviews to learn best practices and improve code qualityDebug and troubleshoot issues across the applicationWork with product managers to understand requirements and provide technical inputContribute to technical decisions about architecture, tools, and approachesTest your work to ensure reliability and performanceDocument your code to help current and future team members understand your workWhy This Role Is SpecialLearn from the best: Work directly with long-tenured web developers who are invested in your growthGreenfield opportunity: Shape the architecture and approach from day one rather than maintaining legacy codeCross-functional collaboration: Partner closely with experienced designers and product managersReal impact: Your work will directly serve users in our communityPreferred EducationBachelor's DegreeTechnical FoundationRequired technical and professional expertiseExperience with both front-end and back-end web developmentFamiliarity with modern web technologies and frameworksUnderstanding of how complex content systems workMindset And ApproachGenuinely curious about how things workOpen to feedback and eager to learnReady to tackle challenging technical problemsExcited about building something substantial from scratchYou don't need to know everything—we are looking for someone who's ready to grow and isn't afraid to ask questions.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Web Development",
        "APIs",
        "Front-End Development",
        "Back-End Development",
        "Modern Web Technologies",
        "Frameworks"
      ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251120_005"
  },
  {
    "job_id": "senior-software-engineer-net-at-virtusa-4336889409",
    "title": "Senior Software Engineer - .NET",
    "company": "Virtusa",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-software-engineer-net-at-virtusa-4336889409?position=5&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=hMBapIZVL1IVqYDC%2FsyEJQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793561",
    "description": "Design, develop, and maintain scalable and high-performance web applications using .NET technologies. Implement responsive and user-friendly front-end interfaces using React or Angular. Collaborate with cross-functional teams to define, design, and ship new features. Ensure the performance, quality, and responsiveness of applications. Integrate with cloud services (Azure/AWS) to enhance application functionality and scalability. Troubleshoot and resolve complex technical issues. Mentor junior developers and contribute to team growth and knowledge sharing. Participate in code reviews and ensure adherence to best practices and coding standards.",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Finance",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        ".NET",
        "React",
        "Angular",
        "AWS",
        "Azure"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_003"
  },
  {
    "job_id": "software-engineer-%E2%80%93-swift-flutter%C2%A0-ec-46-at-eyepax-4334543608",
    "title": "Software Engineer – Swift/Flutter (EC-46)",
    "company": "Eyepax",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-06",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-%E2%80%93-swift-flutter%C2%A0-ec-46-at-eyepax-4334543608?position=15&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=JZgK7%2BjWZaIRbTwYt%2FTfvQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793564",
    "description": "We are seeking for a Software Engineer with expertise in iOS (Swift) and Flutter for our client, a premier appliance manufacturing company in New Zealand. The role involves designing and developing high-performance mobile applications for their IoT initiatives, integrating with smart appliances, sensors, and cloud platforms. You should have hands-on development experience, strong problem-solving skills, and a willingness to grow within a cross-platform environment.Key Responsibilities:Develop and maintain mobile applications using Swift (iOS Native) and Flutter.Work on Swift projects following VIPER architecture and Flutter apps using Bloc/Cubit state management.Integrate apps with IoT hardware components and sensors through Wi-Fi, Bluetooth, and BLE protocols.Implement real-time communication features with WebSocket and REST APIs.Collaborate with backend developers, QA engineers, and hardware teams to ensure smooth end-to-end IoT experiences.Participate in code reviews, debugging, and performance tuning.Support App Store/TestFlight distribution processes.Contribute to continuous learning by staying updated on mobile and IoT trends. What We Expect:Bachelor's degree in computer science, Software Engineering, or a related field (or equivalent experience).3 – 4 years of professional experience in iOS and/or Flutter development.Proficiency in Swift with exposure to VIPER architecture.Solid knowledge of Flutter, Dart, and Bloc/Cubit for state management.Hands-on experience with Xcode (iOS) and Android Studio (Flutter).Familiarity with WebSocket, REST APIs, and Bluetooth/Wi-Fi integrations.Basic understanding of IoT concepts and device lifecycle.Experience with Git, CI/CD, and Agile practices.Good problem-solving and debugging skills.Effective communication and teamwork abilities. Nice To Have:Exposure to Objective-C or Android native development.Experience with payment gateways or in-app subscription flows.Familiarity with embedded systems or resource-constrained environments. Who We AreEstablished in 2006, Eyepax is a company headquartered in Singapore. Our main development hubs are located in Sri Lanka and Vietnam and other offices situated at Sweden, USA, France and Australia. Eyepax has a dedicated workforce of 180+ experts who are proficient in 30+ technologies and serve clients around the globe. We nurture a dynamic workplace where Continuous Improvement culture takes a central part in our work DNA and the key areas being coaching, transferable skills, scientific problem solving and global exposure.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
      "skills": [
        "Swift",
        "Flutter",
        "Dart",
        "iOS",
        "Android",
        "VIPER Architecture",
        "Bloc",
        "Cubit",
        "WebSocket",
        "REST APIs",
        "Bluetooth",
        "BLE",
        "Wi-Fi",
        "Xcode",
        "Android Studio",
        "Git",
        "CI/CD",
        "Material UI",
        "Ant Design",
        "Chakra UI",
        "Embedded Systems"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_007"
  },
  {
    "job_id": "associate-software-engineer-%E2%80%93-frontend-at-qoria-sri-lanka-4335250347",
    "title": "Associate Software Engineer – Frontend",
    "company": "Qoria Sri Lanka",
    "location": "Colombo District, Western Province, Sri Lanka",
    "posted_date": "2025-11-10",
    "job_url": "https://lk.linkedin.com/jobs/view/associate-software-engineer-%E2%80%93-frontend-at-qoria-sri-lanka-4335250347?position=25&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=evRTg9ryOvcvVZpcz%2FnXSg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793575",
    "description": "Who we are?Headquartered in Perth, Australia, with offices globally including in Colombo, Sri Lanka, Qoria is an ASX listed global leader in child digital safety technology and services. We are a purpose-driven business, operating under the ‘Linewize’ brand in North America and Asia Pacific, the ‘Smoothwall’ brand in the UK, 'Qoria LK' in Sri Lanka and the ‘Qoria’ brand in EMEA. Our solutions are utilised by schools, school districts, and parental communities to protect children from seeing harmful content online, identify children at risk based on their digital behaviours and ensure teachers maintain focus and safe learning in the digital classroom. 30.000 schools and 7 million parents depend on our solutions to keep 25 million children safe in 180 countries around the world.What’s the opportunity?As an Associate Front‐End Engineer you will sharpen your skills by building, testing,and shipping customer‐facing React/Next.js components in TypeScript. Under the guidance of senior engineers, you’ll turn clearly scoped user stories into production‐ready UI, help keep our design system consistent, and learn modern engineering practices that set the foundation for your career growth.Key Responsibilities:Learning & Development:Actively participate in required training programs and mentorship sessions, to expand your knowledge.Demonstrate a strong commitment to continuous personal growth and the development of essential soft skills, including communication, teamwork, and problem-solving.Continuously enhance your coding skills and deepen your understanding of best practices through dedicated self-study and hands-on practical application in daily tasks.Technical Stack:Design, implement, and maintain complex, responsive, and highly interactive user interfaces using React.js, Next.js and TypeScript.Apply comprehensive knowledge in both local and global state management strategies (e.g., React Context API, Redux Toolkit) to ensure efficient and predictable data flow across the application.Utilize and advocate for frontend design patterns such as Ducks, Presentational/Containercomponents, and other architectural best practices to build modular, maintainable, and extensible codebases.Drive the implementation of visually consistent and accessible user interfaces through hands-on expertise in styling with CSS, SCSS, and LESS, along with experience in integrating and extending established design systems (e.g.,Material UI, Ant Design,Chakra UI, or custom solutions).Engineering Practice:Translate business requirements into technical specificationsDevelop the ability to thoroughly understand and interpret software requirements and design specifications, proactively raising concerns or seeking clarification where needed.Understand the business requirement and Develop, implement new features and functionalities according to the requirement.Meet deadlines for assigned requirements, demonstrating reliability and time management.Display strong willingness to gain proficiency in the necessary tools, technologies, and techniques relevant to our projects and tech stack.Write, test, and debug code accurately, ensuring it aligns precisely with project requirements and functional specifications while keeping the bug rate minimum.Adhere strictly to team agreements, coding standards, and established best practices within the organization to maintain code quality and consistency.Conduct thorough unit testing to ensure the reliability, functionality, and robustness of your code contributions.Take ownership of your work, seeing tasks through from start to completion with dedication and responsibility. Take necessary actions to keep the ticket movingCollaboration & Problem Solving:Collaborate effectively with other teams (e.g., QA, Product, Infrastructure) to identify challenges, share insights, and provide well-reasoned solutions.Analyze and troubleshoot issues in the software efficiently, providing timely and effective solutions to maintain system stability.Documentation & Knowledge Sharing:Create and maintain technical documentation, including design documents, clear and meaningful code comments, and user manuals, ensuring clarity for current and future reference.Keep all documentation up-to-date to reflect changes and evolving features in the software.Professionalism & Continuous Improvement:Stay updated on industry trends, emerging technologies, and cutting-edge best practices in software development, bringing new insights to the team.Provide clear, accurate, and timely status updates on all assigned tasks and projects, ensuring transparency and alignment with team goals.Working Environment & ToolsLanguages & Frameworks: TypeScript 5+, React18, Next.js 14State Management: Redux Toolkit, Context APIStyling: SCSS Modules, CSS‐in‐JSTesting: Jest, React Testing Library, Cypress (E2E)Tooling: GitHub, GitHub Actions CI, Storybook, VS CodeDesign System: Ant d, MUI, ChakraRequired Skills & ExperienceBachelor’s degree in Computer Science, Software Engineering, or equivalent practical experience.Minimum 1.5 years of front‐end development experience (internships included) using React, Next.js, and TypeScript.Fundamental knowledge of ES 2020+, HTML5, CSS/SCSS/LESS, responsive design, and browser developer tools.Familiarity with at least one design system or component library (Material UI, Ant Design, Chakra UI, etc.).Basic understanding of git workflows, pull requests, and CI pipelines.Solid written and verbal communication skills in English.Nice‐to‐HaveHands‐on experience with Testing Library, Cypress, or Playwright.Knowledge of performance auditing tools (Lighthouse).Experience working in Agile/Scrum teams.Ability to design, document, and manage comprehensive test cases and test plans,often utilizing",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Technology, Information and Internet, Data Infrastructure and Analytics, and IT System Data Services"
    },
    "skills": [
      "TypeScript",
      "React",
      "Next.js",
      "Redux Toolkit",
      "React Context API"
      ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_012"
  },
  {
    "job_id": "senior-software-quality-assurance-engineer-at-hcltech-sri-lanka-4315658480",
    "title": "Senior Software Quality Assurance Engineer",
    "company": "HCLTech Sri Lanka",
    "location": "Colombo District, Western Province, Sri Lanka",
    "posted_date": "2025-11-19",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-software-quality-assurance-engineer-at-hcltech-sri-lanka-4315658480?position=27&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=QPoCmdtjuRsBec677lA3vA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793577",
    "description": "Senior Software Quality Assurance Engineer | Functional Testing | HCLTech Sri LankaWe are HCLTech, one of the fastest-growing large tech companies in the world and home to 219,000+ people across 60 countries, supercharging progress through industry-leading capabilities centered around Digital, Engineering and Cloud.The driving force behind that work, our people, are diverse, creative, and passionate, raising the bar for excellence on a regular basis. We, in turn, work hard to bring out the best in them as we strive to help them find their spark and become the best version of themselves that they can be.If all this sounds like an environment you’ll thrive in, then you’re in the right place. Join us on our journey in advancing the technological world through innovation and creativity.Job Description:We are looking for a Functional Tester with strong exposure to Agile methodologies and excellent communication skills to join our dynamic team. The ideal candidate should have a proven track record in functional testing with an in-depth understanding of software development lifecycles.Key Requirements:3+ years of hands-on experience in Functional Testing.Ability to write test cases, test scripts, and test scenarios based on requirements and specifications.Working in Agile environments with tools like JIRA, TestRail, ALM, Bugzilla, or Zephyr.Proficient in executing manual tests and validating functionality against acceptance criteria.Knowledge of writing simple SQL queries for data validation.Exposure to API testing using tools like Postman.Excellent communication skills.Why Join Us?• Be part of a global tech leader• Work in a diverse and inclusive environment• Grow your career with comprehensive learning and development programs• Enjoy a competitive benefits package and flexible work cultureApply now via hansanie.atapattu@hcltech.com",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "SQL",
      "Postman",
      "JIRA"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_013"
  },
  {
    "job_id": "lead-senior-software-engineer-frontend-igt1-lanka-sitecore-at-igt1-4340964081",
    "title": "Lead / Senior Software Engineer - Frontend (IGT1 Lanka: Sitecore)",
    "company": "IGT1",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-17",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-senior-software-engineer-frontend-igt1-lanka-sitecore-at-igt1-4340964081?position=35&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=%2FTjnS9%2BT274is%2B9nJQQnFQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793580",
    "description": "About IGT1 LankaIGT1 Lanka is a rapidly growing offshore technology and talent solutions company based in Port City Colombo. We are a fully owned subsidiary of IGT I Holdings Sweden AB, funded by the three of world’s leading private equity firms; EQT Group, Hg, and TA Associates. We’re also proud to be a sister company of IFS, Sri Lanka’s largest and most established technology company.At IGT1 Lanka, we partner with global businesses to scale operations, accelerate innovation, and build world-class SaaS platforms through high-quality offshore delivery. Our people-first culture champions diversity, teamwork, and continuous learning, creating an environment where talent thrives.With a team of over 400 professionals and counting, we are always looking for passionate, skilled individuals who want to make a global impact while being part of something extraordinary.Through our offshore collaboration model, you'll be embedded within the team of one of our esteemed international clients, contributing directly to high-impact, enterprise-level initiatives.About the client: Sitecore Sitecore delivers a composable digital experience platform that empowers the world’s smartest and largest brands to build lifelong relationships with their customers. A highly decorated industry leader, Sitecore is the leading company bringing together content, commerce, and data into one connected platform that delivers millions of digital experiences every day. Thousands of blue-chip companies including American Express, Porsche, Starbucks, L’Oréal, and Volvo Cars rely on Sitecore to provide more engaging, personalized experiences for their customers.Job DescriptionAbout the role:We are seeking a highly experienced and technically skilled Senior Front-End Engineer to join Sitecore's new technology hub in Sri Lanka. The ideal candidate is a technical expert with a passion for solving complex problems and writing high-quality software solutions. You will be expected to take on significant technical challenges, owning major features and influencing key architectural decisions while helping to elevate the skills of the engineers around you.Key responsibilities:Own the solution design and implementation of large-scale, complex front-end features from start to finish. Elevate the team's technical abilities through exemplary code, thoughtful and constructive code reviews, informal mentorship, and hands-on guidance on configuring and optimizing build tools (Vite, Webpack, Rollup). Lead key technical decisions across state management, performance optimization, and front-end architecture, ensuring scalable and maintainable solutions. Collaborate closely with cross-functional teams (Design, Product, Backend, QA) to shape cohesive, high-quality features and influence product direction. Write clean, type-safe TypeScript code aligned with recognized best practices (DRY, SOLID). QualificationsPreferred Skills and Experience:Bachelor's degree in Computer Science, Engineering, or equivalent practical experience. 5+ years of professional software development experience, including 3+ years of deep, hands-on React work. Expert-level proficiency in JavaScript/TypeScript, HTML5, and CSS3. Strong experience with modern build tools, including Vite, Webpack, and Rollup (configuration, optimization, plugin ecosystems). Deep understanding of state management strategies and tooling (React Query, Jotai, React Context). Experience integrating REST APIs and working with code generation tools such as OpenAPI/Swagger. Mastery of modern React patterns: functional components with hooks, custom hooks, component composition, React Server Components, and performance optimization techniquesStrong CSS architecture and implementation skills, including Flexbox, Grid, Container Queries, and experience with CSS-in-JS or utility frameworks (TailwindCSS preferred). Understanding of UI/UX principles and a passion for creating thoughtful, user-centered experiences. Solid understanding of Core Web Vitals and front-end performance optimization. Strong problem-solving, communication, and collaboration skills. Nice to have:Test-driven development (TDD) experience and mindset. Experience with MCP (Model Context Protocol) integration. Experience with Next.js, Remix, or other modern React frameworks. Monorepo tooling experience (Turborepo, Nx, Lerna). Strong understanding of web security fundamentals (XSS, CSRF, CSP). Accessibility knowledge (WCAG 2.1 AA standards)Experience with REST API code generation tools (OpenAPI, Swagger Codegen)Advanced experience with GitHub Actions, such as creating custom actions or complex, multi-stage workflowsExperience with Agile/Scrum methodologiesExperience designing or developing agentic UI experiences, where the interface proactively assists the userCore technologies we use:React, TypeScript, JavaScript (ES6+)Vite for development, Webpack/Rollup for more complex buildsReact Query, Jotai, React Context for state managementTailwindCSS and CSS ModulesVitest, React Testing Library, PlaywrightGitHub Actions, DockerTurborepo with pnpm workspacesREST APIs with OpenAPI/Swagger code generationWhat matters to us:Simplicity over cleverness - complexity should come from the problem, not the solutionReadability first - we spend more time reading code than writing itWell-tested and maintainable - code should be easy for anyone on the team to understand and modifyFunctional and declarative patterns over imperative codeType safety - comprehensive TypeScript usageComponent-driven development with clear separation of concernsTesting ownership -- no feature is complete without testsCode ownership - if you write it, you maintain it and take responsibility for its qualityAdditional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Executive",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development and IT Services and IT Consulting"
    },
    "skills": [
      "JavaScript",
      "TypeScript",
      "React",
      "Next.js",
      "Vite",
      "Webpack",
      "Rollup",
      "React Query",
      "Jotai",
      "React Context",
      "REST API",
      "OpenAPI",
      "Swagger",
      "CSS",
      "CSS Modules",
      "TailwindCSS",
      "Vitest",
      "React Testing Library",
      "Playwright",
      "GitHub Actions",
      "Docker",
      "Turborepo",
      "pnpm workspaces"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_017"
  },
  {
    "job_id": "lead-software-engineer-at-coninnova-4322772391",
    "title": "Lead Software Engineer",
    "company": "ConInnova",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-16",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-software-engineer-at-coninnova-4322772391?position=36&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=14y32vikeEbul6hhXCesLQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793583",
    "description": "Company: ConInnova Limited (Sri Lanka)Location: Battaramulla, Sri LankaType: Full-TimeAbout ConInnovaConInnova is led by experienced quantity surveyors, engineers, and technology specialists who deeply understand the challenges faced in the construction industry. Our mission is to combine practical field expertise with modern intelligent systems to help construction businesses manage costs, reduce overheads, optimise workflows, and deliver projects with confidence.We build smart, scalable solutions that transform traditional construction processes through automation, data intelligence, and seamless collaboration.Position OverviewWe are seeking a highly skilled Lead Developer to take ownership of the technical vision, architecture, and delivery of our next-generation construction intelligence platforms. This role requires expertise in .NET Core, Angular, SQL, Azure DevOps, AWS, and test automation pipelines, along with strong experience in Agile delivery and team leadership.The Lead Developer will mentor the development team, drive architectural decisions, and ensure our products remain reliable, scalable, and aligned with the needs of the construction industry.Key Responsibilities1. Technical LeadershipLead the development of enterprise-level applications using .NET Core, C#, and Angular.Oversee architectural decisions with a focus on scalability, reliability, and performance.Solve complex technical and business challenges with efficient, practical solutions tailored for construction workflows.Enforce clean architecture, coding standards, and best practices across the development team.2. Full-Stack DevelopmentBuild modern, responsive front-end applications using Angular, TypeScript, RxJS, and RESTful architecture.Develop and optimise backend APIs, services, and modules using .NET Core and Entity Framework Core.Design and maintain SQL databases, stored procedures, data models, and performance tuning.3. Cloud & DevOps (Azure & AWS)Build and maintain CI/CD pipelines using Azure DevOps (Repos, Pipelines, Boards, Artifacts).Manage cloud-based deployments on Azure or AWS with a strong understanding of compute, storage, serverless, and identity management.Implement infrastructure-as-code, environment automation, and secure deployment strategies.Work with Docker containers; Kubernetes knowledge is a plus.4. Test Automation & Quality EngineeringImplement automated testing and quality gates within CI/CD pipelines.Build unit, integration, and UI test suites using tools like NUnit, xUnit, Selenium, Cypress, or similar.Ensure high code coverage and consistency in test strategy across the engineering team.5. Agile Delivery & Cross-Functional CollaborationCollaborate closely with product managers, QS experts, engineers, and construction domain specialists.Break down features into tasks, prepare estimates, and deliver sprint objectives on time.Participate in Agile ceremonies and support the smooth execution of each sprint.6. Team Management & MentorshipMentor developers at all levels and create growth plans to elevate team capability.Perform code reviews, ensure technical excellence, and uphold development discipline.Provide leadership to foster a culture of collaboration, innovation, responsibility, and continuous improvement.7. System Design & ArchitectureDesign secure, scalable, construction-focused digital platforms—cost management tools, site automation systems, reporting dashboards, etc.Integrate external systems, APIs, and construction management platforms as required.Produce architecture documentation, workflow diagrams, technical guidelines, and system specifications.Required Skills & ExperienceTechnical Skills.NET Core / .NET 6+, C#, Web APIAngular 8+, TypeScript, JavaScriptSQL Server, stored procedures, indexing, optimizationExperience in Azure DevOps (CI/CD, YAML pipelines, Git repos)Real-world exposure to Azure or AWS cloud servicesKnowledge of microservices, REST APIs, cloud architectureFamiliarity with automation frameworks and DevOps workflowsExperience with containers (Docker) is required; Kubernetes is a bonusLeadership & Soft SkillsAbility to lead and inspire a development teamStrong communication skills, especially with non-technical stakeholdersExperience collaborating with QS, engineering, or construction professionals (preferred)Excellent problem-solving, decision-making, and conflict-handling skillsStrong organizational and time-management abilityComfortable in a fast-paced, delivery-oriented environmentQualificationsBachelor’s degree in Computer Science, Engineering, IT, or equivalent experience6–10+ years of professional software development experience2–4+ years in a leadership or senior engineering roleExperience in construction tech, ERP systems, cost management tools, or enterprise SaaS is an advantage This role is an excellent opportunity to gain hands-on experience, develop professional skills, and work closely with a global team across construction, engineering, and software projects.Apply Today and Start Your Professional Journey With ConInnova!",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      ".NET Core",
      ".NET 6",
      "C#",
      "Web API",
      "Angular",
      "TypeScript",
      "JavaScript",
      "SQL Server",
      "Stored Procedures",
      "Azure DevOps",
      "YAML",
      "Git",
      "AWS",
      "Azure",
      "Microservices",
      "REST API",
      "Entity Framework Core",
      "RxJS",
      "Docker",
      "Kubernetes",
      "NUnit",
      "xUnit",
      "Selenium",
      "Cypress"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_018"
  },
  {
    "job_id": "senior-software-engineer-igt1-lanka-sitecore-at-igt1-4341336918",
    "title": "Senior Software Engineer (IGT1 Lanka: Sitecore)",
    "company": "IGT1",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-18",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-software-engineer-igt1-lanka-sitecore-at-igt1-4341336918?position=46&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=ZMNF2ww4bJ1Ye3VM56Ty%2FQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793585",
    "description": "About IGT1 LankaIGT1 Lanka is a rapidly growing offshore technology and talent solutions company based in Port City Colombo. We are a fully owned subsidiary of IGT I Holdings Sweden AB, funded by the three of world’s leading private equity firms; EQT Group, Hg, and TA Associates. We’re also proud to be a sister company of IFS, Sri Lanka’s largest and most established technology company.At IGT1 Lanka, we partner with global businesses to scale operations, accelerate innovation, and build world-class SaaS platforms through high-quality offshore delivery. Our people-first culture champions diversity, teamwork, and continuous learning, creating an environment where talent thrives.With a team of over 400 professionals and counting, we are always looking for passionate, skilled individuals who want to make a global impact while being part of something extraordinary.Through our offshore collaboration model, you'll be embedded within the team of one of our esteemed international clients, contributing directly to high-impact, enterprise-level initiatives.About the client: Sitecore Sitecore delivers a composable digital experience platform that empowers the world’s smartest and largest brands to build lifelong relationships with their customers. A highly decorated industry leader, Sitecore is the leading company bringing together content, commerce, and data into one connected platform that delivers millions of digital experiences every day. Thousands of blue-chip companies including American Express, Porsche, Starbucks, L’Oréal, and Volvo Cars rely on Sitecore to provide more engaging, personalized experiences for their customers.Job DescriptionAbout the role:We are seeking a Senior Software Engineer to join our Backend Engineering Team. In this role, you will design and build scalable data infrastructure, optimize data pipelines, and enable advanced analytics. You will build Restful APIs to power personalization and recommendation systems.ResponsibilitiesDevelop RESTful APIs using Go, Python, or equivalent frameworks to expose data services and integrate with downstream applications. Design & Develop scalable ingestion frameworks for structured, semi-structured, and unstructured data from diverse sources. Build & Optimize ETL pipelines ensuring data integrity, quality, and reliability across batch and real-time workflows. Automate Testing & Monitoring for ingestion frameworks to ensure resilience and adaptability. Contribute to Architecture decisions, design patterns, and scalability strategies for new and existing systems. Perform POCs to evaluate emerging technologies and continuously improve platform capabilities. Develop unit integration tests and use continuous integration to deploy services. QualificationsPreferred Skills and Experience4–6 years of experience in Software Engineering with a Bachelor’s or Master’s in Computer Science, Information Systems, or related field. Skilled in programming languages: Golang, Python, SQL; exposure to and React is a plus. Experience developing RESTful APIs using Go, Python, or similar frameworks. Experience with CI/CD pipelines (GitHub, Jenkins) and containerization (Docker, Kubernetes/EKS). Knowledge of AWS services: EC2, S3, DynamoDB, Elasticsearch. or Azure Services. Strong understanding of Agile methodologies, APIs, and microservices. Nice To Have SkillsFamiliarity with stream processing(flink), message queues(Kafka, rabbit mQ), and scalable data systems. Proven experience building and optimizing big data pipelines, architectures, and datasets. Strong proficiency in Elasticsearch (architecture, indexing, querying). Hands-on experience with Big Data frameworks: Hadoop, Spark, Spark Streaming, or Flink. Proficiency in SQL and NoSQL systems (Snowflake, Redshift, MongoDB, DynamoDB, HBase). Experience with workflow orchestration tools (Airflow preferred; Luigi, Azkaban are a plus). Additional InformationWe embrace flexibility and hybrid work opportunities to support diverse needs and lifestyles, while also valuing inclusive workplace experiences. By fostering a sense of community, we drive innovation, strengthen connections, and nurture belonging. Our commitment ensures you can work in a way that suits you best, while also engaging with colleagues to share ideas and build meaningful relationships.",
    "criteria": {
      "Seniority level": "Executive",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development and IT Services and IT Consulting"
    },
    "skills": [
      "Go",
      "Python",
      "SQL",
      "RESTful APIs",
      "MongoDB",
      "DynamoDB",
      "Elasticsearch",
      "Snowflake",
      "Redshift",
      "NoSQL",
      "AWS EC2",
      "AWS S3",
      "AWS DynamoDB",
      "Azure",
      "Docker",
      "Kubernetes",
      "Jenkins",
      "CI/CD",
      "GitHub",
      "Spark",
      "Spark Streaming",
      "Hadoop",
      "HBase",
      "Kafka",
      "Airflow",
      "Luigi",
      "ETL",
      "Big Data",
      "Flink"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_022"
  },
  {
    "job_id": "senior-software-engineer-at-h2o-ai-4312491121",
    "title": "Senior Software Engineer",
    "company": "H2O.ai",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-08",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-software-engineer-at-h2o-ai-4312491121?position=55&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=nCzR0c4NKTkO7i2NmH5NmQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793588",
    "description": "Founded in 2012, H2O.ai is dedicated to democratizing AI. As the world’s leading agentic AI company, H2O.ai converges Generative and Predictive AI to help enterprises and public sector agencies develop purpose-built GenAI applications on their private data. Its open-source technology is trusted by over 20,000 organizations worldwide, including more than half of the Fortune 500. H2O.ai powers AI transformation for companies such as AT&T, Commonwealth Bank of Australia, Singtel, Chipotle, Workday, Progressive Insurance, and the NIH.H2O.ai partners include Dell Technologies, Deloitte, Ernst & Young (EY), NVIDIA, Snowflake, AWS, Google Cloud Platform (GCP), and VAST. H2O.ai’s AI for Good program supports nonprofit groups, foundations, and communities in advancing education, healthcare, and environmental conservation. With a vibrant community of 2 million data scientists worldwide, H2O.ai aims to co-create valuable AI applications for all users.About This OpportunityJoin the team building H2O Driverless AI, our award-winning Automated Machine Learning (AutoML) platform. Driverless AI is a flagship product designed to use AI to make AI, automating the complex data science pipeline—including intelligent feature engineering, model selection, model validation, and interpretability (MLI). The platform significantly accelerates the time from data to production-ready models, generating highly optimized scoring pipelines in both Python and Java for high-performance, low-latency deployment.As a Senior Software Engineer, you will play a critical role in the full lifecycle development of core platform features, from high-performance computation back-end services to user-facing components.This position is based in Sri Lanka.What You Will DoDesign, develop, and maintain core components of the H2O Driverless AI platform, focusing on scalability, performance, and reliability.Write clean, efficient, and well-documented code primarily in Python, contributing to the core AutoML engine, feature transformers, and model pipelines.Build and improve user interface elements and complex data visualizations using TypeScript.Implement and manage deployment mechanisms using Docker and containerization best practices to ensure seamless deployment across cloud and on-premise environments.Collaborate closely with data scientists, researchers, and product managers to translate complex machine learning research into production-quality software features.Participate in code reviews, design discussions, and mentor junior engineers on software architecture and engineering best practices.What We Are Looking For4+ years of professional experience in software development, building and shipping scalable enterprise software products.Deep expertise and fluency in Python (required for primary product development).Solid experience developing enterprise applications using Java and/or working with Java-based APIs and systems.Proven experience with front-end development using TypeScript or JavaScript.Expertise in containerization and orchestration, specifically utilizing Docker in development and production environments.Strong understanding of distributed systems, multi-threading, concurrency, and performance optimization techniques.How To Stand Out from the CrowdHands-on experience or strong theoretical background in Machine Learning (ML), Deep Learning, or Data Science concepts (e.g., feature engineering, model training/testing, explainability techniques).Familiarity with ML frameworks (e.g., TensorFlow, PyTorch, XGBoost) or distributed computing technologies (e.g., Dask, Spark).Why H2O.ai?Market Leader in Total RewardsRemote-Friendly CultureFlexible working environmentBe part of a world-class teamCareer GrowthH2O.ai is committed to creating a diverse and inclusive culture. All qualified applicants will receive consideration for employment without regard to their race, ethnicity, religion, gender, sexual orientation, age, disability status, or any other protected characteristic under applicable law.H2O.ai is an innovative AI cloud platform company, leading the mission to democratize AI for everyone. Thousands of organizations worldwide have utilized our cutting-edge technology across various industries. We’ve made it easy for people at all levels to generate breakthrough solutions to complex business problems and advance the discovery of new ideas and revenue streams. We push the boundaries of what is possible with artificial intelligence.H2O.ai employs the world’s top Kaggle Grandmasters, the community of best-in-the-world machine learning practitioners and data scientists. A strong AI for Good ethos and a responsible approach to AI drive the company’s purpose.Please visit www.H2O.ai to learn more.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "Java",
      "TypeScript",
      "JavaScript",
      "Docker",
      "Containerization",
      "AutoML",
      "MLI",
      "TensorFlow",
      "PyTorch",
      "XGBoost",
      "Dask",
      "Spark"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_023"
  },
  {
    "job_id": "lead-software-engineer-maritime-at-stark-4335914632",
    "title": "Lead Software Engineer Maritime",
    "company": "STARK",
    "location": "Devon, Central Province, Sri Lanka",
    "posted_date": "2025-11-13",
    "job_url": "https://lk.linkedin.com/jobs/view/lead-software-engineer-maritime-at-stark-4335914632?position=56&pageNum=0&refId=R7FmrLPo9gToqqPMkKKxyA%3D%3D&trackingId=KVz76WxruHY%2Bazag4Wrf4A%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793590",
    "description": "Permanent employee, Full-time DevonAbout UsSTARK is a new kind of defence technology company revolutionising the way autonomous systems are deployed across multiple domains. We design, develop, and manufacture high-performance unmanned systems that are software-defined, mass-scalable, and cost-effective. This provides our operators with a decisive edge in highly contested environments.STARK is bringing its expertise in software-defined unmanned systems to the maritime domain. Traditional fleets alone cannot safeguard this vast, critical space. Unmanned Surface Vessels (USVs) extend naval reach at lower cost and reduced risk to personnel.Our maritime family of systems is AI-enabled and built for reliable performance in the harshest seas, delivering NATO a fully integrated hardware–software capability for scalable ISR and strike operations.Your missionYou’ll lead the development of STARK’s maritime software capability, integrating autonomous sea systems into the Minerva front-line platform. You’ll design and implement modern C++ architecture that connects front-line control with edge computing systems — ensuring reliability, precision, and operational excellence at sea.ResponsibilitiesLead software design, development, and integration for maritime systems within the Minerva platform.Develop and maintain core C++ architecture for autonomy, control, and communication subsystems.Build and manage software delivery pipelines for maritime applications, from edge to front-line.Conduct detailed code reviews and enforce modern C++ standards across the team.Collaborate with hardware and systems engineers to integrate code with real-world autonomous platforms.Define software structure, interfaces, and quality benchmarks to ensure cohesive, mission-ready systems.Support future team growth by establishing technical foundations and engineering best practices.QualificationsExpert in modern C++ with hands-on development experience.Strong understanding of software architecture, integration, and system design.Experience in real-time, embedded, or safety-critical systems — ideally in automotive, aerospace, or defence.Familiar with autonomous control systems such as autopilots, guidance algorithms, or vehicle dynamics.Practical experience working with physical hardware, sensors, or data communication systems.Advantageous: experience with radar, sensors, maritime systems, or web-based front-ends (TypeScript, React).Knowledge of data communications, including Starlink and tactical radio systems, is a plus.Security-cleared or eligible to obtain defence-level clearance within the UK/EU.Apply for this jobAbout UsLEGAL DISCLAIMERWe are an equal-opportunity employer committed to fostering a diverse and inclusive workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, or any other characteristic protected by law. Due to the nature of our work in the defense sector, candidates must be eligible to obtain and maintain the appropriate security clearance required for the position.Apply for this jobWe are looking forward to hearing from you!Thank you for your interest in STARK. Please fill out the following short form. Should you have difficulties with the upload of your data, please contact our recruiting team.Data privacy statementUploading document. Please wait.Please add all mandatory information with a * to send your application.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Defense and Space Manufacturing"
    },
    "skills": [
      "C++",
      "TypeScript",
      "React",
      "Edge Computing",
      "Autopilots",
      "Guidance Algorithms",
      "Vehicle Dynamics",
      "Radar",
      "Sensors",
      "Data Communications",
      "Starlink"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_024"
  },
  {
    "job_id": "software-engineer-internship-at-seatgeek-4307571879",
    "title": "Software Engineer - Internship",
    "company": "SeatGeek",
    "location": "New York, NY",
    "posted_date": "2025-11-15",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-internship-at-seatgeek-4307571879?position=5&pageNum=0&refId=wuE8zpHVnDgtaeF%2FDyVeAw%3D%3D&trackingId=LhTerlaq94WfvGSJDAHCSA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793593",
    "description": "SeatGeek believes live events are powerful experiences that unite humans. With our technological savvy and fan-first attitude we’re simplifying and modernizing the ticketing industry.By catering to both consumers and enterprises, we’re powering a new, open entertainment ecosystem where fans have effortless access to experiences, and teams, venues, and shows have seamless access to their audiences. Because everyone should expect more from ticketing.Open roles for internsWe are looking for the best and brightest College Interns to join us for Summer 2026, to help us make live entertainment even better! Experience is preferred, but not required – in fact, we look forward to supporting you by teaching you new technologies and mentoring you in software development craft as a member of our world-class engineering team.Backend (Python, Go)Frontend Web (Typescript + React)Mobile (Kotlin, Swift)Platform (AWS, Docker, Python, Go)This is a 12 week summer Internship Program with a hybrid work style (expected to be on-site 50% of the week) at our corporate office in NYC.What You'll DoDesign cloud-native software architectureSolve customer problemsScale our software to support a booming businessBuild a many-sided marketplaceEmpower decision-making at a rapidly growing data-driven company Run experiments and evaluate new technologies that will determine the future of our business for years to comeBuild performant, beautiful, inclusive user interfaces that delight our users and enhance our brandWhat You HaveYou are currently enrolled college student studying Computer Science or a related degree set to graduate in the Spring/Summer of 2027Experience in building or testing software. We'll be interested in hearing about what you've built and how you built itProblem solving skills - adept at handling technical challenges. SeatGeek engineers create custom solutions to unique ticketing problems, including venue mapping, inventory tracking, and event matchingPassion for software craftsmanship and products. You hold yourself and your code to a high standardCommitment to your teammates. You enjoy working with a diverse group of people with different experiences and take pride in mentoring and learning from othersInternship perks$120 a month to spend on tickets to live eventsMonthly commuter card for transportationSubscription to HeadspaceFree lunch & snacks is provided every day in the officeWeekly planned events like comedy/broadway shows, sports games, museum visits and moreHousing stipendPlease note you are expected to come into the SeatGeek New York City office at least 3 days a week**The compensation for this role is $55/hour USD (based on a 40 hour work week).SeatGeek is committed to providing equal employment opportunities to all employees and applicants for employment regardless of race, color, religion, creed, age, national origin or ancestry, ethnicity, sex, sexual orientation, gender identity or expression, disability, military or veteran status, or any other category protected by federal, state, or local law. As an equal opportunities employer, we recognize that diversity is a positive attribute and we welcome the differences and benefits that a diverse culture brings. Come join us!To review our candidate privacy notice, click here.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Internship",
      "Job function": "Engineering",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Go",
      "TypeScript",
      "React",
      "Kotlin",
      "Swift",
      "AWS",
      "Docker",
      "React Native"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_031"
  },
  {
    "job_id": "full-stack-software-engineer-new-graduates-united-states-at-wanderlog-4336765627",
    "title": "Full-Stack Software Engineer (New graduates: United States)",
    "company": "Wanderlog",
    "location": "United States",
    "posted_date": "2025-11-18",
    "job_url": "https://www.linkedin.com/jobs/view/full-stack-software-engineer-new-graduates-united-states-at-wanderlog-4336765627?position=10&pageNum=0&refId=wuE8zpHVnDgtaeF%2FDyVeAw%3D%3D&trackingId=%2B8m0A5iM3TLPI01SJhLi9g%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793600",
    "description": "Warning: if you’re outside of the Americas timezones, unfortunately, we’re only hiring for engineers with at least some timezone overlap.Wanderlog helps make leisure travel easier. We believe that travel makes the world better, and are building tools that lower the bar to it. Our core product, built starting 2019, is a travel planning app (we’re the top-ranked trip planner on iOS and Android), but we’re also helping travelers book hotels (without hidden fees), providing them with information (through various pages on e.g., best attractions, restaurants, etc.), and more.Our founders are twin brothers. Peter worked as an engineer at Stripe and a consultant at McKinsey, and Harry as a product manager at Google. We’re an engineering and product-driven team: the founders studied computer science at Yale, and have built successful, bootstrapped travel companies (BookWithMatrix and All the Flight Deals) with products people love before starting Wanderlog.We now serve millions of travelers a month, and are a team of 6, including 5 engineers hailing from Yale, University of Toronto, UCLA, and more; and 1 designer. We’re a self-sustaining, default-alive startup.We also love traveling. Whether it’s a short hop to Austin, Seattle, or New Orleans; or a longer jaunt to Australia, Hawaii, or Banff National Park (all places the team’s traveled to in the past year!), travel broadens our horizons, builds empathy, and challenges us to grow. We’re working to bring these experiences to more of the world.What You’ll DoAs an engineer, you’ll be responsible for owning portions of the product. You’ll be expected to:Build new features on our website and mobile app. (Our stack is Javascript (Typescript): modern React on the web, React Native on mobile, and Node.js/Express on the server.)Design and decide what to build based on what would help travelers and drive growth. You won’t be handed a spec; you’ll be coming up with it!Build data pipelines to crawl, process, and synthesize data from various sources around the web.Write tests and and build out engineering infrastructure. Our code is fully typed (Typescript) and tested.Debug and fix bugs and scale the infrastructure as it grows.Review code written by other engineers.Be fast and nimble: figure out the best way to build new features at lowest cost in time and future technical debt.This position is a full-time role reporting to the cofounders at Wanderlog.What You Might Work OnNew, user-friendly hotel booking interfaces that make finding a place to stay easier.AI-powered tools that read articles and watch videos for you and summarize the places they mention.Improvements to our React Native mobile app so that it runs faster on slower Android phones.A Chrome extension to let travelers quickly compare possible places to visit, airfares, and hotels.Better invite and collaboration tools to encourage people using Wanderlog to get more friends to join them.A better profile page that lets travelers on Wanderlog show off where they’ve been, see how many people they’ve helped, and follow other friends and their trips.You May Be a Good Fit If YouAre a Javascript developer comfortable with React and/or React Native.Are a product person: you’ve built products end-to-end before, and really care about the people who use them.Are comfortable with picking up various technologies for the task at hand. We quickly evaluate libraries and tools that could help our product, and variously use Redis, Elasticsearch, and Python as needed too.Are entrepreneurial: excited about joining a small, high-growth team and talking to users, doing product and design, and wearing a variety of hats.Love travel and believe in it as a positive force personally and for the world.What’s it like to work here?We’re an engineering and product-heavy team. Travel’s something everyone does, and we love using the tools we build. A typical week’s work involves talking to users, prioritizing tasks in Sheets, designing on Figma, and building and shipping them continuously.Our values include putting travelers first, owning the product end-to-end, treating teammates with respect, and moving fast by being smart about what we build and how we build it.We believe in work fitting in with your life. We love travel and believe it rejuvenates us and makes us better people, and have twice annual travel offsites where the goal is to enjoy visiting a new place and collaborate more closely with the team in person.Our hiring processWe’ll first have you do 2 short rounds of asynchronous programming challenges, including one with a virtual interviewer. After that, we’ll have a coding interview where you work on a quick program on your laptop in your preferred language with one of the founders, followed by a half-day final-round virtual onsite via video call.FoundersPeter Xu and Harry Yu are twin brothers. Peter shuttled between Los Angeles, Houston, New York, Tokyo, and Hong Kong as a consultant at McKinsey before settling down at Stripe as a full-stack engineer, where he worked closely with support teams to build tools that made support agents’ work more productive.Harry worked at Google as a product manager on Hotel Search, Chrome, and finally Google Assistant for the past three, where he was one of the early PMs on the team.Before building Wanderlog, they had built Coursetable (featured in the New York Times) and travel sites All the Flight Deals (a flight deals aggregator) and BookWithMatrix (a power-traveler flight search tool). The founders are now glad to have been working on Wanderlog for 6 years, and are excited to make travelers’ lives easier!",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Travel Arrangements"
    },
    "skills": [
      "JavaScript",
      "TypeScript",
      "React",
      "React Native",
      "Node.js",
      "Express",
      "Redis",
      "Elasticsearch",
      "Python",
      "iOS",
      "Android"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_034"
  },
  {
    "job_id": "software-engineer-frontend-all-levels-at-ramp-4332771770",
    "title": "Software Engineer, Frontend, All Levels",
    "company": "Ramp",
    "location": "New York, United States",
    "posted_date": "2025-11-19",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-frontend-all-levels-at-ramp-4332771770?position=16&pageNum=0&refId=wuE8zpHVnDgtaeF%2FDyVeAw%3D%3D&trackingId=I8N4bnQa1Qi47q%2Fp2FBL%2Fg%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793604",
    "description": "About RampAt Ramp, we’re rethinking how modern finance teams function in the age of AI. We believe AI isn’t just the next big wave. It’s the new foundation for how business gets done. We’re investing in that future — and in the people bold enough to build it.Ramp is a financial operations platform designed to save companies time and money. Our all-in-one solution combines payments, corporate cards, vendor management, procurement, travel booking, and automated bookkeeping with built-in intelligence to maximize the impact of every dollar and hour spent. More than 45,000 businesses, from family-owned farms to e-commerce giants to space startups, have saved $10B and 27.5M hours with Ramp. Founded in 2019, Ramp powers the fastest-growing corporate card and bill payment platform in America, and enables over $100 billion in purchases each year.Ramp’s investors include Thrive Capital, Sands Capital, General Catalyst, Founders Fund, Khosla Ventures, Sequoia Capital, Greylock, and Redpoint, as well as over 100 angel investors who were founders or executives of leading companies. The Ramp team comprises talented leaders from leading financial services and fintech companies—Stripe, Affirm, Goldman Sachs, American Express, Mastercard, Visa, Capital One—as well as technology companies such as Meta, Uber, Netflix, Twitter, Dropbox, and Instacart.Ramp has been named to Fast Company’s Most Innovative Companies list and LinkedIn’s Top U.S. Startups for more than 3 years, as well as the Forbes Cloud 100, CNBC Disruptor 50, and TIME Magazine’s 100 Most Influential Companies.About The RoleOur ideal candidate has a deep understanding of JavaScript, a passion for web performance, and can creatively come up with solutions to solve customer's needs. Our tech stack currently involves TypeScript, React, Vite, and Ryu, our in-house design system.Check out our Engineering Blog for more on our tech stack, mission and values!What You’ll DoBuild! Design performant, beautiful, and usable interfaces Collaborate on our technical vision. Lead discussions and implementation of multiple complex projectsFoster a culture of upholding industry-leading UXContinuously improve our engineering processes, tools, and systems that allow us to scale the code base, productivity, and the teamRecruit, interview and develop your own interview questions, while fostering the culture of excellence, velocity and humilityInspire and mentor less experienced engineers and internsWhat You'll NeedMinimum of 2 years of frontend engineering experience preferredProficiency in JavaScript and ReactKnack for getting the visuals rightTrack record of shipping high-quality products and developing projects at scaleAbility to turn business and product ideas into engineering solutionsDesire to work in a fast-paced environment, continuously grow, and master your craftAlignment with Ramp’s core values of enabling businesses to grow more by spending lessBenefits (for U.S.-based Full-time Employees)100% medical, dental & vision insurance coverage for youPartially covered for your dependentsOne Medical annual membership401k (including employer match on contributions made while employed by Ramp)Flexible PTOFertility HRA (up to $5,000 per year)WFH stipend to support your home office needsWellness stipendParental LeaveRelocation support to NYC or SF (as needed)Pet insuranceReferral InstructionsIf you are being referred for the role, please contact that person to apply on your behalf.Other NoticesPursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.Ramp Applicant Privacy Notice",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "JavaScript",
      "TypeScript",
      "React",
      "Vite"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_036"
  },
  {
    "job_id": "software-engineer-backend-at-doordash-4084261319",
    "title": "Software Engineer, Backend",
    "company": "DoorDash",
    "location": "Pune, Maharashtra, India",
    "posted_date": "2025-11-13",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-backend-at-doordash-4084261319?position=1&pageNum=0&refId=r7nlz0F7Vnn0XH0fKNinmQ%3D%3D&trackingId=gaPwzP%2F%2FOQhOq%2F2sGViZKA%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793607",
    "description": "About the TeamCome help us build the world's most reliable on-demand, logistics engine for delivery! We're bringing on experienced engineers to help us further our 24x7, global infrastructure system that powers DoorDash's three-sided marketplace of consumers, merchants, and dashers.About the RoleThe Data Tools mission is to build robust data platforms and establish policies that guarantee the analytics data is of high quality, easily accessible/cataloged, and compliant with financial and privacy regulations, fostering trust and confidence in our data-driven decision-making process.We are building the Data Tools team in India and you will have an opportunity to be part of a founding team with a greater opportunity for impact where you can help grow the team and shape the roadmap for the data platform at DoorDash. You will report directly to the Data Tools Engineering Manager.You're excited about this opportunity because you will…Work on building a data discovery platform, privacy frameworks, unified access control frameworks, and data quality platform to enable data builders at DoorDash to deliver high-quality and trustable data sets and metricsHelp accelerate the adoption of the data discovery platform by building integrations across online, analytics platforms and promoting self-serveCome up with solutions for scaling data systems for various business needsCollaborate in a dynamic startup environmentWe're excited about you because…B.E./B.Tech., M.E./M.Tech, or Ph.D. in Computer Science or equivalent2+ years of experience with CS fundamental concepts and experience with at least one of the programming languages of Scala, Java, and PythonPrior technical experience in Big Data infrastructure & governance - you've built meaningful pieces of data infrastructure. Bonus if those were open-sourced technologies like DataHub, Spark, Airflow, Kafka, FlinkExperience improving efficiency, scalability, and stability of data platformsWe use Covey as part of our hiring and / or promotional process for jobs in NYC and certain features may qualify it as an AEDT. As part of the evaluation process we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound on June 20, 2024.Please see the independent bias audit report covering our use of Covey here.About DoorDashAt DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.Our Commitment to Diversity and InclusionWe're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.If you need any accommodations, please inform your recruiting contact upon initial connection.About DoorDashAt DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.Our Commitment to Diversity and InclusionWe're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.If you need any accommodations, please inform your recruiting contact upon initial connection.We use Covey as part of our hiring and/or promotional process for jobs in certain locations.The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: https://getcovey.com/nyc-local-law-144To request a reasonable accommodation under applicable law or alternate selection process, please inform your recruiting contact upon initial connection.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Scala",
      "Java",
      "Python",
      "Kafka",
      "Airflow",
      "Spark",
      "Flink",
      "DataHub"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_037"
  },
  {
    "job_id": "software-engineer-at-flipkart-4321656293",
    "title": "Software Engineer",
    "company": "Flipkart",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-10",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-at-flipkart-4321656293?position=3&pageNum=0&refId=r7nlz0F7Vnn0XH0fKNinmQ%3D%3D&trackingId=PzEAg2RlLq5CYWlYpV%2Buvw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793611",
    "description": "We are hiring SDE 2's at Flipkart.The ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code. Mandatory Skills: Problem solving skills, Algorithms , Java, System Design, Low-Level Design, High-Level Design.Product base startup company experience is a must.Job Title: SDE 2 Apply Here : https://lnkd.in/geFgp-_aWork Location : Bangalore.SDE 2 : Exp : 2.5 to 5 years [Excluding internship].ResponsibilitiesDevelop quality software and web applicationsAnalyze and maintain existing software applicationsDesign highly scalable, testable codeDiscover and fix programming bugsQualificationsBachelor's degree or equivalent experience in Computer Science or related fieldDevelopment experience with programming languagesSQL database or relational database skills",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Design and Consulting",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Java",
      "SQL"
 
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_038"
  },
  {
    "job_id": "software-engineer-at-makemytrip-4335089915",
    "title": "Software Engineer",
    "company": "MakeMyTrip",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-10",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-at-makemytrip-4335089915?position=4&pageNum=0&refId=r7nlz0F7Vnn0XH0fKNinmQ%3D%3D&trackingId=VajX%2BVpn50Qs%2BmGU04XKfQ%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793613",
    "description": "Key Responsibilities Work with product managers and stakeholders to understand user needs and translate them into technical specifications and feature plans Produce clean, efficient, and maintainable code using appropriate programming languages and frameworks, adhering to established coding standards and best practices. Participate in peer code reviews, providing constructive feedback to improve code quality, maintainability, and efficiency across the team Continuously analyze system performance and refine code/architecture to ensure the software can handle increasing load (scale) and operates efficiently (optimize costs/speed) Technical Skills Strong grasp of Data Structures and Algorithms (DSA), and Object-Oriented Programming (OOP) principles. Writing clean, efficient, maintainable, and well-tested code in one programming language (e.g., Golang). Working effectively with designers, product managers, and other engineering teams A strong commitment to continually learning new languages, frameworks, and industry best practices in a rapidly changing field . Educational Qualification Bachelor's or Master's degree in computer science with 1-3 years' experience as a software engineer",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Java",
      "Golang",
      "SQL",
      "System Design",
      "Low-Level Design",
      "High-Level Design"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_039"
  },
  {
    "job_id": "software-engineer-frontend-at-doordash-4248552076",
    "title": "Software Engineer, Frontend",
    "company": "DoorDash",
    "location": "Pune, Maharashtra, India",
    "posted_date": "2025-11-13",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-frontend-at-doordash-4248552076?position=6&pageNum=0&refId=r7nlz0F7Vnn0XH0fKNinmQ%3D%3D&trackingId=wx%2B6T3eL15qAvAR1IOlmxw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793615",
    "description": "About the TeamData is at the foundation of DoorDash's success. The Engineering team in India builds data tools for our internal and external consumers like Data as a Platform (DaaP) solution - which enables merchants and partners to retrieve the data they need from DoorDash and integrate it with their data pipeline, configuration tool which enables configuration management for ETLs, and few other internal tools to solve other data related use cases.About the Role DoorDash is building the world's most reliable on-demand, logistics engine for delivery. We are continuing to grow rapidly and expanding our Engineering offices globally! We are looking for Frontend Engineers to build and maintain large scale data applications and platforms.Frontend Engineers in the data applications space help design and build beautiful, intuitive user interfaces for our web applications to create the best delivery experience possible. Product focused Engineers work at the intersection of product, data platform and data engineering to solve key business problems with elegant technical solutions. You'll work with both technical and business teams to build features that keep our users top of mind. This role is hybrid based in Pune with some in-office time expected and will report to an Engineering Manager.You're excited about this opportunity because you will…Become a product owner for one of our client facing applications. Write robust, highly tested, well-crafted code that you can be proud of. Fight for the best customer experience through technical and product decisions. We're excited about you because you have…B.S., M.S. or PhD in relevant field 2+ years of industry experienceUnderstanding of cross-browser compatibility, progressive enhancement and graceful degradation, responsive design, website performance, and accessibility.Experience architecting large-scale frontend applicationsMastery of the foundations of the web: vanilla JS, HTML5, CSS3Deep understanding of REST principles and experience working with and implementing backend APIsExperience with React/Redux, or similar frameworksExperience with documentation, unit and integration testingNotice to Applicants for Jobs Located in NYC or Remote Jobs Associated With Office in NYC OnlyWe use Covey as part of our hiring and/or promotional process for jobs in NYC and certain features may qualify it as an AEDT in NYC. As part of the hiring and/or promotion process, we provide Covey with job requirements and candidate submitted applications. We began using Covey Scout for Inbound from August 21, 2023, through December 21, 2023, and resumed using Covey Scout for Inbound again on June 29, 2024.The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: CoveyAbout DoorDashAt DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.Our Commitment to Diversity and InclusionWe're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.If you need any accommodations, please inform your recruiting contact upon initial connection.About DoorDashAt DoorDash, our mission to empower local economies shapes how our team members move quickly, learn, and reiterate in order to make impactful decisions that display empathy for our range of users—from Dashers to merchant partners to consumers. We are a technology and logistics company that started with door-to-door delivery, and we are looking for team members who can help us go from a company that is known for delivering food to a company that people turn to for any and all goods.DoorDash is growing rapidly and changing constantly, which gives our team members the opportunity to share their unique perspectives, solve new challenges, and own their careers. We're committed to supporting employees' happiness, healthiness, and overall well-being by providing comprehensive benefits and perks.Our Commitment to Diversity and InclusionWe're committed to growing and empowering a more inclusive community within our company, industry, and cities. That's why we hire and cultivate diverse teams of people from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has room at the table and the tools, resources, and opportunity to excel.If you need any accommodations, please inform your recruiting contact upon initial connection.We use Covey as part of our hiring and/or promotional process for jobs in certain locations.The Covey tool has been reviewed by an independent auditor. Results of the audit may be viewed here: https://getcovey.com/nyc-local-law-144To request a reasonable accommodation under applicable law or alternate selection process, please inform your recruiting contact upon initial connection.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "JavaScript",
      "HTML5",
      "CSS3",
      "React",
      "Redux",
      "REST API",
      "Unit Testing",
      "Integration Testing"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_040"
  },
  {
    "job_id": "%E2%80%8B%E2%80%8Bsoftware-engineer%E2%80%8B-at-microsoft-4341623116",
    "title": "Software Engineer",
    "company": "Microsoft",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-19",
    "job_url": "https://in.linkedin.com/jobs/view/%E2%80%8B%E2%80%8Bsoftware-engineer%E2%80%8B-at-microsoft-4341623116?position=7&pageNum=0&refId=r7nlz0F7Vnn0XH0fKNinmQ%3D%3D&trackingId=68aRiOnv2ps4udQsNokCNw%3D%3D",
    "scraped_at": "2025-11-20T07:49:22.793619",
    "description": "OverviewMicrosoft is a company where passionate innovators come to collaborate, envision what can be and take their careers further. This is a world of more possibilities, more innovation, more openness, and the sky is the limit thinking in a cloud-enabled world. Microsoft’s Azure Data engineering team is leading the transformation of analytics in the world of data with products like databases, data integration, big data analytics, messaging & real-time analytics, and business intelligence. The products our portfolio include Microsoft Fabric, Azure SQL DB, Azure Cosmos DB, Azure PostgreSQL, Azure Data Factory, Azure Synapse Analytics, Azure Service Bus, Azure Event Grid, and Power BI. Our mission is to build the data platform for the age of AI, powering a new class of data-first applications and driving a data culture. Within Azure Data, the databases team builds and maintains Microsoft's operational Database systems. We store and manage data in a structured way to enable multitude of applications across various industries. We are on a journey to enable developer friendly, mission-critical, AI enabled operational Databases across relational, non-relational and OSS offerings. As a member of this team, you will join the Azure Cosmos DB team working on Managed Instance for Apache Cassandra, a cloud-native service that simplifies deployment and scaling of open-source Cassandra clusters. This role is focused on learning, contributing to feature development, and building foundational skills in distributed systems. We do not just value differences or different perspectives. We seek them out and invite them in so we can tap into the collective power of everyone in the company. As a result, our customers are better served.Responsibilities Feature Development: Implement well-scoped features and tasks under guidance from senior engineers. Service Health & Reliability: Contribute to improving automation for cluster provisioning, upgrades, and compliance workflows. Debugging & Support: Assist in diagnosing issues related to Cassandra MI deployments, including networking, configuration, and performance bottlenecks. Collaboration: Work closely with peers and mentors to understand design patterns, coding standards, and operational best practices. Learning & Growth: Rapidly acquire knowledge of Cassandra internals, Azure infrastructure, and Cosmos DB control plane componentsQualificationsRequired Qualification Bachelor's Degree in Computer Science, or related technical discipline . 6 months to 2.6 yrs of proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR equivalent experience. Strong problem-solving skills and willingness to seek help when blocked. Proficiency in Java or C# for backend development; familiarity with scripting (PowerShell or Python) for automation. Basic understanding of distributed systems concepts (consistency, replication, partitioning). Knowledge of Linux environments . Knowledge of Cassandra is a plus.Preferred/Additional QualificationsMaster's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR Bachelor's Degree in Computer Science or related technical field AND 6 months to 2.6 years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python OR equivalent experience.Other Requirements Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud background Check.This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations, and ordinances. If you need assistance and/or reasonable accommodation due to a disability during the application or the recruiting process, please send a request via the Accommodation request form (Accessibility | Microsoft Careers). Benefits/perks listed below may vary depending on the nature of your employment with Microsoft and the country where you work. #azdat #azuredata #cosmosdbThis position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "C",
      "C++",
      "C#",
      "Java",
      "JavaScript",
      "Python",
      "Azure Cosmos DB",
      "Azure SQL Database",
      "Azure PostgreSQL",
      "Azure Data Factory",
      "Azure Synapse Analytics",
      "Azure Service Bus",
      "Azure Event Grid",
      "Power BI",
      "Linux",
      "Apache Cassandra"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251120_041"
  },
  {
    "job_id": "senior-ai-ml-engineer-at-skaleart-4325117007",
    "title": "Senior AI/ML Engineer",
    "company": "Skaleart",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-12-01",
    "job_url": "https://lk.linkedin.com/jobs/view/senior-ai-ml-engineer-at-skaleart-4325117007?position=1&pageNum=0&refId=wdx25viugiMWXUhDz40ouA%3D%3D&trackingId=MNhA4Liu7Y%2F%2FPhjdWs9Zzg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939319",
    "description": "Job OverviewAre you passionate about building real-world AI solutions and working with fast-moving global startups?Were looking for AI/ML Engineers who can bridge the gap between theory and practical deployment engineers who are eager to build, deploy, and scale AI systems that power real-world products.In this role, you'll gain hands-on exposure to applied AI, MLOps, and cloud deployment, while collaborating with international teams and contributing to innovative, high-impact projects across global tech ecosystems.Job ResponsibilitiesArchitect and develop advanced systems for AI research, agent workflows, and cognitive tools.Design and optimize LLM inference flows, embeddings pipelines, and RAG architectures.Integrate LangChain/LangGraph with vector databases and LLM runtimes.Implement graph reasoning layers using GraphDBs (Neo4j, Memgraph).Build MCP tools and multi-agent (A2A) communication pipelines.Collaborate with research teams to operationalize experiments and technical explorations.Maintain engineering excellence through documentation, testing, security, and code quality.Contribute to system design reviews, architecture discussions, and R&D investigations.Job RequirementsStrong experience with LLM systems, embeddings, RAG flows, and inference pipelines.Advanced proficiency with LangChain, LangGraph, and agent orchestration tools.Deep knowledge of vector databases and graph reasoning systems.Expertise in designing distributed, AI-integrated software architectures.Strong engineering discipline, documentation, and secure code practices.Comfort working in experimental and research-first engineering environments.Strong experience in React/Next.js (Frontend) or Python/Node.js (Backend) is required. Proficiency in both will be considered a significant advantage, in addition to the AI-focused skill set outlined above.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Node.js",
      "React",
      "Next.js",
      "LangChain",
      "LangGraph",
      "Vector Database",
      "Neo4j",
      "Memgraph",
      "GraphDB",
      "MLOps",
      "RAG",
      "LLM",
      "AI",
      "Embeddings"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_001"
  },
  {
    "job_id": "machine-learning-engineer-at-zillow-4343864230",
    "title": "Machine Learning Engineer",
    "company": "Zillow",
    "location": "United States",
    "posted_date": "2025-12-16",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-at-zillow-4343864230?position=2&pageNum=0&refId=M69P3ALFQHLqYOLiOeqtsA%3D%3D&trackingId=7p4M4M8Kdjr0RjubAKXlhQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939334",
    "description": "About The TeamAt Zillow, our mission is to give people the power to unlock life’s next chapter. Zillow’s AI Org plays an important part in delivering unique AI-powered experiences for the hundreds of millions of customers who visit Zillow websites each month.The Connections AI team iterates quickly and solves problems at the forefront of AI product development. This role requires an entrepreneurial approach and a driven curiosity about the constantly evolving field of ML Modeling, LLMs and AI-powered assistants.As a Machine Learning Engineer (MLE) on the Connections AI team, you’ll be a part of a skilled group of applied scientists, software developers, and other machine learning engineers working together to connect buyers with the right professionals to help realize their home-buying dreams.About The RoleWe are seeking a collaborative, customer-focused, and product-minded engineer and scientist with deep experience with applied machine learning. You are a roll-up-the-sleeves and get-it-done engineer with a deep understanding of, and are constantly learning about, new techniques in modeling, ML frameworks, and ML infra. You excel at prototyping new ML applications and optimizing impact, performance, and efficiency in production.Apply a growth-mindset and first principles to ambiguous customer problems to rapidly iterate on novel solutions and ways of working. Collaborate closely with applied scientists, engineering, design and research to understand, scope, design, prototype, implement and iterate on internal and external facing systems supporting and implementing next generation AI applications. Shepherd the deployment of machine learning applications into production with an eye towards reliability. Cultivate connections with other teams for critical dependencies and infrastructure. Contribute to carrying and growing our team culture of rapid innovation and creative frugality. This role has been categorized as a Remote position. “Remote” employees do not have a permanent corporate office workplace and, instead, work from a physical location of their choice, which must be identified to the Company. U.S. employees may live in any of the 50 United States, with limited exceptions.In California, Connecticut, Maryland, Massachusetts, New Jersey, New York, Washington state, and Washington DC the standard base pay range for this role is $145,500.00 - $232,500.00 annually. This base pay range is specific to these locations and may not be applicable to other locations. In Colorado, Hawaii, Illinois, Minnesota, Nevada, Ohio, Rhode Island, and Vermont the standard base pay range for this role is $138,300.00 - $220,900.00 annually. The base pay range is specific to these locations and may not be applicable to other locations.In addition to a competitive base salary this position is also eligible for equity awards based on factors such as experience, performance and location. Actual amounts will vary depending on experience, performance and location. Employees in this role will not be paid below the salary threshold for exempt employees in the state where they reside.Who you areProficiency with a high-level programming language (we most commonly use Python)Practical knowledge of statistics (for example, causal inference, Frequentist or Bayesian inference)The communication skills to influence, collaborate with, and educate others (whom you may need to educate on methods and requirements in experimentation and statistics). Experience prototyping, developing, and implementing algorithmic solutions and new technologies with diverse analytics and data. Hands-on experience in deploying machine learning models into realtime production environments. Experience working with large scale datasets and building ETL pipelines using Spark, Kubeflow, and DataBricks. Strong understanding of Machine Learning and Natural Language Processing fundamentals. Experience with Machine Learning tools and Frameworks (e.g. PyTorch, Transformers, XGBoost, scikit-learn, etc.)The tenacity to embrace and tackle challenging problems. Practiced technical ability and passion for both owning implementation and contributing technical/thought leadership for a team of world-class scientists engineers. Bachelor's degree or equivalent experience in Computer Science, or a related field. Bonus Qualifications:Experience with generative AI or large language models and related technologies (knowledge retrieval solutions, for example). Experience with regulated, private or sensitive data, document understanding, user interest modeling, or reinforcement learning. Experience collaborating with science, engineering, design, research and product partners in a team with a startup culture. Advanced degree (M.S. or Ph. D.) or equivalent experience in Computer Science or Engineering, Machine Learning, or related field. Get to know usAt Zillow, we’re reimagining how people move—through the real estate market and through their careers. As the most-visited real estate platform in the U.S., we help customers navigate buying, selling, financing and renting with greater ease and confidence. Whether you're working in tech, sales, operations, or design, you’ll be part of a company that's reshaping an industry and helping more people make home a reality.Zillow is honored to be recognized among the best workplaces in the country. Zillow was named one of FORTUNE 100 Best Companies to Work For® in 2025, and included on the PEOPLE Companies That Care® 2025 list, reflecting our commitment to creating an innovative, inclusive, and engaging culture where employees are empowered to grow.No matter where you sit in the organization, your work will help drive innovation, support our customers, and move the industry—and your career—forward, together.Zillow Group is an equal opportunity employer committed to fostering an inclusive, innovative environment with the best employees. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you have a disability or special need that requires accommodation, please contact your recruiter directly.Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable state and local law.Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Real Estate"
    },
    "skills": [
      "Python",
      "Spark",
      "Kubeflow",
      "DataBricks",
      "PyTorch",
      "Transformers",
      "XGBoost",
      "scikit-learn",
      "Machine Learning",
      "Natural Language Processing",
      "Statistics",
      "ETL Pipeline",
      "Generative AI",
      "Large Language Model",
      "Reinforcement Learning"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_005"
  },
  {
    "job_id": "ai-ml-research-engineer-at-auric-ai-labs-4350173418",
    "title": "AI/ML Research Engineer",
    "company": "Auric AI Labs",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-15",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-research-engineer-at-auric-ai-labs-4350173418?position=1&pageNum=0&refId=yQ7GfYuc%2Bller5QpNcxjyQ%3D%3D&trackingId=bOEcUmLGE%2B%2Bhgt6QGzn9qg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939338",
    "description": "About UsAuric AI builds AI-first products exclusively for defense and intelligence applications. We're a self-funded, research-driven company working on unprecedented technical challenges that compete with the best in the world. Small team (10-15 people), 3-4 year runway, zero commercial pressure and pure focus on technical excellence.The Role You'll architect and build novel AI/ML systems for multi-modal intelligence analysis at scale. This involves designing new approaches for:Cross-modal data fusion and correlation across heterogeneous sourcesGeospatial-temporal reasoning and pattern discoveryQuery understanding and semantic search for specialized domainsAnomaly detection in sparse, adversarial environmentsReal-time inference at scale with strict latency requirementsThis is NOT:Applying existing frameworks to new datasetsFine-tuning foundation modelsStandard RAG/retrieval systemsIncremental optimization workThis IS:Designing novel architectures from first principlesResearch that gets deployed to production within monthsDirect user interaction with military/intelligence analystsBuilding systems where failure has real-world consequencesWhat You Have1. Exceptional First Principles ThinkingYou decompose complex problems to fundamentals and build novel solutions from scratchYou do not respect arbitrary convention2. Deep Algorithmic Foundations Beyond ML, you have mastery in:Spatial algorithms: R-trees, k-d trees, geometric algorithmsGraph algorithms: temporal graphs, probabilistic graphical modelsTemporal reasoning: causal inference, time-series analysisOptimization: combinatorial optimization, approximate algorithms3. Novel Architecture Design You've built systems that don't fit existing frameworks:Published novel architectures or deployed unprecedented systemsCreated domain-specific neural network componentsWhat You GetTechnical Freedom:No project managers, no arbitrary deadlinesYou define what to build based on user needsFull ownership: problem definition to deploymentAccept 70% failure rate in researchEnvironment:Work with researchers from top institutions Access to cutting-edge compute and specialized datasetsDirect access to end users for rapid iterationCulture of intellectual honesty, zero politics",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Defense and Space Manufacturing"
    },
    "skills": [
      "AI",
      "ML",
      "Spatial Algorithms",
      "R-trees",
      "k-d trees",
      "Geometric Algorithms",
      "Graph Algorithms",
      "Temporal Graphs",
      "Probabilistic Graphical Models",
      "Temporal Reasoning",
      "Causal Inference",
      "Time-Series Analysis",
      "Combinatorial Optimization",
      "Approximate Algorithms"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_006"
  },
  {
    "job_id": "ai-ml-engineer-at-hdfc-bank-4348381505",
    "title": "AI/ML Engineer",
    "company": "HDFC Bank",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-03",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-engineer-at-hdfc-bank-4348381505?position=3&pageNum=0&refId=yQ7GfYuc%2Bller5QpNcxjyQ%3D%3D&trackingId=V58TkMVol6UGc58ojkgARQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939341",
    "description": "Job Purpose:An experienced AI/ML Engineer to design, develop and maintain AI / ML and GenAI based solutions on enterprise platform on Industry best and open-source models at scale along with governance and security frameworksDesired Skills :Strong background in designing and implementing machine learning and deep learning algorithms and responsible AI practices at enterprise scale and speedWorking knowledge with ML platforms like TensorFlow, PyTorch, or Hugging FaceProficiency in Training, Tuning and Deploying GenAI models based on LLMs, GANs, and VAEsHands on expert in programming languages like Python, Java, or C++, and have experience with cloud platforms, containerization technologies (e.g., Docker, Kubernetes), and data pipeline tools (e.g., Apache Kafka, Spark) Experience working in cross-functional teams Strong analytical and problem solving skills",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology and Engineering",
      "Industries": "Banking"
    },
    "skills": [
      "Python",
      "Java",
      "C++",
      "Machine Learning",
      "Deep Learning",
      "TensorFlow",
      "PyTorch",
      "Hugging Face",
      "LLM",
      "GAN",
      "VAE",
      "Docker",
      "Kubernetes",
      "Apache Kafka",
      "Spark",
      "Containerization"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_007"
  },
  {
    "job_id": "ai-software-engineer-at-dhl-4327806638",
    "title": "AI Software Engineer",
    "company": "DHL",
    "location": "Indore, Madhya Pradesh, India",
    "posted_date": "2025-12-15",
    "job_url": "https://in.linkedin.com/jobs/view/ai-software-engineer-at-dhl-4327806638?position=5&pageNum=0&refId=JH5LtPms9UPQegO7jG12qA%3D%3D&trackingId=G71W55S3xqrjGXrLIq6DWQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939343",
    "description": "Your IT Future, DeliveredSoftware Engineer (Python, Gen AI)With a global team of 6000+ IT professionals, DHL IT Services connects people and keeps the global economy running by continuously innovating and creating sustainable digital solutions. We work beyond global borders and push boundaries across all dimensions of logistics. You can leave your mark shaping the technology backbone of the biggest logistics company of the world. Our offices in Cyberjaya, Prague, and Chennai have earned #GreatPlaceToWork certification, reflecting our commitment to exceptional employee experiences.Digitalization. Simply delivered.At IT Services, we are passionate about Generative AI. Our Warehousing team is continuously expanding. No matter your level of AI Software Engineer proficiency, you can always grow within our diverse environment.#DHL #DHLITServices #GreatPlaceGrow togetherThe role of a Software Engineer is a combination of project delivery and support. Software Engineers are an important part of an agile team, they need to understand and implement the requirements by business. As part of a DevOps Team, they solve incidents based on tickets, take care of a proper monitoring of the system and implement CR’s after the Go Live of a product. On top of it they bring improvement ideas in the discussions to increase quality and develop the product further.Ready to embark on the journey? Here’s what we are looking for:As a Software Engineer, having Python experience, Prompt Engineering and Generative AI models, use cases knowledge is a huge plus. Very good knowledge of Software Development Methodologies and DevSecOps process and tools will also be an integral part of this role.You are a GenAI aficionado, therefore you have a good understanding of version control systems (e.g., Git) and project management tools, analytical and soft skills. You are able to work independently prioritize and organize your tasks under time and workload pressure. Working in a multinational environment, you can expect cross-region collaboration with teams around the globe, thus being advanced in spoken and written English will be certainly useful.An array of benefits for you:Hybrid work arrangements to balance in-office collaboration and home flexibility.Annual Leave: 42 days off apart from Public / National Holidays.Medical Insurance: Self + Spouse + 2 children. An option to opt for Voluntary Parental Insurance (Parents / Parent -in-laws) at a nominal premium covering pre existing disease.In House training programs: professional and technical training certifications.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Transportation, Logistics, Supply Chain and Storage"
    },
    "skills": [
      "Python",
      "Prompt Engineering",
      "Generative AI",
      "Version Control",
      "DevSecOps",
      "Git"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_008"
  },
  {
    "job_id": "ai-software-engineer-at-dhl-4327863594",
    "title": "AI Software Engineer",
    "company": "DHL",
    "location": "Indore, Madhya Pradesh, India",
    "posted_date": "2025-12-15",
    "job_url": "https://in.linkedin.com/jobs/view/ai-software-engineer-at-dhl-4327863594?position=10&pageNum=0&refId=JH5LtPms9UPQegO7jG12qA%3D%3D&trackingId=rx8hBjMo2vlNhJsGKGajhg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939346",
    "description": "Your IT Future, Delivered.AI Software Engineer (Python, GenAI)With a global team of 5600+ IT professionals, DHL IT Services connects people and keeps the global economy running by continuously innovating and creating sustainable digital solutions. We work beyond global borders and push boundaries across all dimensions of logistics. You can leave your mark shaping the technology backbone of the biggest logistics company of the world. All our offices have earned #GreatPlaceToWork certification, reflecting our commitment to exceptional employee experiences.Digitalization. Simply delivered.At IT Services, we are passionate about technology. Our team is continuously expanding. No matter your level of Architecture proficiency, you can always grow within our diverse environment.#DHL #DHLITServices #GreatPlaceGrow together.The role of an AI Engineer is the pathfinder for the Engineering team. AI Engineers need to be able to understand the challenges on the ground and find solution to improve efficiency in delivering solutions for faster time to market. AI Engineer is proficient in leveraging available AI tools in applying real world use cases for better productivity.Ready to embark on the journey? Here’s what we are looking for:As an AI Engineer, having Python experience, Prompt Engineering and Generative AI models, and AI use cases application is required. Also, knowledge of AI workflow tools such as LangChain and n8n will be a huge plus to help our company improve our business and IT processes with better efficiency, breaking down tasks to use the right learning models, while grounding results via “context engineering” using RAG and MCP protocols to ensure only relevant and good quality results are produced.Aside from that, you should be able to work independently prioritize and organize your tasks under time and workload pressure. Working in a multinational environment, you can expect cross-region collaboration with teams around the globe, thus being advanced in spoken and written English will be certainly useful.Ready to embark on the journey? Here’s what we are looking for:As a Software Engineer, having Python experience, Prompt Engineering and Generative AI models, use cases knowledge is a huge plus. Very good knowledge of Software Development Methodologies and DevSecOps process and tools and Java & Node.js programming language will also be an integral part of this role.You are a GenAI aficionado, therefore you have a good understanding of version control systems (e.g., Git) and project management tools, analytical and soft skills. You are able to work independently prioritize and organize your tasks under time and workload pressure. Working in a multinational environment, you can expect cross-region collaboration with teams around the globe, thus being advanced in spoken and written English will be certainly useful.An array of benefits for you:Hybrid work arrangements to balance in-office collaboration and home flexibility.Annual Leave: 42 days off apart from Public / National Holidays.Medical Insurance: Self + Spouse + 2 children. An option to opt for Voluntary Parental Insurance (Parents / Parent -in-laws) at a nominal premium covering pre existing disease.In House training programs: professional and technical training certifications.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Transportation, Logistics, Supply Chain and Storage"
    },
    "skills": [
      "Python",
      "Prompt Engineering",
      "Generative AI",
      "LangChain",
      "n8n",
      "RAG",
      "MCP",
      "Java",
      "Node.js",
      "Version Control",
      "DevSecOps",
      "Git"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_009"
  },
  {
    "job_id": "ai-ml-software-engineer-at-ebay-4265461193",
    "title": "AI/ML Software Engineer",
    "company": "eBay",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-12",
    "job_url": "https://in.linkedin.com/jobs/view/ai-ml-software-engineer-at-ebay-4265461193?position=18&pageNum=0&refId=JH5LtPms9UPQegO7jG12qA%3D%3D&trackingId=8HLOH5VFZfb5jWt4I4uZEw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939349",
    "description": "At eBay, we're more than a global ecommerce leader — we’re changing the way the world shops and sells. Our platform empowers millions of buyers and sellers in more than 190 markets around the world. We’re committed to pushing boundaries and leaving our mark as we reinvent the future of ecommerce for enthusiasts.Our customers are our compass, authenticity thrives, bold ideas are welcome, and everyone can bring their unique selves to work — every day. We're in this together, sustaining the future of our customers, our company, and our planet.Join a team of passionate thinkers, innovators, and dreamers — and help us connect people and build communities to create economic opportunity for all.About The Team And RoleThe Compliance Engineering team at eBay is focused on prohibited, restricted, and counterfeit compliance detection is dedicated to ensuring that eBay’s marketplace adheres to all relevant regulations and internal policies.The team develops and maintain advanced, AI-driven tools and scalable backend systems that automatically identify and assess items listed on the platform. By applying sophisticated data models, machine learning algorithms, and rules-based engines, they detect products that may be illegal, harmful, non-compliant with trade regulations, or counterfeit.Overall, this Compliance Engineering team plays a crucial role in maintaining trust in eBay’s platform, safeguarding customers, and upholding the company’s dedication to a fair, safe, and legally compliant marketplace.What You Will AccomplishBuild large-scale applications, low-latency APIs, data pipelines, and foundational architectures to support eBay’s business operations and customer experiences.Design and implement highly configurable, metadata-driven platforms to enable seamless ingestion of attributes, rules, models, policies, and derived aggregates.Develop machine learning models and Gen AI tools to generate insights and improve customer experiences across eBay.Partner with architects, business leaders, and industry experts to devise strategies and scalable solutions.Be responsible for the entire software lifecycle, including design, development, testing, and experimentation.Mentor and lead junior team members by setting examples and guiding them toward success.What You Will BringPrefer Technical degree with 3-5+ years of relevant software development experience.Strong hands on Machine Leaning experience, AI/ML/Gen AI, LLM's and proven experience in building and running AI/ML/GenAI models in production environments.Outstanding programming skills in Java, Scala, and Python, with hands-on experience in frameworks like PyTorch and TensorFlow.Proven experience with APIs and Distributed Systems, building and consuming horizontally scalable RESTful APIs, GraphQL, and distributed systems.Hands-on experience with technologies like Spark, Flink, and Kafka with practical experience in their use.Strong understanding of SQL, NoSQL, and sophisticated data modeling techniques.Hands-on experience with the Hadoop ecosystem (HDFS, MapReduce, Hive, Spark) for building and optimizing large-scale data solutions.Please see the Talent Privacy Notice for information regarding how eBay handles your personal data collected when you use the eBay Careers website or apply for a job with eBay.eBay is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, sex, sexual orientation, gender identity, veteran status, and disability, or other legally protected status. If you have a need that requires accommodation, please contact us at talent@ebay.com. We will make every effort to respond to your request for accommodation as soon as possible. View our accessibility statement to learn more about eBay's commitment to ensuring digital accessibility for people with disabilities.The eBay Jobs website uses cookies to enhance your experience. By continuing to browse the site, you agree to our use of cookies. Visit our Privacy Center for more information.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Java",
      "Scala",
      "Python",
      "PyTorch",
      "TensorFlow",
      "APIs",
      "RESTful API",
      "GraphQL",
      "Spark",
      "Flink",
      "Kafka",
      "SQL",
      "NoSQL",
      "Hadoop",
      "HDFS",
      "MapReduce",
      "Hive",
      "Machine Learning",
      "GenAI",
      "LLM"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_011"
  },
  {
    "job_id": "machine-learning-engineer-intern-at-tinder-4323750983",
    "title": "Machine Learning Engineer Intern",
    "company": "Tinder",
    "location": "Palo Alto, CA",
    "posted_date": "2025-12-03",
    "job_url": "https://www.linkedin.com/jobs/view/machine-learning-engineer-intern-at-tinder-4323750983?position=1&pageNum=0&refId=M69P3ALFQHLqYOLiOeqtsA%3D%3D&trackingId=TAfkLwDU9OQ3gn1DmsahwA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939352",
    "description": "Our MissionAs humans, there are few things more exciting than meeting someone new. At Tinder, we’re inspired by the challenge of keeping the magic of human connection alive. With tens of millions of users, hundreds of millions of downloads, 2+ billion swipes per day, 20+ million matches per day, and a presence in 190+ countries, our reach is expansive—and rapidly growing.We work together to solve complex problems. Behind the simplicity of every match, we think deeply about human relationships, behavioral science, network economics, AI and ML, online and real-world safety, cultural nuances, loneliness, love, sex, and more.Program DurationThe internship program will run from June 1 through August 28, 2026.Where you’ll workThis is a hybrid role that requires in-office collaboration three days per week in Palo Alto, California. About the Role The Tinder ML team drives impact across nearly every core domain of the product — from Recommendations and Trust & Safety to Profile, Chat, Growth, and Revenue. Our mission is to apply machine learning to enhance user experiences, foster trust, and accelerate business growth across Tinder’s ecosystem. With Tinder's global scale and impact, you'll be at the forefront of solving some of the most complex challenges in technology. In this internship program, you will collaborate with senior engineers to build and deploy ML solutions that advance Tinder’s business goals.What you'll do:Gain real-world experience on exciting challenges to improve the user experienceDesign and implement machine learning algorithms for the assigned domains: Recommendation, Trust, Profile, Chat, Growth, or Revenue. Experience the ML model formulation of production problem under the guidanceWork closely with a Senior Engineers to develop machine learning solutions to further Tinder’s business goalsParticipate in the annual Tindership Hackathon, presenting with your team to the entire Tinder team and panel of executives. What we're looking for:Aspiring ML Engineer who’s excited to work on large scale challenges with cutting-edge technologyPractical knowledge of how to build efficient end-to-end ML workflowsProficient in Python. Hands-on experience in designing and building ML modelsFoundational knowledge of basic Computer Science principles: data structures and algorithms. Currently pursuing a BS/BA or MS in Computer Science or a related field. Nice to have:Publications in top ML or data science conferences (e.g., NeurIPS, ICML, RecSys, KDD)Experience deploying ML models in production environmentsFamiliarity with deep learning frameworks such as PyTorch, TensorFlow, or KerasExperience with Databricks, Spark, or AirflowProficiency in additional programming languages like Go, Java or ScalaCommitment to InclusionAt Tinder, we don’t just accept difference, we celebrate it. We strive to build a workplace that reflects the rich diversity of our members around the world, and we value unique perspectives and backgrounds. Even if you don’t meet all the listed qualifications, we invite you to apply and show us how your skills could transfer. Tinder is proud to be an equal opportunity workplace where we welcome people of all sexes, gender identities, races, ethnicities, disabilities, and other lived experiences. Learn more here: https://www.lifeattinder.com/deiIf you require reasonable accommodation to complete a job application, pre-employment testing, or a job interview or to otherwise participate in the hiring process, please speak to your Talent Acquisition Partner directly.#TinderWe may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.The compensation range listed above is representative of the hourly rate offered. Factors such as scope and responsibilities of the position, candidate's work experience, education/training, job-related skills, internal peer equity, as well as market and business considerations may influence base pay offered. This salary range is reflective of a position based in Palo Alto, California. This hourly rate will be subject to a geographic adjustment (according to a specific city, state, and country), if an authorization is granted to work outside of the location listed in this posting.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Internship",
      "Job function": "Engineering",
      "Industries": "Software Development, Consumer Services, and Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Java",
      "Go",
      "Machine Learning",
      "Deep Learning",
      "TensorFlow",
      "PyTorch",
      "Databricks",
      "Spark",
      "Airflow",
      "Keras",
      "Data Structures",
      "Algorithms"
    ],
    "role_tag": "AIML",
    "role_key": "ai_ml_engineer",
    "job_role_id": "AIML_20251218_004"
  },
  {
    "job_id": "data-analyst-fixed-term-contract-at-hatton-national-bank-plc-4324664637",
    "title": "Data Analyst (Fixed Term Contract)",
    "company": "Hatton National Bank PLC",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-11-27",
    "job_url": "https://lk.linkedin.com/jobs/view/data-analyst-fixed-term-contract-at-hatton-national-bank-plc-4324664637?position=2&pageNum=0&refId=6oQDz6V%2FWe7nZkn11k6Jgw%3D%3D&trackingId=syqr7UPL%2BjEXxOcUY%2Bl1AQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939355",
    "description": "Join HNB and Shape the Future of Data-Driven BankingHatton National Bank PLC is strengthening its advanced analytics capabilities to support strategic initiatives such as customer profiling, hyper-personalization, revenue growth, SME/Wholesale insights, and predictive analytics. We are seeking analytical and motivated professionals to join our team as Data Analysts (Contract Basis – 1 year, renewable).What You Will DoLead and execute analytics projects across Retail, SME, Wholesale, Savings, and Branch Network.Build dashboards, automated reports, and BI solutions using Power BI/Tableau.Develop predictive models and machine learning solutions using Python/R.Translate business needs into analytical insights and recommendations.Work closely with BCG, Leap-TMO, and internal business units.Ensure data accuracy, quality, governance, and compliance.What We Are Looking ForImportant: Minimum 1–2 years of experience in data analytics, BI, or predictive modeling is mandatory.Candidates without this experience will not be considered.Bachelor’s degree in Data Science, Statistics, IT, Engineering, Mathematics, Finance Analytics, or a related quantitative field.Strong hands-on experience with SQL and Python/R.Proficiency in BI tools such as Power BI or Tableau.Exposure to machine learning or statistical modeling is preferred.Strong analytical thinking, problem-solving, and communication skills.Why Join HNBOpportunity to work on high-impact analytics use cases across strategic business lines.Learn directly from industry experts and HNB’s analytics leadership.Exposure to modern BI/AI platforms and enterprise-scale datasets.Competitive contractual package with structured learning and development opportunities.If you are ready to contribute to HNB’s analytics-driven transformation, we encourage you to apply.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Contract",
      "Job function": "Information Technology, Finance, and Analyst",
      "Industries": "Banking"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "Machine Learning",
      "Statistics",
      "Tableau",
      "Power BI",
      "Predictive Modeling",
      "Data Analytics"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_002"
  },
  {
    "job_id": "data-analyst-dashboard-development-analytics-at-pbg-4343658157",
    "title": "Data Analyst - Dashboard Development & Analytics",
    "company": "PBG",
    "location": "United States",
    "posted_date": "2025-12-15",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-dashboard-development-analytics-at-pbg-4343658157?position=2&pageNum=0&refId=TrpIYz%2BrGMppGBxfv%2BmLeg%3D%3D&trackingId=5qXcSlpNFKIoTH9NKtwwCA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939358",
    "description": "PBG delivers mission-focused solutions that eliminate inefficiency and power transformation for federal agencies requiring agility, security, and impact.Position: Data Analyst - Dashboard Development & AnalyticsLocation: Remote - Candidates must be U.S. citizens and live in the U.S.Clearance/Screening: Active Secret ClearancePosition SummaryThe Data Analyst – Dashboard Development & Analytics supports executive decision-making through the design, development, and maintenance of automated dashboards, analytics products, and reporting solutions. This role focuses on transforming complex operational and survey data into clear, actionable insights using modern visualization tools and automation techniques. The analyst works closely with cross-functional teams, government stakeholders, and contractor leadership to ensure reporting products are accurate, reliable, and aligned with evolving mission needs.Key Responsibilities Design, develop, and maintain executive dashboards and reporting products using Power BI, Microsoft Excel, and automated Word and PowerPoint outputs. Support operational, compliance, and leadership reporting across multiple functional teams and workstreams. Translate complex datasets into intuitive visualizations and narrative insights that support executive-level decision-making. Collaborate with government leads, technical teams, and contractor staff to refine requirements and adapt reporting to changing stakeholder needs. Apply analytics best practices to streamline and automate data collection, transformation, and visualization workflows using Excel macros, R, and similar tools. Conduct data validation, testing, and quality checks to ensure accuracy, consistency, and reliability on the dashboard. Identify trends, anomalies, and strategic insights through structured analysis of operational and survey-based datasets. Develop and maintain comprehensive documentation, including data dictionaries, dashboard logic, process flows, and reporting methodologies using Excel, OneNote, and Visio. Manage multiple concurrent analytics efforts independently while maintaining consistent communication and delivery timelines.Required Qualifications Demonstrated experience designing, building, and maintaining executive dashboards and automated reports. Strong proficiency in Power BI, Microsoft Excel (including macros), and Microsoft Word and PowerPoint automation. Experience using R, Python, or similar analytical programming languages for data manipulation and analysis. Ability to clearly communicate analytical findings to both technical and non-technical audiences. Strong attention to detail with the ability to balance data-level precision and strategic context. Minimum 2+ years of experience in analytics, reporting, or dashboard development (additional experience may substitute for formal education). Experience working with operational or survey data; familiarity with tools such as Qualtrics is a plus. Bachelor’s degree in a relevant field or equivalent professional experience.Preferred / Desired Qualifications Experience supporting federal government, defense, or national security-related programs. Familiarity with Agile or project-based delivery environments, particularly as they relate to reporting cycles and iterative improvements. Awareness of emerging analytics and automation capabilities, including AI-enabled reporting and narrative generation tools.Tools & PlatformsPower BI, Microsoft Excel, Word, PowerPoint, SharePoint, OneNote, Visio, R, Python (or similar), Power Automate, survey platforms (e.g., Qualtrics).#WHYPBGWe have successfully built a company culture based on our single most important asset - our employees. At PBG we are passionate about employee engagement and make it our business to provide our employees a range of challenging and rewarding opportunities that align with business strategy, promote team work and inspire innovation. A job is where you are spending most of your day, so PBG believes in making it a fun, collaborative and productive environment. We want our employees to have the opportunity to grow and be part of a company that is making a lasting contribution to our customers. Benefits:401K Retirement PlanMedical Plan options with significant financial investments from PBGPrescription benefit planDental and Vision coverageEmployee Assistance ProgramShort term / Long-term disabilitySupplemental group life and AD&D optionsYearly BonusesGenerous Paid Time Off / Paid HolidaysCareer/Professional Development ProgramSpot Bonus ProgramEqual Employment Opportunity Statement:PBG is an equal opportunity employer and makes all employment decisions based on job-related qualifications, skills, experience, and business needs. We do not discriminate against any applicant or employee based on legally protected characteristics, including but not limited to race, color, religion, sex, national origin, age, disability, genetic information, or veteran status, in accordance with applicable federal, state, and local laws. PBG complies with all laws regarding non-discrimination in employment in every location in which the company operatesDisclaimer:This job description reflects management's assignment of essential job functions but is not intended to be a comprehensive list of all activities, duties and responsibilities required by the job incumbent. Nothing in the herein restricts management's right to assign or reassign duties and responsibilities to this job at any time.This document does not create an employment contract, implied or otherwise, other than an \"at will\" relationship.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Construction, Software Development, and IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "R",
      "Power BI",
      "Excel",
      "Macros",
      "Reporting",
      "Analytics",
      "Automation",
      "Data Visualization"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_004"
  },
  {
    "job_id": "data-analyst-at-kpmg-india-4323182631",
    "title": "Data Analyst",
    "company": "KPMG India",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-11",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-kpmg-india-4323182631?position=1&pageNum=0&refId=zQuGmjIjWh3%2B6jee%2Fkv26A%3D%3D&trackingId=CkT99WD2lKq21ZkXiifHJA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939362",
    "description": "About KPMG in India :KPMG entities in India are professional services firm(s). These Indian member firms are affiliated with KPMG International Limited. KPMG was established in India in August 1993. Our professionals leverage the global network of firms, and are conversant with local laws, regulations, markets and competition. KPMG has offices across India in Ahmedabad, Bengaluru, Chandigarh, Chennai, Gurugram, Jaipur, Hyderabad, Jaipur, Kochi, Kolkata, Mumbai, Noida, Pune, Vadodara and Vijayawada.KPMG entities in India offer services to national and international clients in India across sectors. We strive to provide rapid, performance-based, industry-focused, and technology-enabled services, which reflect a shared knowledge of global and local industries and our experience of the Indian business environment.About the Job :Location - Bangalore/Gurgaon/PuneExperience - 6+ YearsFunctional SkillsDetermining, creating, and implementing internal process improvements, such as redesigning infrastructure for increased scalability, improving data delivery, and automating manual procedures.Building analytical tools that make use of the data flow and offer a practical understanding of crucial company performance indicators like operational effectiveness and customer acquisition.Helping stakeholders, including the data, design, product, and executive teams, with technical data difficulties.Working on data-related technical challenges while collaborating with stakeholders, including the Executive, Product, Data, and Design teams, to support their data infrastructure needs.Remaining up to date with developments in technology and industry norms can help you to produce higher-quality results.Technical Skills:Analyze large datasets to derive actionable insights and support decision-making processes.Develop and maintain data pipelines using PySpark and other data processing tools.Write efficient SQL queries to extract, transform, and load data from various sources.Implement data models and schemas to organize and optimize data storage and retrieval.Perform data normalization and denormalization to ensure data integrity and accessibility.Collaborate with data engineers to centralize and manage data assets.Ensure data quality through validation and cleansing processes.Utilize CI/CD pipelines to streamline data deployment and maintain continuous integration.Qualifications:6 years or more Proven experience in data analytics and working with large datasets.Proficiency in Python, including libraries such as Pandas and Numpy for data manipulation.Strong SQL skills for querying and managing databases.Experience with PySpark for large-scale data processing.Basic understanding of Hadoop and its ecosystem.Familiarity with data engineering concepts and best practices.Knowledge of data modeling, including schemas, normalization, and denormalization techniques.Understanding of data centralization, cardinality, and data quality principles.Good to have experience in CI/CD pipelines and toolsBanking Deep understanding of banking operations, financial products, and regulatory frameworksExperience with data modeling, ETL processes, and statistical analysisPrior experience in retail or corporate banking analyticsAnalyze banking data including customer transactions, loan performance, and financial statementsSupport credit risk analysis and fraud detection initiativesMaintain and optimize banking databases and data pipelinesEqual employment opportunity informationKPMG India has a policy of providing equal opportunity for all applicants and employees regardless of their color, caste, religion, age, sex/gender, national origin, citizenship, sexual orientation, gender identity or expression, disability or other legally protected status. KPMG India values diversity and we request you to submit the details below to support us in our endeavor for diversity. Providing the below information is voluntary and refusal to submit such information will not be prejudicial to you.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Banking, Financial Services, and Insurance"
    },
    "skills": [
      "Python",
      "SQL",
      "Pandas",
      "NumPy",
      "Data Modeling",
      "CI/CD",
      "PySpark",
      "Hadoop",
      "ETL",
      "Data Quality",
      "Analytics"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_006"
  },
  {
    "job_id": "data-analyst-at-birla-opus-4341279420",
    "title": "Data Analyst",
    "company": "Birla Opus",
    "location": "Maharashtra, India",
    "posted_date": "2025-12-03",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-birla-opus-4341279420?position=3&pageNum=0&refId=zQuGmjIjWh3%2B6jee%2Fkv26A%3D%3D&trackingId=a9W9ZZcqiyAWa76YbStPbg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939365",
    "description": "About The RoleWe are looking for a highly analytical and business-oriented Data Analyst to join our– Analytics team. This role is ideal for someone who can turn data into insights across both Business, supporting strategic decisions and enhancing business performance across functions i.e sales, marketing and supply chainWe are looking for a highly analytical and business-oriented Data Analyst to join our team. This role is ideal for someone who can turn data into insights across both Business, supporting strategic decisions and enhancing business performance across functions i.e sales, marketing and supply chain.Analyze business performance across digital (web, app, campaigns) and non-digital channels (retail, call centers, field operations, Institutional franchise , painting service ) to identify trends, gaps, and opportunities.Translate business challenges into analytical models and deliver actionable insights.Develop and maintain dashboards and reports using Power BI to visualize KPIs and performance metrics.Conduct secondary research to support strategic planning and customer understanding.Present insights through data storytelling to influence stakeholders and support decision-making.Monitor and report on monthly performance across key areas including: Sales, Marketing, Customer Experience (CX), Supply Chain, Finance.Identify grey areas, improvement opportunities, and high-performing segments through deep-dive analysis.Collaborate with cross-functional teams to explore and implement data-driven solutions that improve business effectiveness.Collaborate with cross-functional teams within the organization to explore and implement data-driven solutions that improve business effectiveness.Strong proficiency in SQL for querying and managing large datasets.Hands-on experience with Python and data libraries (Pandas, NumPy, Matplotlib, Seaborn).Solid understanding of statistics and business metrics.Expertise in Power BI or similar tools for data visualization and dashboarding.Excellent presentation and communication skills to convey insights clearly.Familiarity with digital analytics tools (e.g., Google Analytics, Adobe Analytics) and experience working with non-digital data sources.Ability to manage multiple stakeholders and work in a fast-paced environment.Preferred QualificationsDegree in Business Analytics, Data Science, Statistics, Economics, or a related field from a premier institute.Prior experience in Digital & Omnichannel Business Analytics, E-commerce, or Customer Experience (CX) domains.Exposure to A/B testing, customer segmentation ,decision trees etc.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Chemical Manufacturing"
    },
    "skills": [
      "Python",
      "SQL",
      "Pandas",
      "NumPy",
      "Statistics",
      "A/B Testing",
      "Matplotlib",
      "Seaborn",
      "Power BI",
      "Data Visualization",
      "Dashboarding"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_007"
  },
  {
    "job_id": "data-analyst-at-sonovate-4343783167",
    "title": "Data Analyst",
    "company": "Sonovate",
    "location": "Cardiff, Wales, United Kingdom",
    "posted_date": "2025-12-15",
    "job_url": "https://uk.linkedin.com/jobs/view/data-analyst-at-sonovate-4343783167?position=1&pageNum=0&refId=WpmKjp3I28FNHvBbhMCAlA%3D%3D&trackingId=%2FKUgqCkE3GKsFjuZD%2B4aUQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939369",
    "description": "Job title: Data Analyst – (Operational Performance)Location: Cardiff or London (Hybrid working) About SonovateSonovate is lending and technology company with a clear vision: to be The Funding Platform for the Future of Work. Our embedded payment solution empowers the new world of work. By offering flexible payments, it lets recruiters, consultants, and labour marketplaces place contractors and freelancers to unlock their cashflow to capitalise on the opportunities that flexible working provides. This means our customers can draw funds as and when they need them to pay their workers while waiting for end clients to pay them on their own terms.Role OverviewWe are looking for a Data Analyst (Operational performance) to drive business success by analysing business unit performance and pinpointing what drives profitability. You’ll turn insights into practical strategies that boost growth, improve client retention, and encourage the right behaviours through effective incentive schemes.This role blends advanced analytical skills with commercial awareness, using SQL expertise to provide clear, actionable insights that support data-driven decisions and deliver real results. Reporting to the Head of Data & Analytics, you’ll have full access to the data needed to achieve the objectives set by the Chief People Officer.Key Responsibilities:Business Unit Performance Analysis Assess revenue composition, cost structure, and profitability across all business units aligned to Annual Rocks and Cash flow positivity.Build and maintain SQL queries in our BI tool' and work with the data team to architect and deploy efficient maintainable solutions into our dbt models.Leverage advanced SQL and Python skills to maximise BI tools.Establish baseline metrics for growth and performance tracking.Growth & Retention StrategyTranslate profitability insights into targeted actions for each business unit.Analyse churn and client behaviour data to identify retention risks and opportunities.Partner with leadership to align operational priorities with customer-centric strategies.Incentive Scheme Design Evaluate current incentive structures and their behavioural impact.Define desired behaviours (e.g., collaboration, upselling, retention focus) and ensure schemes reinforce these.Design and implement commission structures for CSM, CE, and Sales teams that balance short-term wins with long-term value.Performance Measurement & InsightsImplement timely performance dashboards for business units and functions.Deliver actionable insights to enable data-driven decisions at leadership level.Create a feedback loop where measurement informs strategy for continuous improvement.Core Technical Skills SQL Expertise – Ability to write complex queries and manipulate large datasetsData Analysis & Interpretation – Skilled at turning raw data into actionable insights.Financial Acumen – Understanding of revenue, cost structures, profitability, and ROI analysis.Dashboard & Reporting Tools – Experience creating BI and performance dashboards and automated reports. Strong analytical and problem-solving skills with ability to interpret complex data.Key Deliverables Successful Delivery of Outputs / Milestones: time and expected deliveryAccuracy & Timeliness of Reporting: Monthly and quarterly performance reports delivered on schedule; with continuous improvement.Profitability Insights presented aligned to rocks.Data Accessibility: SQL queries and dashboards maintained.What will you get in return?28 days holiday + bank holidaysPrivate medical insurance with BupaEmployee Assistance ProgrammeTechscheme with Apple and Currys PC WorldCycleschemeWorking with latest technologies and leading SaaS providersEye care vouchers with Specsavers50% discounted gym membership50% off mobile apps (Calm, Duolingo, Audible, Les Mills)2 days charity leave per yearYou’ll work for a company that is passionate about personal development and a strong community focussed cultureSound interesting?If your answer is ‘yes’ then click apply to find out more!If you require any reasonable adjustments to support you during the interview process, please let our Talent Acquisition Partner (Alex Morrell) know and we'd be happy to help!We know that diverse teams are strong teams. We promote a diverse, inclusive and empowering culture and are committed to recruiting, retaining and developing all our employeesPlease note: All successful applicants who are offered a role at Sonovate will be required to pass background screening checks before starting with us. These checks will include National ID Checks, Right to Work, Employment References, Adverse Financial History, Criminal Record, Global Sanctions, Bankruptcy checks. Our Talent Acquisition team will be able to run you through these in detail at the early stage of your application",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology, Analyst, and Human Resources",
      "Industries": "Financial Services"
    },
    "skills": [
      "Python",
      "SQL",
      "dbt",
      "Reporting",
      "Metrics",
      "Analytics",
      "Dashboard",
      "Business Intelligence"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_008"
  },
  {
    "job_id": "data-analyst-at-morgan-mckinley-4327674841",
    "title": "Data Analyst",
    "company": "Morgan McKinley",
    "location": "Belfast, Northern Ireland, United Kingdom",
    "posted_date": "2025-12-16",
    "job_url": "https://uk.linkedin.com/jobs/view/data-analyst-at-morgan-mckinley-4327674841?position=2&pageNum=0&refId=WpmKjp3I28FNHvBbhMCAlA%3D%3D&trackingId=S2m%2BceMA1itCqIm2t4UfeQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939372",
    "description": "🚀 Contract Opportunity – Markets Data / Risk & Controls Specialist📍 Belfast (Hybrid)💷 £558 per day | ⏳ 6–12 Month ContractWe are currently seeking an experienced Markets Data / Risk & Controls Contractor to join a high-profile Markets function based in Belfast, operating on a hybrid model (3 days onsite / 2 days remote).Key RequirementsWe are looking for contractors with 8–12 years’ experience and a strong background across Markets, data, and controls, including:Solid Markets product and business knowledge from a practical, hands-on perspectiveStrong understanding of data flows and Markets infrastructureProven risk and control experience, with the ability to design, implement, run, and operate controlsExperience working with regulatory requirement operating models, Internal Audit expectations, and regulatory standardsDeep understanding of Trade / Transactional data and the ability to interpret what the data actually representsExcellent communication and critical thinking skills, with the ability to engage effectively with Markets stakeholdersAdditional DetailsRate: £558 per day via umbrellaContract Length: 6–12 monthsLocation: BelfastWorking Pattern: Hybrid (3 days onsite per week)Equipment: Contractors must provide their own laptop",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Contract",
      "Job function": "Analyst",
      "Industries": "Investment Banking and Financial Services"
    },
    "skills": [
      "Data Flows",
      "Risk and Controls",
      "Trade Data",
      "SQL"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_009"
  },
  {
    "job_id": "data-analyst-at-uniperms-4343627051",
    "title": "Data Analyst",
    "company": "Uniperms",
    "location": "Coventry, England, United Kingdom",
    "posted_date": "2025-12-15",
    "job_url": "https://uk.linkedin.com/jobs/view/data-analyst-at-uniperms-4343627051?position=3&pageNum=0&refId=WpmKjp3I28FNHvBbhMCAlA%3D%3D&trackingId=huVHmP1vzK6NgJLYO4cCag%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939374",
    "description": "We are seeking a Data Analyst to play a pivotal role in enabling the work of our Development and Alumni Engagement (DAE) team. This position focuses on delivering high-quality management information that informs strategic decision-making across the department.You will work in a dynamic environment, balancing challenging timescales, fluctuating demands, and finite resources while ensuring exceptional service delivery. Your analysis will underpin key activities such as fundraising campaigns, alumni engagement initiatives, and strategic planning.Key ResponsibilitiesDevelop and provide timely, high-quality management information for DAE, as directed by the Information Systems Manager.Deliver ad-hoc analysis and structured projects, including:Technical modelling (e.g., prospect pipeline models for fundraising campaigns).Extended analysis (e.g., comparative alumni engagement by international region).Source and integrate internal and external data, applying agreed presentation standards.Identify, analyse, and interpret patterns in complex datasets.Collaborate with administrative and academic departments to support cross-functional projects.Conduct quantitative and qualitative analysis of fundraising and alumni engagement activities.Support the Head of Systems & Insight with timely metrics for campaign planning and process improvement.Provide bespoke analysis for DAE processes, including annual CASE Insight Survey and CASE AEM Atlas Survey.Work with the Strategic Programmes and Analytics (SPA) team on various projects throughout the year.Advise on data collection, enhancement projects, and improvements to data entry for better reporting.Promote continuous improvement and explore new tools (e.g., Alteryx, Power BI, R).About YouWe are looking for a proactive and detail-oriented individual with:Education: A good educational background, ideally a 2:1 Honours degree or equivalent. Technical Expertise:Extensive experience using spreadsheets and databases (including SQL) to manipulate and analyse large datasets.Proven ability to develop reports and dashboards in Power BI.Familiarity with tools such as Python, MS SQL Server Management Studio, R, and MS Power Platform.Analytical Skills:Strong numeracy and statistical skills.Ability to analyse qualitative and quantitative data, draw reasoned conclusions, and present findings in a clear, intuitive way.Project Management:Demonstrable experience managing projects, with excellent organisational and operational planning skills.Ability to handle a varied and heavy workload under challenging timescales.Problem-Solving & Creativity:Innovative approach to tackling complex problems and improving processes.Communication & Interpersonal Skills:Excellent oral and written communication skills, including report writing and presenting complex arguments.Ability to build professional relationships, negotiate effectively, and maintain confidentiality.IT Skills:Confidence with Microsoft Office applications (ECDL or equivalent as a minimum).Compliance:A sound understanding of data protection principles and GDPR.Why Join Us?This is an exciting opportunity to make a real impact on the success of our fundraising and alumni engagement strategies. You’ll work in a supportive team environment that values innovation, collaboration, and continuous improvement.BenefitsCompetitive salary and generous holiday allowance.Access to professional development opportunities.Flexible working arrangements and a supportive work culture.Excellent pension scheme and staff benefits.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Analyst and Information Technology",
      "Industries": "Higher Education"
    },
    "skills": [
      "Python",
      "R",
      "SQL",
      "SQL Server",
      "Power BI",
      "Reporting",
      "Metrics",
      "Analytics",
      "Data Visualization"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_010"
  },
  {
    "job_id": "data-analyst-at-new-york-state-unified-court-system-4344230382",
    "title": "Data Analyst",
    "company": "New York State Unified Court System",
    "location": "Albany, NY",
    "posted_date": "2025-12-16",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-new-york-state-unified-court-system-4344230382?position=1&pageNum=0&refId=TrpIYz%2BrGMppGBxfv%2BmLeg%3D%3D&trackingId=JNNvumZLZhFgsu06FxavKw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939377",
    "description": "The Principal Court Analyst will be assigned to the Clean Slate Data Quality Team within the Division of Technology and Court Research’s Criminal Disposition Reporting (CDR) Unit.With a focus on data quality, the selected candidate will gather business requirements and perform analyses to determine system, data, and reporting requirements. The analyst will document requirements, do data entry, perform system testing, and create official documentation. The selected candidate will be working with criminal court staff to resolve data inconsistencies, reporting errors, and provide system training. Strong customer service and communication skills are required.Candidates must be detail-oriented and possess strong problem-solving skills and must be willing to learn new systems and technology.Experience with development of user training materials, help desk support and technology system implementation is preferred.Knowledge of the business practices of New York State criminal courts and their case management systems is preferred but not required.The ability to write SQL queries is preferred but not required.Occasional travel within New York State may be required.Qualifications: One year in the Senior Court Analyst title; or Bachelor's degree from an accredited college or university and three (3) years of relevant experience; or Master's degree in Public or Business Administration from an accredited college or university and two (2) years of relevant experience or An equivalent combination of education and experience. Salary: $84,659This position has potential to be eligible for one day of telecommuting per week.The Unified Court System does not participate in e-verify, therefore we are not able to accept candidates on F-1 or OPT Visa's.View full posting here: 15167.pdf",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Analyst",
      "Industries": "Administration of Justice"
    },
    "skills": [
      "SQL",
      "Data Quality",
      "Reporting",
      "System Testing",
      "Documentation"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_003"
  },
  {
    "job_id": "data-analyst-at-the-walt-disney-company-4343923967",
    "title": "Data Analyst",
    "company": "The Walt Disney Company",
    "location": "Seattle, WA",
    "posted_date": "2025-12-16",
    "job_url": "https://www.linkedin.com/jobs/view/data-analyst-at-the-walt-disney-company-4343923967?position=3&pageNum=0&refId=TrpIYz%2BrGMppGBxfv%2BmLeg%3D%3D&trackingId=3mFSUzQbXVxyqWkqao6ebw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939380",
    "description": "Disney Entertainment and ESPN Product & TechnologyTechnology is at the heart of Disney’s past, present, and future. Disney Entertainment and ESPN Product & Technology is a global organization of engineers, product developers, designers, technologists, data scientists, and more – all working to build and advance the technological backbone for Disney’s media business globally.The team marries technology with creativity to build world-class products, enhance storytelling, and drive velocity, innovation, and scalability for our businesses. We are Storytellers and Innovators. Creators and Builders. Entertainers and Engineers. We work with every part of The Walt Disney Company’s media portfolio to advance the technological foundation and consumer media touch points serving millions of people around the world. Here are a few reasons why we think you’d love working here:Building the future of Disney’s media: Our Technologists are designing and building the products and platforms that will power our media, advertising, and distribution businesses for years to come. Reach, Scale & Impact: More than ever, Disney’s technology and products serve as a signature doorway for fans' connections with the company’s brands and stories. Disney+. Hulu. ESPN. ABC. ABC News…and many more. These products and brands – and the unmatched stories, storytellers, and events they carry – matter to millions of people globally. Innovation: We develop and implement groundbreaking products and techniques that shape industry norms and solve complex and distinctive technical problems.The Business Operations team helps guide and articulate technology strategy and research and is responsible for driving the day-to-day operation of the Product & Technology organization, including: project and portfolio management and tracking; organization-level capital, space, and resource management and allocation; process management; technical incident management; and our administrative and workplace experience support team.The Data Analyst role within the Planning and Delivery Operations team partners closely with Portfolio, Finance, HR, Global Program Management (GPM) and leads within our Technology pillars to logistically manage and orchestrate essential business workflows across the organization. This function plays a key role in the execution, optimization, and standardization of the organization’s cost and resource allocation models. You will be involved in the management, integrity, analysis, and documentation of data that support our internal operations, the resourcing necessary to deliver our projects, and cost allocations for the businesses we support.The Data Analyst will develop and maintain frameworks and procedures to produce reporting data in both static and real-time formats while maintaining the highest quality and accuracy. The ideal candidate has proven problem-solving skills, a sense of urgency, and experience with technical programs, data analytics and business operations. This role offers the unique opportunity to work on both tactical actions that drive our near-term business operations, and strategic initiatives that will define our future.ResponsibilitiesBuild a deep understanding of costing and resourcing data related to our internal teams and functional partnersSupport internal business workflows, such as service costing, workforce management, and resource planningTrack and report on key performance metricsPerform data and compliance audits on a variety of areas such as standardization and timely reporting to ensure consistency and accuracySystem admin and support responsibilities for planning tools that are managed by the teamConduct training on planning tools to enable other team members to become informed and self-proficientAssist in defining, establishing, and implementing enhancements to operational processes, procedural documentation, and tool requirementsProvide support to Product Strategy, Program, and Portfolio teams across the organizationIdentify areas of opportunity for data improvement and operational tactics that improve performance throughout the initiative lifecycleCreate presentations that summarize analytics and tell a story for management reviewCollaborate with project teams, resource managers, and project leaders on resource needs and identify resource constraints when they ariseIdentify, track, and help resolve cross-portfolio dependencies and conflictsSupport Technology Planning and Operations framework, governance, and processesSupport the completion of special projects and deliver ad-hoc requests as requiredBasic Qualifications3+ years of experience in informatics, data analytics, data engineering or technical fieldsStrong written and verbal skills and the ability to communicate effectively across multiple levels of the organizationMust be a team player who is motivated, disciplined, flexible, and able to work effectively in collaborative and autonomous environmentsExhibit critical thinking, problem-solving, and analytical capabilities with strong attention to detailUnderstand the strategic objectives to integrate seemingly disparate goals into a broader plan for synchronized, harmonious execution while delivering high value to the organizationAbility to work and adapt to a fast-paced dynamic environment with consistent changeSolid understanding of technology and business to tell the ‘story’ behind the dataAbility to create and present materials to management to drive decision-making and tell a compelling storyExperience compiling data and building reports/dashboards with BI visualization toolsPossess solid computer skills with proficiency in Microsoft Office and Google SuiteExhibit advanced Excel / Google Sheets knowledge including complex formulasRequired QualificationsExperience working with Smartsheet, Airtable, SQL queries and TableauPreferred QualificationsExperience working with JIRA and Snowflake (SQL)Prior experience in Media/Entertainment is a plus, but not a prerequisiteFamiliarity with data modeling and predictive analyticsRequired EducationBachelor's degree in technical field- Data Science, Statistics, Business Finance/Economics, Informatics, Computer ScienceThe hiring range for this position in Washington is $102,100.00-$136,900.00 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "SQL",
      "Tableau",
      "Smartsheet",
      "Airtable",
      "Excel",
      "Google Sheets",
      "Business Intelligence",
      "Snowflake",
      "Data Modeling",
      "Reporting"
    ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251218_005"
  },
  {
    "job_id": "trainee-data-engineer-business-intelligence-at-qoria-4342764176",
    "title": "Trainee Data Engineer (Business Intelligence)",
    "company": "Qoria",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-12-08",
    "job_url": "https://lk.linkedin.com/jobs/view/trainee-data-engineer-business-intelligence-at-qoria-4342764176?position=1&pageNum=0&refId=PjuzJ6HhpxCZ0envKqfLsQ%3D%3D&trackingId=v3%2BGcWOZcUWj5Zzhcgs9bg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939383",
    "description": "Want to deliver tech with purpose, with people who care?Join us in our mission to create solutions that help keep children safe online.Who we are?Headquartered in Perth, Australia, with offices globally, Qoria is an ASX listed global leader in child digital safety technology and services. We are a purpose-driven business, operating under the ‘Linewize’ brand in North America and Asia Pacific, the ‘Smoothwall’ brand in the UK, and the ‘Qoria’ brand in EMEA and Sri Lanka. Our solutions are utilised by schools, school districts, and parental communities to protect children from seeing harmful content online, identify children at risk based on their digital behaviours and ensure teachers maintain focus and safe learning in the digital classroom. 30.000 schools and 7 million parents depend on our solutions to keep 25 million children safe in 180 countries around the worldWhat’s The OpportunityWe are looking for a Trainee Data Engineer (Business Intelligence) to join our global BI team. This is an entry-level opportunity designed to help you build strong foundational skills in data engineering while contributing to real business projects.You will work closely with senior data engineers and business analysts to prepare, clean, and manage the data that powers reporting, dashboards, and analytics across Qoria.This role is ideal for someone eager to learn, detail-oriented, and passionate about developing a career in data engineering.Key ResponsibilitiesClean, prepare, and validate datasets for analysis and reporting.Support data ingestion processes into centralised storage platforms such as BigQuery.Assist in maintaining ETL (Extract, Transform, Load) pipelines.Work with Business Analysts and Data Analysts to ensure data quality rules and standards are followed.Learn and adhere to Qoria’s data management and documentation practices.Participate in team meetings, code reviews, and continuous learning activities.Support the global BI team in maintaining accurate and trusted datasets.Collaborate with regional teams to align on data definitions and data processes.Assist with documenting data flows, validation rules, and system dependencies.Ensure data confidentiality, integrity, and compliance with Qoria’s data governance standards.RequirementsBachelor’s degree in Computer Science, Data Science, Information Systems, or a related field.Basic knowledge of databases, SQL, and data concepts.Strong analytical and problem-solving skills.Good written and verbal communication skills in English.Detail-oriented, organised, and committed to producing high-quality work.Eagerness to learn and grow in a fast-paced, global environment.Ability to take initiative and explore opportunities to improve data quality and processes.Preferred QualificationsExposure to Python or similar programming languages.Familiarity with cloud data platforms (e.g., Google Cloud, BigQuery).Basic understanding of ETL principles and data pipelines.Internship or project experience related to data engineering, analytics, or BI.We'd love to hear from you. Please submit your application if you would like to be considered for this opportunity.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "SQL",
      "BigQuery",
      "Google Cloud Platform",
      "ETL",
      "Data Pipeline",
      "Data Management"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_001"
  },
  {
    "job_id": "data-engineer-at-cube-4320535662",
    "title": "Data Engineer",
    "company": "CUBE",
    "location": "Colombo, Western Province, Sri Lanka",
    "posted_date": "2025-12-17",
    "job_url": "https://lk.linkedin.com/jobs/view/data-engineer-at-cube-4320535662?position=3&pageNum=0&refId=PjuzJ6HhpxCZ0envKqfLsQ%3D%3D&trackingId=YhAwcIEe7SPF%2Bu55Tq76vA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939386",
    "description": "CUBE are a global RegTech business defining and implementing the gold standard of regulatory intelligence for the financial services industry. We deliver our services through intuitive SaaS solutions, powered by AI, to simplify the complex and everchanging world of compliance for our clients.Why us?🌍 CUBE is a globally recognized brand at the forefront of Regulatory Technology. Our industry-leading SaaS solutions are trusted by the world’s top financial institutions globally.🚀 In 2024, we achieved over 50% growth, both organically and through two strategic acquisitions. We’re a fast-paced, high-performing team that thrives on pushing boundaries—continuously evolving our products, services, and operations. At CUBE, we don’t just keep up we stay ahead.🌱 We believe our future is built by bold, ambitious individuals who are driven to make a real difference. Our “make it happen” culture empowers you to take ownership of your career and accelerate your personal and professional development from day one.🌐 With over 700 CUBERs across 19 countries spanning EMEA, the Americas, and APAC, we operate as one team with a shared mission to transform regulatory compliance. Diversity, collaboration, and purpose are the heartbeat of our success.💡 We were among the first to harness the power of AI in regulatory intelligence, and we continue to lead with our cutting-edge technology. At CUBE, You will work alongside some of the brightest minds in AI research and engineering in developing impactful solutions that are reshaping the world of regulatory compliance.Role MissionAs a Data Engineer, your mission is to architect, build, and optimize scalable and secure data pipelines and infrastructure to support advanced analytics, business intelligence, and data science initiatives. Leveraging technologies like Microsoft Fabric, Apache Spark, Python, and SSIS, you will be instrumental in transforming raw data into actionable insights that drive business performance.Key ResponsibilitiesDesign & Development: Build robust ETL pipelines and scalable data solutions using Azure Data Factory and/or Microsoft Fabric Data Factory and Python.Data Integration: Develop reliable data integration frameworks that consolidate structured and unstructured data from various sources in Azure, ensuring high-quality and consistent datasets.Data Processing & Transformation: Create and optimize data transformation logic using Data Flows, Python, Spark SQL and/or PySpark to support complex analytical workloads.Collaboration: Work closely with data scientists, analysts, and business stakeholders to gather data requirements and deliver efficient and secure data solutions.Data Modelling: Design data models (relational and dimensional) that support operational processes and business reporting needs.Documentation: Maintain thorough documentation of data architecture, pipelines, and workflows.Required Skills & QualificationsEducation: Bachelor’s degree in Computer Science, Engineering, or a related discipline (Master’s degree preferred).Experience: 5-8 years in data engineering or related roles.Core Technologies:Expertise in Azure Data Factory or Microsoft Fabric ecosystem (Data Factory).Solid experience in SQL Server.Programming experience with Python for data manipulation.Proven experience in developing and maintaining ETL workflows.Database Proficiency:Strong T-SQL querying skills.Design and implementation of database objects (tables, views etc) using best practices and enforcing integrity.DevOps & Version Control: Experience with Git and CI/CD tools and practices.Data Modelling: Proficiency in designing relational and dimensional data models.Soft Skills: Strong communication, analytical thinking and problem-solving ability.Preferred QualificationsFamiliarity with data visualization tools such as Power BI.Cloud platform experience, especially with Azure (Blob storage, KeyVault, Function Apps etc).Microsoft/Azure certifications in data engineering or analytics.Experience working on ML data pipelines or in support of data science teams.Interested?If you are passionate about leveraging technology to transform regulatory compliance and meet the qualifications outlined above, we invite you to apply. Please submit your resume detailing your relevant experience and interest in CUBE.CUBE is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees.",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Azure Data Factory",
      "Microsoft Fabric",
      "Python",
      "SQL Server",
      "T-SQL",
      "ETL",
      "Git",
      "CI/CD",
      "Power BI",
      "Data Modeling",
      "DevOps",
      "Apache Spark"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_002"
  },
  {
    "job_id": "data-engineer-l5-at-netflix-3982462774",
    "title": "Data Engineer (L5)",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-12-16",
    "job_url": "https://www.linkedin.com/jobs/view/data-engineer-l5-at-netflix-3982462774?position=1&pageNum=0&refId=FfvT8CZleVvEyyVOFmqt%2Bw%3D%3D&trackingId=b%2BoJh2c9OG6zYedLzTzhyw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939390",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.Netflix is revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Ads, Games, Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring business metrics to life to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with.Who are you?You strive to write elegant code, and you're comfortable with picking up new technologies independentlyYou are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQLYou enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning modelsYou have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modelingYou are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasetsYou have an eye for detail, good data intuition, and a passion for data qualityYou appreciate the importance of great documentation and data debugging skillsYou relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedbackYou are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risksOur compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for is $170,000 - $720,000.Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.Netflix is a unique culture and environment. Learn more here.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Python",
      "Java",
      "Scala",
      "SQL",
      "Spark",
      "Flink",
      "Big Data",
      "Data Modeling",
      "Distributed Systems"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_003"
  },
  {
    "job_id": "data-engineer-analytics-university-grad-at-meta-4333234367",
    "title": "Data Engineer, Analytics (University Grad)",
    "company": "Meta",
    "location": "New York, NY",
    "posted_date": "2025-12-13",
    "job_url": "https://www.linkedin.com/jobs/view/data-engineer-analytics-university-grad-at-meta-4333234367?position=2&pageNum=0&refId=FfvT8CZleVvEyyVOFmqt%2Bw%3D%3D&trackingId=v0b9iBplSOG2t5lPRSLrtA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939394",
    "description": "Are you passionate about Facebook’s product, analytics and technology? The Analytics, Data Engineering team is looking for fast-moving analytics candidates and data junkies who want to make an impact. Our data warehouse team works very closely with Product Managers, Product Analysts and Internet Marketers to figure out ways to acquire new users, retain existing users and optimize user experience - all of this using massive amounts of data. In this role, you will see a direct link between your work, company growth, and user satisfaction. You will work with some of the brightest minds in the industry, and you'll have the opportunity to solve some of the most challenging business problems on the web and mobile Internet, at a scale that few companies can match.Data Engineer, Analytics (University Grad) Responsibilities:Architect, implement and deploy new data models and data processes in productionPerform data analysis to generate business insightsInterface with Engineers, Product Managers and Product Analysts to understand product goals and data needsBuild data expertise and own data quality for allocated areas of ownershipManage data warehouse plans for a product or a group of productsSupport critical data processes running in productionMinimum Qualifications:Programming knowledge in Python or JavaKnowledge of SQLKnowledge of database systemsMust obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employmentCurrently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining MetaPreferred Qualifications:Experience thriving in a fast-paced work environmentCurious, self-driven, analytical and excited to play with dataExperience in collaborating with individuals and organizationsAbout Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.$46.63/hour to $134,000/year + bonus + equity + benefitsIndividual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Java",
      "SQL",
      "Database Systems",
      "Data Modeling",
      "Data Analysis"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_004"
  },
  {
    "job_id": "data-engineer-l5-ads-at-netflix-3989284331",
    "title": "Data Engineer (L5) - Ads",
    "company": "Netflix",
    "location": "United States",
    "posted_date": "2025-12-13",
    "job_url": "https://www.linkedin.com/jobs/view/data-engineer-l5-ads-at-netflix-3989284331?position=3&pageNum=0&refId=FfvT8CZleVvEyyVOFmqt%2Bw%3D%3D&trackingId=9UwoKoxQEyYVpaxdDWq0Bg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939398",
    "description": "Netflix is one of the world's leading entertainment services, with over 300 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time.About The TeamAds Data Engineering team sits at the core of building a data ecosystem that will power Netflix’ understanding and decision making about what impact ads have on our business. This team’s main focus is to build rich, connected, and easily accessible data products about ad inventories, forecasting, targeting, ad serving, pacing and much more. We are looking for passionale, mature, and curious software engineers with strong data intuition, analytical mindset and ad ecosystem experience, to contribute to the team’s impact in a quickly evolving.We are hiring for several different roles, ranging from senior to staff level for this team.Who are you?Beyond talented, you are curious, creative, and tenacious. Sharp communicator who can break down and explain complex data problems in clear and concise language. You have an extensive background and strong technical expertise working with data at scale, experience with advertising data (preferred) and understand how to build for privacy, and business impactYou have a high tolerance for ambiguity and fast-changing contextHands-on experience building batch or streaming production data pipelines, ideally using one or more distributed processing frameworks such as Spark, Flink or Hive/HadoopKnowledge in data modeling and establishing data architecture across multiple systemsThrive in a fast paced environment, and see yourself as a partner with the business with the shared goal of moving the business forward.Create code that is understandable, simple, and clean, and take pride in its beauty.Love freedom and hate being micromanaged. Given context, you're capable of self-direction.Passionate about data quality and delivering effective data to impact the business. What will you do?Architect, strengthen, and expand the core data products that scale our Ads business. You’ll get on a team of talented data engineers and envision how all the data elements from multiple sources should fit together as a whole, and then execute on that plan.Fully own critical portions of Netflix' Ads data products. Collaborate with stakeholders to understand needs, model tables using software engineering and data warehouse best practices, and develop large scale data processing solutions to ensure the timely delivery of high quality data.Partner with Analytics Engineers, Data Scientists, and Software Engineers to create data products that will serve analysis, ML and reporting needs intuitivelyDevelop best practices for governance of data sets with sensitive informationBuild strong and collaborative partnerships with data scientists, analytics engineers, and Machine Learning practitionersWhat (ideally) do you know? Domains related to advertising, data privacy, GDPRData warehousing, data modeling, and data transformation for both batch and streaming Hands on command programming languages such as python, scala or java as well data exploration using sqlExpert at building performant data pipelines and optimizing existing workflows for new featuresBig Data tech - Hadoop, Spark, Flink, Stream processing, Hive, Presto, etc. Experience with sourcing and modeling data from application APIsTeam based software development tools and best practicesOur compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $170,000 - $720,000.Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.Inclusion is a Netflix value and we strive to host a meaningful interview experience for all candidates. If you want an accommodation/adjustment for a disability or any other reason during the hiring process, please send a request to your recruiting partner.We are an equal-opportunity employer and celebrate diversity, recognizing that diversity builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.Job is open for no less than 7 days and will be removed when the position is filled.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "Entertainment Providers"
    },
    "skills": [
      "Python",
      "Scala",
      "Java",
      "SQL",
      "Spark",
      "Flink",
      "Hadoop",
      "Big Data",
      "Data Modeling",
      "Data Warehousing",
      "APIs"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_005"
  },
  {
    "job_id": "data-engineer-i-itc-at-nike-4341255293",
    "title": "Data Engineer I, ITC",
    "company": "Nike",
    "location": "Karnataka, India",
    "posted_date": "2025-12-04",
    "job_url": "https://in.linkedin.com/jobs/view/data-engineer-i-itc-at-nike-4341255293?position=1&pageNum=0&refId=2ohxD7M8LE34rE9Fbwt0Vg%3D%3D&trackingId=wlyqzHJC%2FbPbFjFDzeLx7A%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939400",
    "description": "Who You’ll Work WithYou will be a part of the larger Global Technology organization working on Nike’s internal product tools and report to the team’s Engineering Director. You will work day-to-day with a team of engineers, the team’s Technical Product Manager and Principal Engineers in the organization on software projects to achieve Nike’s business objectives. You will also engage with other Global Technology functions and teams on organizational and technical goals.Who We Are Looking ForWe’re looking for a Data Engineer to solve complex software engineering problems supporting Nike’s pursuit of delivering state of the art tools to our Consumer Product and Innovation (CP&I) community. The candidate needs to be highly collaborative with peers, productive in a fast-paced development environment and have depth of native cloud software engineering experience.What You’ll Work OnYou will be part of and leading a team of engineers building out tooling for our Consumer Product & Innovation team members. We are investing in building modular, configurable and “API-First” capabilities which will be consumed by modern web applications build with the most recent SPA frameworks. You are expected to help coordinate with other teams and provide guidance and coaching for more junior team members.Bachelor's degree in Computer Science, Engineering, Data Science, or related field; or equivalent combination of education1-2+ years of hands-on experience in data engineering, software development, or related technical rolesFoundational proficiency in SQL for data querying and manipulation, with basic working knowledge of Python for data processing, scripting, and automation tasksExposure to Spark or similar distributed data processing frameworks, with understanding of big data concepts and parallel computing principlesFamiliarity with at least one major cloud platform (AWS, Azure, Databricks, or Snowflake) and understanding of cloud-based data storage and processing servicesBasic understanding of data modeling, ETL/ELT processes, and data pipeline fundamentals, with awareness of data streaming technologies and real-time data processing conceptsKnowledge of version control systems (Git), CI/CD concepts, and DevOps practices related to data engineering workflows and automated deployment pipelinesExposure to REST API development and data service integration, with understanding of microservices architecture concepts and basic architectural design patternsAwareness of data visualization concepts and dashboard design principles; experience with frameworks such as React, Vue.js, or Angular is a plusStrong problem-solving skills, collaborative mindset, and ability to work effectively in highly collaborative environments with demonstrated learning agility and attention to detail",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Retail"
    },
    "skills": [
      "SQL",
      "Python",
      "Spark",
      "AWS",
      "Azure",
      "Databricks",
      "Snowflake",
      "Data Modeling",
      "ETL",
      "CI/CD",
      "DevOps",
      "REST API",
      "Version Control"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_006"
  },
  {
    "job_id": "python-data-engineer-at-infosys-4321290500",
    "title": "Python Data Engineer",
    "company": "Infosys",
    "location": "Gurgaon, Haryana, India",
    "posted_date": "2025-11-27",
    "job_url": "https://in.linkedin.com/jobs/view/python-data-engineer-at-infosys-4321290500?position=2&pageNum=0&refId=2ohxD7M8LE34rE9Fbwt0Vg%3D%3D&trackingId=zX0unohMpeZg%2BfXfT8M%2Fzw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939404",
    "description": "Primary skills:Technology->Machine Learning->PythonA day in the life of an Infoscion As part of the Infosys consulting team, your primary role would be to get to the heart of customer issues, diagnose problem areas, design innovative solutions and facilitate deployment resulting in client delight. You will develop a proposal by owning parts of the proposal document and by giving inputs in solution design based on areas of expertise. You will plan the activities of configuration, configure the product as per the design, conduct conference room pilots and will assist in resolving any queries related to requirements and solution design You will conduct solution/product demonstrations, POC/Proof of Technology workshops and prepare effort estimates which suit the customer budgetary requirements and are in line with organization’s financial guidelines Actively lead small projects and contribute to unit-level and organizational initiatives with an objective of providing high quality value adding solutions to customers. If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Ability to develop value-creating strategies and models that enable clients to innovate, drive growth and increase their business profitability Good knowledge on software configuration management systems Awareness of latest technologies and Industry trends Logical thinking and problem solving skills along with an ability to collaborate Understanding of the financial processes for various types of projects and the various pricing models available Ability to assess the current processes, identify improvement areas and suggest the technology solutions One or two industry domain knowledge Client Interfacing skills Project and Team management",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "Python",
      "Machine Learning",
      "Software Configuration Management"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_007"
  },
  {
    "job_id": "associate-python-data-engineer-gdc-at-pwc-india-4291069034",
    "title": "Associate - Python Data Engineer - GDC",
    "company": "PwC India",
    "location": "Kolkata, West Bengal, India",
    "posted_date": "2025-12-13",
    "job_url": "https://in.linkedin.com/jobs/view/associate-python-data-engineer-gdc-at-pwc-india-4291069034?position=3&pageNum=0&refId=2ohxD7M8LE34rE9Fbwt0Vg%3D%3D&trackingId=StW72Rq1ZUk9%2BgxAUFPEFg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939407",
    "description": "Line of ServiceAdvisoryIndustry/SectorNot ApplicableSpecialismOperationsManagement LevelSenior AssociateJob Description & SummaryA career in our Analytics Technology practice, within Data and Analytics Technology services, will provide you with the opportunity to help organisations uncover enterprise insights and drive business results using smarter data analytics. We focus on a collection of organisational technology capabilities, including business intelligence, data management, and data assurance that help our clients drive innovation, growth, and change within their organisations in order to keep up with the changing nature of customers and technology. You’ll make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge.Our team helps clients navigate various analytics applications to get the most value out of their technology investment and foster confidence in their business intelligence. As part of our team, you’ll help our clients implement enterprise content and data management applications that improve operational effectiveness and provide impactful data analytics and insights.To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:Use feedback and reflection to develop self awareness, personal strengths and address development areas.Delegate to others to provide stretch opportunities, coaching them to deliver results.Demonstrate critical thinking and the ability to bring order to unstructured problems.Use a broad range of tools and techniques to extract insights from current industry or sector trends.Review your work and that of others for quality, accuracy and relevance.Know how and when to use tools available for a given situation and can explain the reasons for this choice.Seek and embrace opportunities which give exposure to different situations, environments and perspectives.Use straightforward communication, in a structured way, when influencing and connecting with others.Able to read situations and modify behavior to build quality relationships.Uphold the firm's code of ethics and business conduct.Associate - Python Data Engineer Required SkillsOptional SkillsDesired Languages (If blank, desired languages not specified)Travel RequirementsAvailable for Work Visa Sponsorship?Government Clearance Required?Job Posting End Date",
    "criteria": {
      "Seniority level": "Associate",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Business Consulting and Services"
    },
    "skills": [
      "Python",
      "Business Intelligence",
      "Data Management",
      "Data Analytics"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_008"
  },
  {
    "job_id": "data-engineer-i-at-booking-com-4340386217",
    "title": "Data Engineer I",
    "company": "Booking.com",
    "location": "City Of London, England, United Kingdom",
    "posted_date": "2025-12-01",
    "job_url": "https://uk.linkedin.com/jobs/view/data-engineer-i-at-booking-com-4340386217?position=2&pageNum=0&refId=5ChpvnM%2Fki%2Bob4DbJQnhEQ%3D%3D&trackingId=uA39mGRU0%2FdK5p%2FFjwxPgA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939409",
    "description": "Role OverviewThe Data Track exists to provide high‑quality, trustworthy payments data that powers business decisions and enables great experiences for travelers and partners, aligning Fintech foundations with robust governance and reliable delivery across reporting and analytics consumers.Mission: Provide high‑quality payments data that powers impactful decisions and enables exceptional experiences for travelers and partners.Vision: Achieve “Flawless Payments Analysis and Reporting” across Fintech by ensuring stakeholders can trust and act on data with confidence.Scope: Govern, acquire, cleanse, enrich, store, and distribute comprehensive, reliable transactional data; additionally manage card data and ensure PCI DSS compliance.Core capabilities: Operate and evolve the data platform (consumption, transformation, enrichment), deliver reports/dashboards/alerts, improve data quality and lineage, and support analytics and machine learning use casesThe Junior Data Engineer is responsible for supporting development and delivery of end-to-end data solutions. The incumbent supports solution envisaging and technical designs, and drives hands-on implementation. Supports the influencing, differentiation, and guidance to business and technology strategies, as they relate to data, through constant cross-functional interaction.Key Job Responsibilities And DutiesDrive efficiency and resilience by mapping data flows between systems and workflows across the companyEnsure standardisation by following design patterns in line with global and local data governance requirementsSupport real-time internal and customer-facing actions by developing real-time event-based streaming data pipelinesEnable rapid data-driven business decisions by supporting development of efficient and scalable data ingestion solutionsDrive high-value data by connecting different disparate datasets from different systemsMonitor and follow relevant SLIs and SLOsHandle, mitigate and learn from incidents in a manner that improves the overall system healthEnsure ongoing resilience of data processes by monitoring system performance and acting proactively identifying bottlenecks, potential risks, and failure point that might degrade overall qualityWrite readable and reusable code by applying standard patterns and using standard librariesContinuously evolve own craft by keeping up to date with the latest developments in data engineering and related technologies, and upskilling on these as needed.Role Qualifications And RequirementsBachelor’s or Master's degree in Computer Science or related field1-3 years of relevant job experienceentry level exposure to a data engineering or related field using a server side programming languages, preferably Scala, Java, Python, or Perlentry level exposure to building data pipelines and transformations at scale, with technologies such as Hadoop, Cassandra, Kafka, Spark, HBase, MySQLBasic knowledge of data modeling methods based on best practices, e.g. TOGAFBasic knowledge of data quality requirements and implementation methodologiesExcellent English communication skills, both written and verbal.Total Reward Philosophy: The benefits and perks offered by the company can be found here. Inclusion at Booking.com:Take it from our Chief People Officer, Paulo Pisano: “At Booking.com, the diversity of our people doesn’t just create a unique workplace, it also creates a better and more inclusive travel experience for everyone. Inclusion is at the heart of everything we do. It’s a place where you can make your mark and have a real impact in travel and tech.”Read all about Inclusion and the Employee Resource Groups (ERGs) at Booking.com hereCareer Development Opportunities: Learn more about Your Career Journey here. Become a Mentee and benefit from a mentoring relationship with a more experienced person to help you identify and achieve your professional and personal development goals.Booking.com is proud to be an equal opportunity workplace and is an affirmative action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. We strive to move well beyond traditional equal opportunity and work to create an environment that allows everyone to thrive.Pre-Employment ScreeningIf your application is successful, your personal data may be used for a pre-employment screening check by a third party as permitted by applicable law. Depending on the vacancy and applicable law, a pre-employment screening may include employment history, education and other information (such as media information) that may be necessary for determining your qualifications and suitability for the position.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "Java",
      "Scala",
      "Machine Learning",
      "Cassandra",
      "Data Modeling",
      "Hadoop",
      "HBase",
      "Kafka",
      "Data Governance",
      "Data Quality",
      "Reporting"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_009"
  },
  {
    "job_id": "data-engineer-at-adria-solutions-ltd-4344033579",
    "title": "Data Engineer",
    "company": "Adria Solutions Ltd",
    "location": "Brighton, England, United Kingdom",
    "posted_date": "2025-12-16",
    "job_url": "https://uk.linkedin.com/jobs/view/data-engineer-at-adria-solutions-ltd-4344033579?position=3&pageNum=0&refId=5ChpvnM%2Fki%2Bob4DbJQnhEQ%3D%3D&trackingId=vT58cpC0ntTEC9aTZMIsbw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939413",
    "description": "Data Engineer (Snowflake)We are seeking an experienced Data Engineer (Snowflake) to join our clients team on a permanent basis. This role will focus on administering and developing our Snowflake data platform, building robust data pipelines, and transforming data to support analytics and marketing activation use cases.The successful candidate will initially work on projects involving the ingestion of multiple data sources - including Google Analytics 4 (GA4) - and transforming data to surface insights within Google Ads.Key ResponsibilitiesAdminister, maintain, and optimise the Snowflake data platformDesign, build, and manage scalable ETL/ELT data pipelinesIngest and integrate 3–4 data sources, including GA4Transform and model data to support reporting and activation in Google AdsEnsure data quality, performance, and cost efficiencyCollaborate with analytics, marketing, and engineering teamsDocument data solutions and provide ongoing platform supportRequired Skills & ExperienceStrong hands-on experience with SnowflakeProven experience building data pipelines in a cloud environmentAdvanced SQL skills and experience with data modellingExperience working with GA4 or digital analytics dataExperience integrating data with Google Ads or similar platformsFamiliarity with cloud platforms (GCP, AWS, or Azure)Strong communication and problem-solving skillsDesirable ExperienceExperience with tools such as dbt, Airflow, or similar orchestration frameworksBackground in marketing, analytics, or advertising data environmentsUnderstanding of data governance, privacy, and consent frameworksWhat We OfferCompetitive salary and benefits packageFlexible working arrangementsOpportunity to work on high-impact data and marketing initiativesSupportive, collaborative team environmentHow to ApplyIf you are a skilled Data Engineer (Snowflake) looking for your next permanent opportunity, we would love to hear from you. Please apply with your CV or contact us for further information.Data Engineer (Snowflake)",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Technology, Information and Media and Data Infrastructure and Analytics"
    },
    "skills": [
      "SQL",
      "Snowflake",
      "AWS",
      "Azure",
      "GCP",
      "Airflow",
      "dbt",
      "ETL",
      "ELT",
      "Data Governance",
      "Data Quality",
      "Reporting"
    ],
    "role_tag": "DE",
    "role_key": "data_engineer",
    "job_role_id": "DE_20251218_010"
  },
  {
    "job_id": "devops-engineer-1-at-stellar-health-4341503603",
    "title": "DevOps Engineer 1",
    "company": "Stellar Health",
    "location": "New York, NY",
    "posted_date": "2025-12-02",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-1-at-stellar-health-4341503603?position=2&pageNum=0&refId=%2B%2B2Ay7GyAfDCdEvzFtNLxw%3D%3D&trackingId=5GcDotfQaNhsqbzPBiJl0Q%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939416",
    "description": "About Stellar Health:Historically, US Healthcare has relied on a fee-for-service reimbursement system where providers are paid based on the quantity of patient visits and procedures, rather than the quality of health outcomes.At Stellar Health, we help primary care providers put patient health first. Our platform - a mix of technology, people, and analytics - supports providers at the point of care, delivering real-time patient information, activating practice staff, and empowering providers and care teams with incentives that reward the work they are already doing to keep patients healthy. Using the Stellar App, our web-based, point-of-care tool; practices receive a simple checklist of recommended actions that support the best quality care. Providers and care teams are then paid monthly for each action they complete, and Payors save money in reduced healthcare costs along the way.Stellar is a US-based Health-tech backed by Top VCs (General Atlantic, Point72, & Primary Venture Partners) with an established product & proven operating model. We've shown that we make a real difference for physician practices and their patients.About the role:Stellar Health is hiring a DevOps Engineer to join our expanding DevSecOps team. Reporting to the Senior Director, Information Security & DevOps, you will collaborate daily with our Senior DevOps Engineers and cross-functional Engineering teams.We are building a modern, collaborative DevOps culture focused on unifying development and operations through automation, partnership, and shared ownership. Our mission is to accelerate the delivery of high-quality software, enabling teams to build, ship, and operate products with confidence.Core Responsibilities:As a key member of the DevSecOps team, you will own the tooling, infrastructure, and operational foundation that empowers our engineering teams. You will partner closely with developers to ensure our systems are scalable, secure, and easy to work with.Cloud & Infrastructure Management: Manage application deployments and our HIPAA-compliant cloud infrastructure on AWS, including ETL pipelines, queueing systems, and service environments, ensuring high resilience. Critical Service Operations: Operate, scale, upgrade, and improve critical internal services like ElastiCache (Redis), OpenSearch, and Postgres as our product evolves. Observability & Reliability: Own the logging, monitoring, and alerting ecosystem using Datadog and CloudWatch, and help drive a reliable, well-coordinated On-Call process. Security & Access Control: Manage access and roles across the engineering ecosystem (AWS, Databases, Datadog, GitHub) to balance robust security with developer productivity. Developer Experience & Automation: Improve the developer experience by building better tooling, creating faster testing environments (Terraform), and streamlining the release process (Github Actions), enabling fast, safe, and confident deployments/rollbacks of our Python/Django application. By 3 months you will…As a DevOps Engineer, you will support our Engineering teams by helping maintain and improve the systems, pipelines, and tooling that power our platform. You'll work closely with more senior DevOps and Platform Engineers, learning best practices while taking on real responsibility as you grow.Work with Engineering teams to troubleshoot environment issues, deployments, and basic infrastructure issues Help maintain our Cloud infrastructure, observability platforms, and internal tooling Follow established runbooks and processes for routine operations, incident response, and maintenance tasks Participate in improving documentation and internal processes By 6 months you will…Assist in managing and supporting CI/CD pipelines, ensuring reliable, predictable builds and deployments Learn and contribute to automation efforts using scripts, templates, and infrastructure-as-code Participate in improving documentation, onboarding materials, and operational playbooks Collaborate with Developers and Senior DevOps Engineers to support delivery workflows and release processes. Participate in initial triage for incident response on-call rotation What You'll Bring:You don't need to know everything–but you should have a combination of the following fundamentals:1-3 years of experience working as DevOps/SRE, software developer, or similar role, or proven commensurate hands-on experience Basic understanding of Linux commands, file systems, processes Familiarity with Git and simple version controlled workflows Proven exposure to Cloud concepts and building infrastructure with Code (IaC) (AWS/Azure/GCP) Bash scripting skills (Bash or Python) Curiosity about CI/CD pipelines, automation, and systems reliability Who will love this job:Fast learners who can pick up new technologies with guidance Collaborative communicators who enjoy working directly with developers and code pairing to reach solutions Curious and adaptable engineers–you're comfortable with not knowing everything yet and excited to grow. Pay:The salary range for this role is $120,000 - $140,000 + an annual performance based bonus. Where a new hire falls within this range will be based on their individual skills and experience, and how these competencies compare across other employees in the same role. Stellar's bands are designed to allow for individual compensation growth within the role. As such, new hires typically start at the lower end of the range. Stellar rewards performance and outcomes - should you join the company, you will have the opportunity to grow your salary over time.Perks & Benefits:Stellar offers a carefully curated selection of wellness benefits and perks to our employees:Medical, Dental and Vision BenefitsFlexible PTOUniversal Paid Family LeaveCompany sponsored One Medical memberships and Citibike membershipsMedical Travel Benefits A monthly wellness stipend that gives employees the freedom to choose where they spend their cash, whether it be on wellness, pet care, childcare, WFH items, or charitable donationsStock Options & a 401k matching programCareer development opportunities like Manager Training, coaching, and an internal mobility programA broad calendar of company sponsored social events that for our in-office and remote employeesDiversity is the key to our success. Stellar Health is an equal opportunity employer and we are open to all qualified applicants regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or expression, veteran status, or any other legally protected status.We believe that diverse teams -and the different identities, cultures, and life experiences our team members bring to the table- enable us to create amazing products, find creative solutions to interesting problems, and build an inclusive working environment.Stellar Health Employment Privacy NoticeAt Stellar Health, your privacy and security as a job seeker is a priority no matter where you are in the interview process. As recruiting scams have become more prevalent, please take note of the following practices to ensure the legitimacy of any interaction with our team.Please note that any communication from our recruiters and hiring managers at Stellar Health about a job opportunity will only be made by a Stellar Health employee with an @stellar.health email address. Stellar Health does not utilize third-party agencies for recruitment services and does not conduct text message or chat-based interviews. Any other email addresses, agencies, or forums may be phishing scams designed to obtain your personal information. We will not ask you to provide personal or financial information, including, but not limited to, your social security number, online account passwords, credit card numbers, passport information, and other related banking information until we begin onboarding activities, which will be coordinated by a member of the Stellar Health People Ops Team with an @stellar.health email address. If you are ever unsure whether you are in contact with a legitimate Stellar Health teammate, please contact people-team@stellar.health. If you believe you've been a victim of a phishing attack, please mark the communication as \"spam\" and immediately report it by contacting the U.S. Federal Trade Commission.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Hospitals and Health Care"
    },
    "skills": [
      "Python",
      "Bash",
      "Django",
      "Redis",
      "AWS",
      "Azure",
      "GCP",
      "CloudWatch",
      "CI/CD",
      "Terraform",
      "Linux",
      "Git",
      "GitHub",
      "GitHub Actions",
      "Datadog",
      "IaC",
      "ETL",
      "Reporting",
      "Information Security",
      "DevOps",
      "SRE"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_004"
  },
  {
    "job_id": "devops-engineer-at-larsen-toubro-4294308779",
    "title": "DevOps Engineer",
    "company": "Larsen & Toubro",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-17",
    "job_url": "https://in.linkedin.com/jobs/view/devops-engineer-at-larsen-toubro-4294308779?position=2&pageNum=0&refId=qDX0z%2Fq01ACBSivoWTIKQQ%3D%3D&trackingId=vYBa65RjZnjgvsW7kkfGcg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939419",
    "description": "Job Title: Dev Ops EngineerStreamGradeReporting ToLocationSoftware Development ManagerBangalorePurposeThe DevOps Engineer will be responsible for designing and maintaining robust automated build systems, managing source control repositories, and integrating static code analysis and IP compliance tools into the development workflow. This role demands a strong foundation in DevOps practices, version control strategies, and automation tooling, with a focus on improving build reliability, code quality, and overall development efficiency.Areas Of Responsibility1. Automated Build and CI/CD PipelinesDesign, develop, and maintain scalable automated build scripts.Implement and manage daily and weekly build schedules.Ensure build processes are efficient, reliable, and integrated into CI/CD pipelines.Collaborate with development teams to troubleshoot and enhance build workflows.2. Source Control ManagementAdminister and maintain source control systems (e.g., Git, SVN).Enforce best practices for branching, merging, tagging, and versioning.Optimize repository performance and storage.3. Static Code AnalysisDevelop scripts to automate static code analysis checks.Integrate code quality tools into the CI/CD pipeline.Generate and review reports, providing actionable feedback to developers.4. IP Compliance & Violation AnalysisCreate and maintain scripts to scan code for potential IP violations.Conduct regular audits to ensure compliance with licensing and copyright laws.Work with legal/compliance teams to address violations and remediation plans.5. Build Analytics & Log ManagementImplement analytics to monitor and improve build performance.Manage build logs using NFS or other storage solutions.Perform root cause analysis from log data to resolve recurring issues.6. Collaboration & SupportPartner with cross-functional teams to define and deliver new tooling and infrastructure features.Provide ongoing support to development teams for build and version control issues.Participate in code reviews and DevOps practice sessions.7. Continuous ImprovementKeep up with industry trends and emerging DevOps tools and technologies.Propose and implement process improvements to enhance productivity and reliability.Share knowledge through documentation, workshops, and mentoring.8. Scheduler & CI/CD ManagementManage and configure Jenkins or similar CI/CD platforms.Set up job schedulers to automate build and deployment tasks.Create and manage JIRA tickets for tracking build issues and enhancements..ExperienceExperience and Qualification2– 8 years of experience in software development and build automation.Proven experience with source control management and CI/CD tools.Experience in writing and maintaining build scripts and code analysis tools.QualificationsBachelor’s or Diploma in computer science, Engineering, or a related field.Strong knowledge of source control systems (e.g., Git, SVN).Proficiency in scripting languages (e.g., Python, Bash).Familiarity with CI/CD tools (e.g., Jenkins, GitLab CI, CircleCI).Experience with static code analysis tools (e.g., SonarQube, ESLint).Understanding of IP compliance and licensing issues.Technical SkillsTechnical And Behavioural SkillsProficiency in scripting languages and build automation tools.Strong understanding of source control management and best practices.Experience with CI/CD pipelines and tools.Knowledge of static code analysis and IP violation analysis.Experience with build analytics and log management.Familiarity with JIRA for issue tracking and project management.Behavioural SkillsStrong communication and teamwork skills.Ability to adapt to a fast-paced and dynamic business environment.Detail-oriented with a focus on quality and accuracy.Proactive and self-motivated with a results-oriented mindset.Qualifiers for the Role / Necessary Experience and Skills Required for the RoleDiploma/BCA/MCA or degree in engineering, Computer Science, or related fields",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Executive Offices"
    },
    "skills": [
      "Python",
      "Bash",
      "Jenkins",
      "CI/CD",
      "Git",
      "GitLab",
      "SVN",
      "CircleCI",
      "GitLab CI",
      "DevOps",
      "JIRA",
      "Version Control"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_007"
  },
  {
    "job_id": "devops-engineer-at-infosys-4320032037",
    "title": "Devops Engineer",
    "company": "Infosys",
    "location": "Bengaluru East, Karnataka, India",
    "posted_date": "2025-12-12",
    "job_url": "https://in.linkedin.com/jobs/view/devops-engineer-at-infosys-4320032037?position=3&pageNum=0&refId=qDX0z%2Fq01ACBSivoWTIKQQ%3D%3D&trackingId=xo28azHp4kqRh9gsqZMTPg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939421",
    "description": "Technology->Cloud Platform->AWS Database->AWS,Technology->Container Platform->Docker,Technology->Container Platform->KubernetesA day in the life of an Infoscion As part of the Infosys consulting team, your primary role would be to lead the engagement effort of providing high-quality and value-adding consulting solutions to customers at different stages- from problem definition to diagnosis to solution design, development and deployment. You will review the proposals prepared by consultants, provide guidance, and analyze the solutions defined for the client business problems to identify any potential risks and issues. You will identify change Management requirements and propose a structured approach to client for managing the change using multiple communication mechanisms. You will also coach and create a vision for the team, provide subject matter training for your focus areas, motivate and inspire team members through effective and timely feedback and recognition for high performance. You would be a key contributor in unit-level and organizational initiatives with an objective of providing high-quality, value-adding consulting solutions to customers adhering to the guidelines and processes of the organization. If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Good knowledge on software configuration management systems Strong business acumen, strategy and cross-industry thought leadership Awareness of latest technologies and Industry trends Logical thinking and problem solving skills along with an ability to collaborate Two or three industry domain knowledge Understanding of the financial processes for various types of projects and the various pricing models available Client Interfacing skills Knowledge of SDLC and agile methodologies Project and Team management",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "IT Services and IT Consulting"
    },
    "skills": [
      "AWS",
      "Docker",
      "Kubernetes",
      "Software Configuration Management"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_008"
  },
  {
    "job_id": "junior-devops-engineer-at-flox-4343706854",
    "title": "Junior DevOps Engineer",
    "company": "FLOX",
    "location": "London, England, United Kingdom",
    "posted_date": "2025-12-15",
    "job_url": "https://uk.linkedin.com/jobs/view/junior-devops-engineer-at-flox-4343706854?position=1&pageNum=0&refId=MS%2FKonCoYvXvhHypONnwyg%3D%3D&trackingId=VU%2FNk7SGFx0WqZNokxYSvA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939424",
    "description": "🚀 The MissionAt FLOX, we believe smarter farms lead to thriving chickens and healthier lives. Our mission is simple: healthier chickens benefit everyone. That’s why we built FLOX360, a system that uses Computer Vision, smart sensors, and real-time insights to transform poultry farming. By helping farmers improve welfare and efficiency, FLOX360 creates a win-win for birds, farmers, the environment, and people everywhere. Today, we’re watching 60 million chickens a year.Our product vision goes much further and is to empower our customers with autonomous intelligence at speed and scale. This role is a key part of achieving this vision to convert data into actionable intelligence.We believe we are setting the standard for animal welfare and smart farming - and we’re just getting started.We are a Series A ready start-up with plenty of room for progression and making direct impact for our customers.🏠 The PeopleWe’re a Diverse Team Of Engineers And Entrepreneurs, Representing Over 13 Nationalities And All Walks Of Life - Even a Few Vegetarians! We Are Brought Together By a Shared Passion For Meaningful Impact. Our Culture Is Grounded In Values We Live Every Day🧙🏽 Empathetic Artisan - We approach our work with care, artistry, and genuine empathy for each other and our users. We lead with positivity and passion.💪🏼 Tenacious Innovator - Innovation drives us. We trust ourselves, keep learning, and uncover bold solutions that redefine what’s possible in poultry farming.🧤 Hand in Glove - One mission, one team. We grow together with patience, trust, and transparency, amplifying each other’s strengths to revolutionise farming.🏗️ Worth Building - Worth celebrating. We dedicate ourselves to work that matters, taking pride in creating disruptive solutions our users can’t live without.This is an exciting moment of growth for FLOX - and we’re looking for ambitious, humble, and purpose-driven people to join us in building a future of smarter farms, thriving chickens, and healthier lives.🎒 The roleWe are currently seeking a Junior DevOps Engineer to work in our London office under our Lead DevOps Engineer.As a Junior DevOps Engineer, you will help build and maintain the tooling, automation and cloud infrastructure that power our products. You’ll work closely with software engineers, ML engineers, and senior DevOps/Platform teammates to support deployments, reliability, observability, and SOC 2 compliance.You don’t need deep experience with everything—just solid fundamentals, curiosity, and eagerness to learn. This is an opportunity to get hands-on with real production systems, learn from senior engineers, and grow into a key part of our platform and DevOps function.🎁What You’ll GetOpportunity to work on production-scale systems early in your career.Mentorship and personal development guided by experienced platform and ML engineers.Ownership and autonomy in shaping our DevOps culture.Exposure to cloud platforms, security compliance, ML infrastructure, and SRE practices.A fast-paced environment with rapid growth and impact.🛠️What You’ll Work OnInfrastructure & Cloud (AWS)Support deployment and management of AWS infrastructure (EC2, EKS, S3, IAM, CloudWatch, etc.)Assist in implementing infrastructure-as-code best practices (Terraform or CloudFormation).Kubernetes & ContainerisationHelp manage and scale our Kubernetes clusters.Contribute to container build pipelines and debugging workloads.CI/CD & AutomationMaintain and improve Jenkins pipelines for automated builds, tests, and deployments.Assist in building automated workflows for ML model training and deployment.Observability & MonitoringHelp maintain and enhance our monitoring/alerting stack using Prometheus and Grafana.Contribute to dashboards, alert rules, and reliability metrics (SLIs/SLOs).Security & Compliance (SOC 2)Learn about and support implementation of SOC 2 controls across the organisation.Assist with audit readiness tasks, documentation, and evidence gathering.Reliability & OperationsParticipate in triage and incident response (with support from senior engineers).Learn and adopt DevOps/SRE best practices around reliability, automation, and quality.📚 Tech StackDataData sources: PTZ Cameras, IoT sensors, customer derived data setsTerabyte scale data on edge and cloudOn-prem, cloud and edge computeDevOps / MLOps / Software DevelopmentPython and FastAPIKafka, MySQL, MongoDB, PostgreSQLDocker; Kubernetes networking and service mesh; RKE2RTMP, WebRTC, HLS, MPEG-DASHPrometheus, Grafana, Alertmanager, Thanos; ELK; Jaeger; custom exportersJenkins, GitLab, Sonatype Nexus, Terraform, Ansible, Argo CDAWS (primary), with GCP/Azure exposureDVC, MLFlow, Airflow, Dagster, CVAT, Weights & Biases; data lakes/warehouse🤝🏽 We would love to meet you if you these requirements:Essential1+ years of experience in DevOps, Platform, SRE, Cloud, or SysAdmin roles(or strong personal projects / internships / open-source contributions).Basic experience with AWS or another cloud provider.Familiarity with Kubernetes or containerisation concepts.Experience with CI/CD pipelines (Jenkins, GitHub Actions, GitLab CI, etc.).Scripting/programming proficiency (Bash, Python, or similar).Understanding of monitoring tools such as Prometheus or Grafana.A mindset focused on automation, reliability, and continuous improvement.Strong willingness to learn and solve complex infrastructure problems.Nice to HaveExposure to SOC 2, ISO 27001, or general security/compliance work.DevSecOps experience to support secure pipelines, security scanning, and compliance controls.Experience supporting ML/AI workflows (model deployments, pipelines, GPUs).Experience with Terraform or other IaC tools.Knowledge of Linux internals, networking and container runtime fundamentals.👐🏼 What We Can Offer YouUp to £45,000 k p.a. depending on experienceHybrid working, in the office twice a week with flexibilityInclusive and relaxed company culture: we welcome everyone, we encourage you to be yourself and dress as you likeLunch and snacks providedExposure to state-of-the-art technologiesA talented and international work environmentTravel within the UKA chance to work with well-respected experts, including AI and robotics📅 Hiring timelineWe’re accepting applications now but interviews will start in January 2026.If you apply in December, please don’t worry if you don’t hear from us immediately – we’ll be in touch once we begin the interview process in the new year.We are committed to equality of opportunity for all staff and applications from all individuals are encouraged regardless of age, socioeconomic background, disability, sex, gender reassignment, sexual orientation, pregnancy and maternity, race, religion or belief and marriage and civil partnerships.",
    "skills": [
      "Python",
      "Bash",
    "AWS",
    "GCP",
    "Azure",
    "Docker",
    "Kubernetes",
    "Jenkins",
    "GitLab",
    "Terraform",
    "Ansible",
    "ArgoCD",
    "Prometheus",
    "Grafana",
    "Thanos",
    "ELK",
      "IaC",
      "Service Mesh",
      "Airflow",
      "Dagster",
      "Metrics",
      "IAM",
      "Compliance",
      "SOC 2",
      "ISO 27001",
      "DevOps",
      "MLOps",
      "SRE",
      "Innovation",
      "Documentation",
      "IoT",
      "Networking"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_009"
  },
  {
    "job_id": "junior-devops-engineer-at-sparta-global-4344055398",
    "title": "Junior DevOps Engineer",
    "company": "Sparta Global",
    "location": "London, England, United Kingdom",
    "posted_date": "2025-12-16",
    "job_url": "https://uk.linkedin.com/jobs/view/junior-devops-engineer-at-sparta-global-4344055398?position=2&pageNum=0&refId=MS%2FKonCoYvXvhHypONnwyg%3D%3D&trackingId=A8o%2FmxZt1qRsbbvpSOjH7g%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939427",
    "description": "About Sparta GlobalEmbark on a transformative career journey with Sparta Global, where diversity, innovation, and passion for technology converge. We welcome individuals from all backgrounds, offering not just jobs, but dynamic careers in the tech industry. You'll work alongside enthusiastic professionals, receiving top-tier training and mentorship to hone your skills for success in both public and private sectors. Our commitment to designing impactful careers and coaching future leaders is evident in our over 10 prestigious awards in Learning & Development and Equality, Diversity & Inclusion. As a Top 20 Employer for Social Mobility and a proud B-Corp certified organisation, we're not just advancing careers; we're fostering a more diverse, equitable, and inclusive tech landscape. Join us in shaping the future of technology - where your growth is our mission, and your success, our pride. Apply now to be part of our award-winning team at Sparta Global.About This RoleBy utilising DevOps, businesses deliver systems faster, cheaper and without sacrificing high quality. It is an environment, a philosophical mindset and a real-world framework and just as the title says it brings together development and operations so that organisations can create stable, repeatable platforms for product deployment.To become a DevOps specialist, you need to have both technical and soft skills to seamlessly integrate with multiple teams. Engineers use tools to deploy infrastructure as code, create automation and test the platform during deployment and hook in monitoring systems for rapid up to date reporting.As a DevOps Engineer, you will be collaborating with the development and operations teams to automate the deployment of applications to multiple environments.You will be responsible for monitoring the health and performance of systems and troubleshooting issues as they arise.You will implement and maintain infrastructure as code to manage and provision resources effectively, while contributing to the development and improvement of DevOps practises and processes.We're not expecting you to be an expert right away - that's where our award-winning Academy comes in. We're experts in building skills and confidence in a fun and supportive environment that will not only challenge but develop you into a confident and capable consultant.What we're looking for.To be successful for this role you will demonstrate a level of ability in Python or similar. You will be passionate about technology and eager to learn programme development to an advanced level.We're Seeking Candidates Who Can Exemplify Our ValuesEmpathy and Diversity: Integrity, respect, and a commitment to inclusivity.Drive: A goal-oriented mindset with pride in exceeding targets.Collaboration: A team-focused approach, fostering positive relationships.Innovation: Curiosity, creativity, and openness to diverse ideas.Flexibility: Adaptability and composure in the face of change.As a national organisation with clients across the UK, we require all candidates to have the flexibility and willingness to relocate post training for deployment to client site. Remote working cannot be guaranteed. You must have eligibility to work in the UK for the duration of your contract with Sparta Global (British or Irish Citizenship, EU Settled Status, or Permanent Visa Holder). We do not offer visa sponsorships or accept Graduate or PSW Visas due to time limitations.Why You Should ApplyOur environment is designed to nurture your talents and skills, your hard work and progress are not just appreciated - they're tangibly rewarded. We conduct performance-based reviews every six months, offering you the chance to increase your earning potential twice a year. This regular appraisal system is our way of ensuring that your efforts and achievements are consistently recognised and rewarded.We Also Provide20 days annual leave + bank holidays.An extra day off for your birthday.Pension.Eye care.Death in service cover.Cycle to work scheme.Season ticket loan.Employee assistance program.Yearly budget for personal development.Access to alumni and community networks.Opportunities to be brand ambassadors.Being employed by Sparta Global is an investment in your future that pays dividends along the way. We give you breadth of experience and skills, along with increasing opportunities to develop further and earn more. No two career paths look the same at Sparta.Our Recruitment ProcessBegin your journey by applying online and our team will review your application. If you pass our initial screening, you'll be invited to complete our online assessments and first stage interview. If successful, the final stage is a competency-based interview, here you'll have the opportunity to impress us with your ability to communicate effectively and exhibit behavioural competencies through relevant examples. We're looking for candidates who can demonstrate a collaborative spirit and a growth mindset.The Talent Team will be there to support and answer any questions you have. You can also visit our YouTube channel to gain valuable insights and expert advice on virtual interviews, strategies to manage nerves, and tips on nonverbal communication.We look forward to receiving your application - good luck!LNKD1_UKTJ",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
   "skills": [
      "Python",
      "Infrastructure as Code",
      "Automation",
      "Monitoring"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_010"
  },
  {
    "job_id": "dev-ops-engineer-at-punter-southall-4342964247",
    "title": "Dev-Ops Engineer",
    "company": "Punter Southall",
    "location": "Reading, England, United Kingdom",
    "posted_date": "2025-12-09",
    "job_url": "https://uk.linkedin.com/jobs/view/dev-ops-engineer-at-punter-southall-4342964247?position=1&pageNum=0&refId=tv%2FfExXMqlKDuLcDt%2F3%2B9g%3D%3D&trackingId=Qk0ktZKItV5TOW66tiMKjA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939430",
    "description": "Dev-Ops Engineer - Hybrid/ReadingAt Guardian, our mission is simple: to ensure every family has protection they truly believe in. Were challenging the market with a fresh approach and a brand promise Life. Made Better.We are seeking a DevOps Engineer to support and manage Guardians DevOps pipelines and release processes .What does a Dev-Ops Engineer do? This role is critical in driving automation, eliminating manual build steps, and optimising build, deployment, and testing efficiency across our software delivery lifecycle.Your Responsibilities Include But Will Not Be Limited ToReview and identify opportunities to optimise and standardise pipelines across environments.Automate performance, functional, and security testing processes.Support and troubleshoot build, deployment, and release issues.Maintain clear and concise documentation, including high- and low-level designs to support effective outsourcing and collaboration.Produce High and Low Level Designs where required to enable effective outsourcing of work packages.Collaborate closely with developers, testing, and operations teams to improve deployment efficiency and reliability.Proactively identify gaps in automation, tooling, and security recommending and implementing strategic improvements.Who are we looking for? Degree in Computer Science, Software Engineering, or equivalent experience.Hands-on experience across all phases of the software product lifecycle.Strong background in automation tools and frameworks.Familiarity with software security best practices.Proficiency in multiple coding languages.A curious, innovative mindset with strong decision-making and collaboration skills.Excellent communication and prioritisation abilities.Customer-focused and open to constructive feedback.Insurance industry knowledge is a bonus, but not essential.Technical Skills NeededAzure DevOps (YAML pipelines, environments, variable groups)Azure Key Vault (secret and certificate management)Azure API Management (APIM)Azure Managed Identity (system/user assigned)Bearer Token Authentication / OAuth2 / Azure ADAzure Service BusAzure Function AppsAzure App ServicesAzure Front Door (Standard/Premium)Azure Cosmos DBAzure Application Insights / Log AnalyticsAzure AD B2CTerraform (IaC)PowerShell / Bash scriptingYAML configuration and pipeline templatingWhats in it for you?Private Medical Insurance with rewards for yourself with discounted rates for your family membersCompetitive Company Pension SchemeAccess to several employee discounted schemes to suit your lifestyle including but not limited to:Private dental insuranceElectric Vehicle Salary Sacrifice SchemeCycle to Work schemeComprehensive Europe and Worldwide Travel InsuranceMedical Cash PlanGym membershipsAccess to 24/7 GP service for you and your family25 days holiday with the option to purchase moreThis is an exciting time to be joining us with plenty of opportunity for professional growth we invite you to apply to become part of our award-winning team.Should you wish to learn more about the role, or have any questions, please contact our HR Team via .LNKD1_UKTJ",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Contract",
      "Job function": "Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Microsoft Azure",
      "Azure DevOps",
      "YAML",
      "PowerShell",
      "Bash",
      "Terraform",
      "Infrastructure as Code",
      "Azure Key Vault",
      "Azure API Management",
      "Azure Active Directory",
      "OAuth 2.0",
      "Azure Service Bus",
      "Azure Functions",
      "Azure App Service",
      "Azure Front Door",
      "Azure Cosmos DB",
      "Azure Application Insights",
      "Azure Log Analytics",
      "Azure AD B2C"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_012"
  },
  {
    "job_id": "devops-engineer-at-ascendion-4344359761",
    "title": "DevOps Engineer",
    "company": "Ascendion",
    "location": "Raleigh, NC",
    "posted_date": "2025-12-17",
    "job_url": "https://www.linkedin.com/jobs/view/devops-engineer-at-ascendion-4344359761?position=1&pageNum=0&refId=%2B%2B2Ay7GyAfDCdEvzFtNLxw%3D%3D&trackingId=sFMdO9SQPj5DAIoHz4EuAw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939433",
    "description": "About AscendionAscendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.Ascendion | Engineering to elevate lifeWe have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:Build the coolest tech for world’s leading brandsSolve complex problems - and learn new skillsExperience the power of transforming digital engineering for Fortune 500 clientsMaster your craft with leading training programs and hands-on experienceExperience a community of change makers!Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.About The RoleTitle: SRELocation: REMOTEQualificationsIdentity-Related EffortsKnowledge of identity - authentication, authorization, and directory servicesExperience with OktaExperience with TerraformSpecifically, must be able to prioritize, plan, build, test, and launch Terraform workflows from end-to-endProficiency in PythonRecent portfolio projects will be required for review and interviews will include coding challengesExperience with CI/CD pipelinesInfrastructure as Code experienceKnowledge of observability - monitoring and alertingExperience with Kubermetheus Stack (Kubernetes, Prometheus, Loki, Grafana, Alert Manager)Experience with AWSProficiency in PythonSalary Range: The salary for this position is between $130,000- $145,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.Benefits: The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal day accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertains to the City/ State] [10-15 day of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Kubernetes",
      "CI/CD",
      "Terraform",
      "Prometheus",
      "Grafana",
      "SAFe"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_003"
  },
  {
    "job_id": "senior-devops-engineer-at-streamline-4343955799",
    "title": "Senior DevOps Engineer",
    "company": "Streamline",
    "location": "Frisco, TX",
    "posted_date": "2025-12-16",
    "job_url": "https://www.linkedin.com/jobs/view/senior-devops-engineer-at-streamline-4343955799?position=3&pageNum=0&refId=%2B%2B2Ay7GyAfDCdEvzFtNLxw%3D%3D&trackingId=YAn2OZ8DTohsnFS42o62DQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939436",
    "description": "Who We AreAt Streamline, we are experts in Enterprise Mobility, Product Engineering, and IT Transformation. We help organizations navigate the constantly evolving landscape of IT. Our sole focus is ensuring that our client’s organization is armed with the strategies, products, and solutions that are transformative to their business. Streamline works closely with our clients, takes pride in developing genuine relationships, and embraces open communication and collaboration. Our team is comprised of world-class strategists, architects, engineers, and developers.OverviewThis is a remote position. We are looking for a highly skilled Senior DevOps Engineer to join our team. In this role, you will be a key architect of our infrastructure, bridging the gap between development and operations. We need a \"Swiss Army Knife\" of automation who is equally comfortable in Windows and Linux environments and has a mastery of Azure and GitLab.This is a senior-level position requiring deep technical maturity and the ability to solve complex infrastructure challenges through extensive, custom-built automation.Key ResponsibilitiesInfrastructure & Platform EngineeringDesign, deploy, and manage scalable infrastructure within AzureServe as the subject matter expert for both Windows Management and Linux AdministrationImplement and maintain robust system monitoring, logging, and security protocols across hybrid environmentsCI/CD Pipeline MasteryBuild and optimize high-performance CI/CD pipelines using GitLab to ensure seamless application deliveryStandardize deployment processes across multiple development teamsExpert-Level AutomationEliminate manual toil by developing extensive automation scripts using Python, PowerShell, and BashUtilize advanced command line utilities to automate system diagnostics and rapid recovery workflowsMaintain and version-control all infrastructure-as-code and automation scripts using GitRequired QualificationsEducationBachelor's or Master's degree in Computer Science, Software Engineering, or a related fieldExperience8+ years of professional experience in DevOps, Systems Engineering, or Site Reliability EngineeringTechnical Must-HavesAdvanced Scripting: Mastery of Python, PowerShell, and Bash is non-negotiable. You should be able to write complex, reusable, and modular scripts to manage large-scale environmentsCloud: Extensive experience architecting and managing workloads in AzureOperating Systems: Deep dual-stack expertise in Windows Server management and Linux (Ubuntu, RHEL, or similar) administrationTools: Expert knowledge of GitLab and CI/CD methodologiesUtilities: High proficiency with command line utilities for networking, security, and process managementPreferred SkillsExperience with Infrastructure as Code (Terraform, Bicep, or ARM templates)Knowledge of containerization (Docker) and orchestration (Kubernetes)Understanding of SQL and NoSQL database administrationWhat We OfferA challenging and rewarding role in a dynamic and international environmentOpportunity to be part of a growing company with a strong commitment to innovation and excellenceA supportive and collaborative team culture that values personal growth and developmentCompetitive compensation and benefits packagePowered by JazzHRmXKq6LLvMS",
    "criteria": {
      "Seniority level": "Mid-Senior level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Internet Publishing"
    },
    "skills": [
      "Python",
      "Bash",
      "PowerShell",
      "Microsoft Azure",
      "Docker",
      "Kubernetes",
      "GitLab",
      "CI/CD Pipelines",
      "Terraform",
      "Infrastructure as Code",
      "Linux",
      "Ubuntu",
      "SQL",
      "NoSQL Databases",
      "Networking"
    ],
    "role_tag": "DO",
    "role_key": "devops_engineer",
    "job_role_id": "DO_20251218_005"
  },
  {
    "job_id": "web-ui-developer-at-deutsche-bank-4151254134",
    "title": "Web UI Developer",
    "company": "Deutsche Bank",
    "location": "London, England, United Kingdom",
    "posted_date": "2025-12-16",
    "job_url": "https://uk.linkedin.com/jobs/view/web-ui-developer-at-deutsche-bank-4151254134?position=2&pageNum=0&refId=3BCl10EAI8%2BXeIwX935Uww%3D%3D&trackingId=gqgrTQMp3qa%2FeH%2Bzal5gkg%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939439",
    "description": "Position OverviewAdditional Job DescriptionJob Title: EngineerLocation: LondonCorporate Title: Assistant Vice PresidentOur Foreign Exchange (FX) Admin team are working directly with business representatives and global development teams to understand the complex cross-system interactions between distributed configuration, business rules that are required to enable FX Trading at Deutsche Bank. We practice agile, test-first and collaborative development approaches to deliver internal and external applications that allow data to be managed safely and within bank and regulatory requirements. We promote a culture of continuous learning and development and actively engage with Engineering initiatives such as the monthly Engineering Day and our engineering communities.Our team of experts will be there to coach and support your development as you develop greenfield User Interfaces (UI) to support the operation of Deutsche Bank’s FX trading infrastructure and maintain existing systems.What We’ll Offer YouA healthy, engaged and well-supported workforce are better equipped to do their best work and, more importantly, enjoy their lives inside and outside the workplace. That’s why we are committed to providing an environment with your development and wellbeing at its centre.You can expect:Competitive salary and non-contributory pension30 days’ holiday plus bank holidays, with the option to purchase additional daysLife Assurance and Private Healthcare for you and your familyA range of flexible benefits including Retail Discounts, a Bike4Work scheme and Gym benefitsThe opportunity to support a wide ranging CSR programme + 2 days’ volunteering leave per yearYour Key ResponsibilitiesCollaborate and communicate openly. Pair with colleagues to write software and solve problems, engage directly with business stakeholders to elicit requirements, and ensure that the software delivered is fit for purposeDesign solutions using common design patterns with a range of design tools and techniquesImplement solutions following a test-first approach, delivering high quality, maintainable solutionsConduct peer reviews to ensure designs and code are fit for purpose, extensible and re-usableEngage with Engineering Culture initiatives, such as Engineering Day (a monthly day to develop and practice Engineering expertise) to drive Engineering culture across the bankYour Skills And ExperienceA test-first approach to Software DevelopmentProficient in Web UI development (HTML5, CSS, JS, TypeScript, React, Angular)Experienced in building, releasing, operating, and maintaining frontend Web UIsAnalytical thinker and team player with strong communication skillsExperimentation and fast learning approaches to creating business solutionsHow We’ll Support YouCoaching and support from experts in your teamA culture of continuous learning to aid progressionA range of flexible benefits that you can tailor to suit your needsFlexible working to assist you balance your personal prioritiesAbout Us And Our TeamsDeutsche Bank is the leading German bank with strong European roots and a global network. Click here to see what we do.We strive for a culture in which we are empowered to excel together every day. This includes acting responsibly, thinking commercially, taking initiative and working collaboratively.Together we share and celebrate the successes of our people. Together we are Deutsche Bank Group.We welcome applications from all people and promote a positive, fair and inclusive work environment.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Financial Services"
    },
    "skills": [
      "HTML5",
      "CSS",
      "JavaScript",
      "TypeScript",
      "React",
      "Angular",
      "Frontend Architecture",
      "Design Patterns"
    ],
    "role_tag": "WD",
    "role_key": "web_developer",
    "job_role_id": "WD_20251218_002"
  },
  {
    "job_id": "software-engineer-remote-full-time-at-cut%2Bdry-4342738934",
    "title": "Software Engineer (Remote) Full-Time",
    "company": "Cut+Dry",
    "location": "Sri Lanka",
    "posted_date": "2025-12-09",
    "job_url": "https://lk.linkedin.com/jobs/view/software-engineer-remote-full-time-at-cut%2Bdry-4342738934?position=2&pageNum=0&refId=X%2F9WsrRp4k5n3UM1RgPqtw%3D%3D&trackingId=sntCf%2FWR1ZLSaw6HWHiEXQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939442",
    "description": "The ideal candidate is a fast mover with a hunger for developing high-quality applications who will be responsible for implementing testable and scalable code. As an early-stage startup, you must be able to thrive in a fast-moving, rapidly-evolving work setting.ResponsibilitiesDesign and develop software components adhering to both functional and non-functionalrequirements.Work with a team of A-players while contributing to the development efforts.Assure excellent quality of software development with a high level of unit, component and end-to-end testing.QualificationsBachelor’s degree in computer science/engineering or equivalent technical field.Have at least 1 year of experience in developing enterprise grade applications.Strong programming skills in at least 1 programming language i.e.: Python, PHP or JavaScript.Experience with multiple languages will be an added advantage.Possess excellent verbal and written communication skills.Be passionate about solving problems.Why Work at Cut+Dry?Results-driven company culture that encourages a balanced lifestyle.Flexible remote working environment.Above market remuneration, based on experience and skill-level paid in USD.Work with cutting edge technologies in a collaborative and innovating setting.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Other",
      "Industries": "IT Services and IT Consulting"
    },
   "skills": [
      "Python",
      "JavaScript",
      "PHP"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_001"
  },
 {
    "job_id": "software-engineer-1-at-intuit-4333562794",
    "title": "Software Engineer 1",
    "company": "Intuit",
    "location": "New York, NY",
    "posted_date": "2025-12-14",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-1-at-intuit-4333562794?position=2&pageNum=0&refId=H0d2LeOmLt%2FUvKmbHIZoDA%3D%3D&trackingId=C1TWKxPQ4QhnN1NT0yFdKw%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939448",
    "description": "OverviewThis role is ideal for those at the start of their professional journey, with less than two years of industry experience who are eager to learn, grow, and make an immediate impact. As this is a general posting, we’ll align you with a team based on your skills, interests, and career aspirations to set you up for success.We're cultivating a culture that prioritizes innovators, risk-takers, and imaginative thinkers. You’ll help create solutions that transform how millions of consumers and small businesses manage their finances in cloud, platform, mobile, and SaaS environments. Working in a culture that embraces experimentation and rapid prototyping, you’ll collaborate closely with customers and cross-functional teams, turning ideas into real impact while building the skills to launch a rewarding career.ResponsibilitiesFrontend Engineering:Experience developing scalable, responsive, and dynamic web-based applicationsFamiliarity with modern frontend tools and frameworks such as React, AngularJS, or Vue.jsKnowledge of HTML, CSS, and JavaScript standardsStrong ability to collaborate with designers, UX specialists, and backend engineersBackend EngineeringExperience developing web applications using server-side languages, such as Java, Python, or Node.js.Familiarity with database technologies such as MySQL, PostgreSQL, or MongoDBUnderstanding of RESTful API design principles and ability to work with API integrationsExperience with server frameworks such as Express, Spring MVC or DjangoFullstack EngineeringFamiliarity with both frontend and backend developmentAbility to work effectively with developers and designers, discussing application and API architecturesUnderstanding of Agile methodologies and ability to work with Scrum teamsFamiliarity with tools such as Git, Jenkins, or TravisMobile EngineeringExperience developing applications for one or more platforms such as Android and iOSFamiliarity with mobile application development frameworks such as React Native or FlutterUnderstanding of development tools such as XCode, Android Studio and SDK languages such as Objective-C, Swift or JavaAbility to work with designers and backend engineers to integrate mobile applications with cloud-based APIsAcross All Tech StacksContribute to our core products and services, as well as systems that power critical engineering operations.See your work launched and help solve meaningful problems for customers.Learn and apply proven best practices in designing, building, and supporting software projects.Receive hands-on guidance, detailed feedback, and mentorship from experienced team members.Collaborate closely with peers across disciplines and build strong, supportive working relationships.QualificationsQualificationsBachelor’s or Master’s degree in Computer Science, a related technical field, or equivalent practical experience.Foundational understanding of Agile development, object-oriented design, and programming principles.Coursework, internships, personal projects, or academic experience with one or more programming languages (e.g., Java, Python, JavaScript, C++, etc.).Basic knowledge of front-end web technologies (e.g., HTML, CSS, JavaScript) and familiarity with frameworks or tools is a plus.Strong written, verbal, and collaboration skills with the ability to work effectively in a team environment.Awareness of AI concepts and a basic understanding of capabilities like Generative AI.Willingness to learn and adapt to new priorities, tools, and technologies in a fast-paced, dynamic environment.Intuit provides a competitive compensation package with a strong pay for performance rewards approach. This position will be eligible for a cash bonus, equity rewards and benefits, in accordance with our applicable plans and programs (see more about our compensation and benefits at Intuit®: Careers | Benefits). Pay offered is based on factors such as job-related knowledge, skills, experience, and work location. To drive ongoing fair pay for employees, Intuit conducts regular comparisons across categories of ethnicity and gender. The expected base pay range for this position is:Bay Area California $55.50 - 75",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Python",
      "Java",
      "JavaScript",
      "Node.js",
      "React",
      "HTML",
      "CSS",
      "MySQL",
      "PostgreSQL",
      "Git",
      "Jenkins",
      "Android Development",
      "iOS Development",
      "React Native"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_004"
  },
  {
    "job_id": "software-engineer-new-grad-at-seatgeek-4341610061",
    "title": "Software Engineer - New Grad",
    "company": "SeatGeek",
    "location": "New York, NY",
    "posted_date": "2025-12-10",
    "job_url": "https://www.linkedin.com/jobs/view/software-engineer-new-grad-at-seatgeek-4341610061?position=3&pageNum=0&refId=H0d2LeOmLt%2FUvKmbHIZoDA%3D%3D&trackingId=87EiXObpU%2F8DRJlEuo3f9g%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939452",
    "description": "SeatGeek believes live events are powerful experiences that unite humans. With our technological savvy and fan-first attitude we’re simplifying and modernizing the ticketing industry.We’re building an awesome entertainment ecosystem where fans have effortless access to incredible live experiences, while sports teams, venues, and shows have unprecedented access to their audiences – because everyone should expect more from the ticketing industry.Open roles for new graduatesWe are looking for the best and brightest Spring/Summer 2026 college graduates to help us make live entertainment even better! Experience is preferred, but not required – in fact, we look forward to supporting you by teaching you new technologies and mentoring you in software development craft as a member of our world-class engineering team.We Have Roles Open In The Following TechnologiesBackend (Python, Go, C#)Frontend Web (Typescript + React)Mobile (Kotlin, Swift)Platform (AWS, Docker, Python, Go)What You'll DoSolve unique and challenging customer problemsWork with leading-edge tech in the cloud or on web and mobileHelp scale our software as we grow our booming businessTake on the challenges of building software for a many-sided marketplaceEmpower decision-making at a rapidly growing data-driven company Run experiments and evaluate new technologies that will determine the future of our business for years to comeBuild performant, beautiful, inclusive user interfaces that delight our users and enhance our brandWhat You HaveYou are a college student graduating in the Spring/Summer of 2026, ideally in computer science or a related degreeExperience in building software. We'll be interested in hearing about what you've built and how you built itProblem solving abilities, adept at handling technical challenges. SeatGeek engineers create custom solutions to unique ticketing problems, including venue mapping, inventory tracking, and event matching. We'll be excited to hear about the problems you've solvedPassion for software craftsmanship and product. You hold yourself and your code to a high standardCommitment to your teammates. You enjoy working with a diverse group of people with different experiences and take pride in mentoring and learning from othersOur stackYou do not need experience with all of these, but we thought you might be curious. What we care about is your experience, skills, and approach to problem-solving. Tools can be learned.Languages: Python, Go, C#+.NET Core, React+Typescript, Swift, KotlinDatastores: Postgres, Redis, ElasticsearchCloud: AWSVersion control: GitlabPerksEquity stakeA WFH stipend to support your home office setupUnlimited PTOUp to 16 weeks of fully-paid family leave 401(k) matching programStudent loan support resourcesHealth, vision, dental, and life insuranceUp to $25k towards family building and reproductive health servicesGender-affirming care support program$500 per year for wellness expensesSubscriptions to Headspace (meditation), Headspace Care (therapy), and One Medical$120 per month to spend on tickets to live eventsAnnual subscription to Spotify, Apple Music, or Amazon musicPlease note you are expected to come into the SeatGeek New York City Office at least 3 days a week**The salary range for this role is $110,000-$130,000 USD. Actual compensation packages within that range are based on a wide array of factors unique to each candidate, including but not limited to skill set, years and depth of experience, and certifications.SeatGeek is committed to providing equal employment opportunities to all employees and applicants for employment regardless of race, color, religion, creed, age, national origin or ancestry, ethnicity, sex, sexual orientation, gender identity or expression, disability, military or veteran status, or any other category protected by federal, state, or local law. As an equal opportunities employer, we recognize that diversity is a positive attribute and we welcome the differences and benefits that a diverse culture brings. Come join us!To review our candidate privacy notice, click here.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Full-time",
      "Job function": "Engineering",
      "Industries": "Technology, Information and Internet"
    },
    "skills": [
      "Python",
      "Go",
      "C#",
      "TypeScript",
      "React",
      "Swift",
      "Kotlin",
      "PostgreSQL",
      "Redis",
      "Amazon Web Services",
      "Docker",
      "GitLab"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_005"
  },
    {
    "job_id": "data-analyst-at-chevron-4341962225",
    "title": "Data Analyst",
    "company": "Chevron",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-11-20",
    "job_url": "https://in.linkedin.com/jobs/view/data-analyst-at-chevron-4341962225?position=8&pageNum=0&refId=W45lf1%2BMXl4%2B46RPZMoSxw%3D%3D&trackingId=sYufgFlNxKR5X%2B6CV%2FpsMw%3D%3D",
    "scraped_at": "2025-11-27T16:50:00.424076",
    "description": "About The PositionA Data Analyst is responsible for gathering, analyzing and problem solving as it relates to data, types of data, and relationships among data elements within a business system or IT system and with business domain expertise. A Data Analyst provides expertise on how Business workflows map to data, and how data can be integrated to build reusable data products. A Data analyst will serve as a subject matter expert for delivery teams.The Data Analyst will support the analysis and visualization of data to provide valuable insights that drive business decisions. This role requires a strong understanding of data processing, reporting, and visualization tools, as well as a good working knowledge of Microsoft Azure Services and Power Platform. The ideal candidate will have hands-on experience with data modeling, creating dashboards, and leveraging cloud technologies for data management.Key ResponsibilitiesAnalyze data to extract meaningful insights, trends, and patterns that can support decision-making across the organization.Develop and maintain dashboards and visualizations using Power BI, Spotfire, and Tableau to present data insights in an easy-to-understand format for stakeholders.Work with Azure Synapse Analytics, Azure Data Lake, and Azure SQL Database to store, transform, and retrieve data efficiently.Assist in data preparation, cleaning, and integration activities for analysis, ensuring high data quality.Collaborate with data engineers, business stakeholders, and IT teams to understand data requirements and contribute to the delivery of data-driven solutions.Leverage Power Platform tools to automate tasks, create workflows, and enhance data analysis processes.Provide support for ongoing analysis and maintain documentation for data processes, reports, and dashboards.Required QualificationsExperience: Overall 2-4 years of experience with 2 years of proven experience in data analysis, data visualization, or related fields.Bachelor's degree in Data Analytics, Computer Science, Statistics, or a related field (or equivalent experience).0-5 years experienceTechnical Skills:Proficiency in Microsoft Azure services, including Azure Synapse Analytics, Azure Data Lake, and Azure SQL Database.Experience in data visualization tools such as Power BI, Spotfire, and Tableau.Strong skills in data manipulation and transformation using SQL.Familiarity with the Microsoft Power Platform, including Power Apps, Power Automate, and Power BI.Proficiency in data visualization tools such as Power BI, Spotfire, Tableau. Data modeling techniques, data fluency and governance.Proficiency in Oil & gas workflows and data typesData Analysis: Understanding of data analysis concepts and experience in data modeling and building insightful reports.Problem Solving: Strong analytical and problem-solving skills, with attention to detail.Communication Skills: Ability to communicate complex data findings in a clear and concise manner to non-technical stakeholders.Team Collaboration: Ability to work effectively as part of a team, sharing knowledge, and supporting other team members.Excellent communication and collaboration skills with demonstrated ability to build trusted working relationships with remote peers and stakeholders (internal & external parties) across global teams and time zones.Strong knowledge of Microsoft Azure Services & Power Platform, including Azure Synapse Analytics, Azure Data Lake, and Azure SQL Database.Experience with SQL and data querying languages.Experience with Python for data wrangling.Strong analytical and problem-solving skills with attention to detail and accuracyFundamental knowledge of Information Risk Management (IRM).Preferred QualificationsMicrosoft Power BI Data Analyst certification (PL-300)Ability to discover and prepare datasets into clean, understandable, usable, datasets for data analysis.Cloud Certifications: Certifications in Microsoft Azure (e.g., Azure Data Fundamentals, Azure Data Engineer Associate) are preferred.Experience with ETL Tools: Exposure to ETL tools and data integration techniques.Advanced Analytics: Experience or knowledge of machine learning or advanced analytics is a plus.Scripting Languages: Basic understanding of scripting languages such as Python or R for data analysis.Chevron ENGINE supports global operations, supporting business requirements across the world. Accordingly, the work hours for employees will be aligned to support business requirements. The standard work week will be Monday to Friday. Working hours are 8:00AM to 5:00PM or 1:30PM to 10:30PM.",
    "criteria": {
      "Seniority level": "Entry level",
      "Employment type": "Full-time",
      "Job function": "Information Technology",
      "Industries": "Oil and Gas"
    },
 "skills": [
    "SQL",
    "Python",
    "R",
    "Data Analysis",
    "Data Modeling",
    "ETL",

 
    "Microsoft Azure",
    "Azure Synapse Analytics",
    "Azure Data Lake",
    "Azure SQL Database",
    "Power BI",
    "Power Apps",
    "Power Automate",
    "Tableau",
    "Spotfire",
    "Information Risk Management",
    "Machine Learning"
  ],
    "role_tag": "DA",
    "role_key": "data_analyst",
    "job_role_id": "DA_20251127_022"
  },
  {
    "job_id": "software-engineer-university-grad-bangalore-at-meta-4311909465",
    "title": "Software Engineer (University Grad) - Bangalore",
    "company": "Meta",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-17",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-university-grad-bangalore-at-meta-4311909465?position=1&pageNum=0&refId=aKK%2FEL%2FVybjKSUYxSCMueg%3D%3D&trackingId=r%2Fh9BaUqz3NipJ2jqw0i%2FA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939455",
    "description": "Meta is seeking talented engineers to join our teams in building cutting-edge products, with the mission of connecting billions of people around the world. As a member of our team, you will have the opportunity to work on complex technical problems, build new features, and improve existing products across various platforms, including mobile devices and web applications. Our teams are constantly pushing the boundaries of user experience, and we're looking for passionate individuals who can help us advance the way people connect globally. If you're interested in joining a world-class team and working on exciting projects that have a significant impact, we encourage you to apply.Software Engineer (University Grad) - Bangalore Responsibilities:Develop a strong understanding of relevant product area, codebase, and/or systemsDemonstrate proficiency in data analysis, programming and software engineeringProduce high quality code with good test coverage, using modern abstractions and frameworksWork independently, use available resources to get unblocked, and complete tasks on-schedule by exercising strong judgement and problem solving skillsMaster Meta’s development standards from developing to releasing code in order to take on tasks and projects with increasing levels of complexityActively seek and give feedback in alignment with Meta’s Performance PhilosophyMinimum Qualifications:Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining MetaExperience coding in an industry-standard language (e.g. Java, Python, C++, JavaScript)Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employmentPreferred Qualifications:Demonstrated software engineering experience from previous internship, work experience, coding competitions, or publicationsCurrently has, or is in the process of obtaining, a Bachelors or Masters degree in Computer Science or a related fieldAbout Meta:Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Technology, Information and Internet"
    },
      "skills": [
      "Python",
      "Java",
      "JavaScript",
      "C++",
      "Data Analysis"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_006"
  },
  {
    "job_id": "software-engineer-at-microsoft-4343011374",
    "title": "Software Engineer",
    "company": "Microsoft",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-09",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4343011374?position=2&pageNum=0&refId=aKK%2FEL%2FVybjKSUYxSCMueg%3D%3D&trackingId=SPMtCemFeXtgHw4BOBO6WQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939458",
    "description": "OverviewMicrosoft Azure Storage is a highly distributed, massively scalable, and ubiquitously accessible cloud storage platform. Azure storage already runs at Exascale (storing Exabytes of data) and we will scale our designs over the next decade to support Zettascale (storing Zettabytes of data). Within Azure Storage, the Ultra Disk team provides next-generation block storage platform for the most demanding cloud storage workloads. If delivering the fastest block storage platform in the cloud using cutting edge technology sounds interesting, we may have the job for you!As a Software Engineer in the Azure Storage team you will be responsible for designing, developing and maintaining a block storage solution that handles massive amounts of data efficiently. This opportunity will allow you to collaborate with cross functional teams to design storage solutions that meet performance availability and durability. You will be responsible for writing clean, efficient and scalable code, creating technical documentation, API specifications, operation procedures etc. As part of our commitment to work-life balance, this role offers upto 50% Work from Home.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesWorks with appropriate stakeholders to determine user requirements for a set of features.Contributes to the identification of dependencies, and the development of design documents for a product area with little oversight.Creates and implements code for a product, service, or feature, reusing code as applicable.Contributes to efforts to break down larger work items into smaller work items and provides estimation.Acts as a Designated Responsible Individual (DRI) working on-call to monitor system/product feature/service for degradation, downtime, or interruptions and gains approval to restore system/product/service for simple problems.Remains current in skills by investing time and effort into staying abreast of current developments that will improve the availability, reliability, efficiency, observability, and performance of products while also driving consistency in monitoring and operations at scale.QualificationsRequired/Minimum Qualifications:Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience.Other RequirementsAbility to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include, but are not limited to the following specialized security screenings: Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud Background Check upon hire/transfer and every two years thereafter. Additional Or Preferred QualificationsBachelor's Degree in Computer ScienceOR related technical field AND 1+ year(s) technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, OR PythonOR Master's Degree in Computer Science or related technical field with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience.1+ years experience in designing and building large scale distributed systems.1+ years experience in cloud backend development and operation, including performance, reliability, resilience, and scale-out.This position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Java",
      "JavaScript",
      "Python",
      "C",
      "C++",
      "C#",
      "Microsoft Azure",
      "Azure Storage",
      "Cloud Storage",
      "Distributed Systems"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_007"
  },
  {
    "job_id": "software-engineer-at-microsoft-4326794717",
    "title": "Software Engineer",
    "company": "Microsoft",
    "location": "Bengaluru, Karnataka, India",
    "posted_date": "2025-12-11",
    "job_url": "https://in.linkedin.com/jobs/view/software-engineer-at-microsoft-4326794717?position=3&pageNum=0&refId=aKK%2FEL%2FVybjKSUYxSCMueg%3D%3D&trackingId=8gGc%2BUfEaa4qbyHHeVo8hA%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939461",
    "description": "OverviewDo you want to be a part of a multi-billion-dollar organization that is rapidly growing and is responsible for 200M MAU and exabytes of customer data in the cloud at high performance and scale? Do you want to work on technically challenging problems on the cloud in a full-stack environment, with an opportunity to influence the roadmap and vision of not only your team but your partner teams as well? If so, come join the OneDrive-SharePoint (ODSP) team as part of Office M365 ecosystem in Hyderabad!SharePoint helps millions of people work better together and empowers the biggest companies in the world to solve mission critical problems. We create global scale services to store, secure and manage some of the most sensitive data on the planet.We have fantastic opportunities and are on the front-line of making many of our next generation architecture investments to deliver multi-geo content store, amazing performance/scale/reliability, and security capabilities using scalable cloud distributed systems.Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.ResponsibilitiesLead the design/development of software and ensure its quality.Defining new components with complete understanding of service interdependencies and limitations.Possess knowledge and is curious to learn more about performance, scalability, enterprise system architecture, and engineering best practices.Creating prototypes and proof-of-concepts for iterative development.Work effectively with product development and engineering teams.You must be self-driven, curious to learn, proactive, and result-oriented.Join a team of builders and innovators that think outside the box.A team that’s committed to a low operational burden by designing for it.A team that puts work-life balance, personal and professional growth as a principle, not just a goal. QualificationsRequired Qualifications:Bachelor's Degree in Computer Science, or related technical discipline with proven experience coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or PythonOR equivalent experience.Solid CS fundamentals and exceptional coding skills.Good communication and cross group collaboration skills.Experience in Azure, Exchange, or other cloud and distributed systems is a big plus. #ExDIndia #ODSPJobsThis position will be open for a minimum of 5 days, with applications accepted on an ongoing basis until the position is filled.Microsoft is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance with religious accommodations and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.",
    "criteria": {
      "Seniority level": "Not Applicable",
      "Employment type": "Full-time",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development"
    },
    "skills": [
      "Java",
      "JavaScript",
      "Python",
      "C",
      "C++",
      "C#",
      "Microsoft Azure",
      "SharePoint",
      "Distributed Systems"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_008"
  },
  {
    "job_id": "software-engineer-intern-at-stripe-4335414748",
    "title": "Software Engineer, Intern",
    "company": "Stripe",
    "location": "London, England, United Kingdom",
    "posted_date": "2025-12-02",
    "job_url": "https://uk.linkedin.com/jobs/view/software-engineer-intern-at-stripe-4335414748?position=3&pageNum=0&refId=6Ylag2lhPm2WaGjUpgD5uw%3D%3D&trackingId=P9EcIQEnp6wfw7p7cC%2BkeQ%3D%3D",
    "scraped_at": "2025-12-18T07:42:57.939464",
    "description": "Who we areAbout StripeStripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career.About The TeamOur internship program will provide an opportunity to work on meaningful products that will grow the GDP of the internet. Through the internship, you will work with many systems and technologies, gain experience in systems design and testing, and have opportunities to present your work to your team and the wider org. Each intern has a dedicated intern manager, and every project is part of the team’s roadmap and will directly help Stripe’s mission.What you’ll doEvery internship at Stripe centers around a real, legitimate project that our customers urgently need, touching many parts of our operations and stack. We will support you in shipping it. Yes, you will actually ship it. Some recent projects include rebuilding our statistics aggregation service, building new service discovery systems, and many user facing projects like making it easy to understand error messages on Stripe Checkout. As a Stripe intern, you'll be tackling important projects to increase global commerce, while working alongside exceptional people who insist on doing their best work. You’ll learn from people with high standards who are great at inspiring others to do more and go further. We value technical and personal growth, and see our internship program as a vehicle to foster both.ResponsibilitiesWrite software that will be used in production, and has meaningful impact to StripeGive and receive technical feedback through code reviews or design discussionsCollaborate with other engineers and cross-functional stakeholders to proactively seek and incorporate feedbackLearn quickly by asking great questions, by working with your intern manager and teammates effectively, and by communicating the status of your work clearlyWho you areWe’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.Minimum RequirementsA strong fundamental understanding of computer science through pursuit of a Bachelor’s, Master’s, or PhD degree in computer science, math, or a related disciplineSome experience and familiarity with programming, either through side projects or classwork. We work mostly in Java, Ruby, JavaScript, Scala, and Go. We believe new programming languages can be learned if the fundamentals and general knowledge are presentExperience from previous internships or other multi-person projects, including open source contributions, that demonstrate evaluating and receiving feedback from mentors, peers, and stakeholdersAbility to learn unfamiliar systems and form an understanding of those systems, through independent research and working with a mentor and subject matter expertsPreferred QualificationsAt least 2 years of university education, or equivalent work experienceOne or more areas of specialized knowledge balanced with general skills and knowledge, such as knowing more frontend technologies and, at a high level, how a service handles an HTTP requestUnderstanding and some experience writing high quality pull requests, with good test coverage, and working knowledge to complete projects with minimal defectsFamiliarity with navigating and managing your work in new code bases, with multiple languagesAbility to write clearly to explain your work to stakeholders, team members, and other Stripes.In-office expectationsOffice-assigned Stripes in most of our locations are currently expected to spend at least 50% of the time in a given month in their local office or with users. This expectation may vary depending on role, team and location. For example, Stripes in our Bucharest, Romania site have an 80% in-office expectation, and those in Stripe Delivery Center roles in Mexico City, Mexico and Bengaluru, India work 100% from the office. Also, some teams have greater in-office attendance requirements, to appropriately support our users and workflows, which the hiring manager will discuss. This approach helps strike a balance between bringing people together for in-person collaboration and learning from each other, while supporting flexibility when possible.Pay and benefitsThe annual salary range for this role in the primary location is £49,200 - £49,200. This range may change if you are hired in another location. For sales roles, the range provided is the role’s On Target Earnings (“OTE”) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. This salary range may be inclusive of several career levels at Stripe and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and specific location. Applicants interested in this role and who are not located in the primary location may request the annual salary range for their location during the interview process.Specific benefits and details about what compensation is included in the salary range listed above will vary depending on the applicant’s location and can be discussed in more detail during the interview process. Benefits/additional compensation for this role may include: equity, company bonus or sales commissions/bonuses; retirement plans; health benefits; and wellness stipends.",
    "criteria": {
      "Seniority level": "Internship",
      "Employment type": "Internship",
      "Job function": "Engineering and Information Technology",
      "Industries": "Software Development, Financial Services, and Technology, Information and Internet"
    },
   "skills": [
      "Java",
      "JavaScript",
      "Ruby",
      "Go",
      "Scala",
      "Distributed Systems",
      "Service Discovery"
    ],
    "role_tag": "SE",
    "role_key": "software_engineer",
    "job_role_id": "SE_20251218_009"
  }
]